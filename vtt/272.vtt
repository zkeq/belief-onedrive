WEBVTT

1
00:00:11.932 --> 00:00:14.151
In the early days of Twitter. 
[AI] 在Twitter的早期。

2
00:00:14.152 --> 00:00:17.259
it was like a place of radical de-shaming.
[AI] 这就像是一个彻底消除羞耻感的地方。

3
00:00:17.283 --> 00:00:20.231
People would admit shameful secrets about themselves.
[AI] 人们会承认自己的可耻秘密。

4
00:00:20.255 --> 00:00:24.749
and other people would say. "Oh my God. I'm exactly the same."
[AI] 其他人会说。“哦，我的天啊，我完全一样。”

5
00:00:24.773 --> 00:00:27.575
Voiceless people realized that they had a voice.
[AI] 无声的人意识到他们有声音。

6
00:00:27.599 --> 00:00:30.554
and it was powerful and eloquent.
[AI] 它是强有力的，雄辩的。

7
00:00:30.578 --> 00:00:35.347
If a newspaper ran some racist or homophobic column.
[AI] 如果报纸上有种族主义或恐同的专栏。

8
00:00:35.371 --> 00:00:37.762
we realized we could do something about it.
[AI] 我们意识到我们可以做点什么。

9
00:00:37.786 --> 00:00:39.155
We could get them.
[AI] 我们可以得到他们。

10
00:00:39.179 --> 00:00:42.631
We could hit them with a weapon that we understood but they didn't --
[AI] 我们可以用我们理解的武器打击他们，但他们没有--

11
00:00:42.655 --> 00:00:44.830
a social media shaming.
[AI] 社交媒体的耻辱。

12
00:00:45.564 --> 00:00:48.316
Advertisers would withdraw their advertising.
[AI] 广告商将撤回他们的广告。

13
00:00:48.753 --> 00:00:51.763
When powerful people misused their privilege.
[AI] 当有权势的人滥用他们的特权时。

14
00:00:51.787 --> 00:00:53.450
we were going to get them.
[AI] 我们要去拿。

15
00:00:54.132 --> 00:00:56.912
This was like the democratization of justice.
[AI] 这就像司法的民主化。

16
00:00:56.936 --> 00:00:59.339
Hierarchies were being leveled out.
[AI] 等级制度正在被拉平。

17
00:00:59.363 --> 00:01:01.361
We were going to do things better.
[AI] 我们打算把事情做得更好。

18
00:01:02.575 --> 00:01:09.943
Soon after that. a disgraced pop science writer called Jonah Lehrer -- he'd been caught plagiarizing and faking quotes.
[AI] 不久之后。一位声名狼藉的通俗科学作家乔纳·莱勒（Jonah Lehrer）因抄袭和伪造引文而被捕。

19
00:01:09.967 --> 00:01:13.699
and he was drenched in shame and regret. he told me.
[AI] 他沉浸在羞愧和悔恨之中。他告诉我。

20
00:01:13.723 --> 00:01:15.214
And he had the opportunity
[AI] 他有机会

21
00:01:15.238 --> 00:01:19.068
to publicly apologize at a foundation lunch.
[AI] 在基金会午餐上公开道歉。

22
00:01:19.092 --> 00:01:22.023
This was going to be the most important speech of his life.
[AI] 这将是他一生中最重要的演讲。

23
00:01:22.047 --> 00:01:24.331
Maybe it would win him some salvation.
[AI] 也许这会为他赢得一些救赎。

24
00:01:24.934 --> 00:01:26.263
He knew before he arrived
[AI] 他到达之前就知道了

25
00:01:26.287 --> 00:01:29.366
that the foundation was going to be live-streaming his event.
[AI] 基金会将现场直播他的事件。

26
00:01:29.390 --> 00:01:31.414
but what he didn't know until he turned up.
[AI] 但直到他出现他才知道。

27
00:01:31.438 --> 00:01:36.366
was that they'd erected a giant screen Twitter feed right next to his head.
[AI] 他们在他的头旁边竖起了一个巨大的屏幕。

28
00:01:36.390 --> 00:01:37.882
(Laughter)
[AI] （众笑）

29
00:01:37.906 --> 00:01:40.449
Another one in a monitor screen in his eye line.
[AI] 另一个在他眼线的监视器屏幕上。

30
00:01:40.473 --> 00:01:43.909
I don't think the foundation did this because they were monstrous.
[AI] 我不认为基金会这么做是因为它们太可怕了。

31
00:01:43.933 --> 00:01:47.087
I think they were clueless: I think this was a unique moment
[AI] 我认为他们是无知的：我认为这是一个独特的时刻

32
00:01:47.111 --> 00:01:49.648
when the beautiful naivety of Twitter
[AI] 当美丽天真的推特

33
00:01:49.672 --> 00:01:52.981
was hitting the increasingly horrific reality.
[AI] 正在触及日益可怕的现实。

34
00:01:53.627 --> 00:01:56.980
And here were some of the Tweets that were cascading into his eye line.
[AI] 这里有一些推特，这些推特正源源不断地传到他的眼线。

35
00:01:57.004 --> 00:01:58.730
as he was trying to apologize:
[AI] 当他试图道歉时：

36
00:01:58.754 --> 00:02:02.016
"Jonah Lehrer. boring us into forgiving him."
[AI] “约拿·莱勒。让我们厌烦去原谅他。”

37
00:02:02.040 --> 00:02:03.115
(Laughter)
[AI] （众笑）

38
00:02:03.139 --> 00:02:07.607
And. "Jonah Lehrer has not proven that he is capable of feeling shame."
[AI] 和“约拿·莱勒没有证明他有能力感到羞耻。”

39
00:02:08.409 --> 00:02:12.100
That one must have been written by the best psychiatrist ever.
[AI] 那一定是有史以来最好的精神病医生写的。

40
00:02:12.124 --> 00:02:15.599
to know that about such a tiny figure behind a lectern.
[AI] 真想知道在讲台后面有这么一个小人物。

41
00:02:15.955 --> 00:02:18.972
And. "Jonah Lehrer is just a frigging sociopath."
[AI] 和“乔纳·莱勒只是个该死的反社会者。”

42
00:02:19.694 --> 00:02:25.094
That last word is a very human thing to do. to dehumanize the people we hurt.
[AI] 最后一句话是非常人性化的事情。让我们伤害的人失去人性。

43
00:02:25.118 --> 00:02:29.295
It's because we want to destroy people but not feel bad about it.
[AI] 这是因为我们想毁灭人们，但并不为此感到难过。

44
00:02:30.323 --> 00:02:32.771
Imagine if this was an actual court.
[AI] 想象一下，如果这是一个真正的法庭。

45
00:02:32.795 --> 00:02:35.621
and the accused was in the dark. begging for another chance.
[AI] 被告在黑暗中。乞求另一次机会。

46
00:02:35.645 --> 00:02:37.386
and the jury was yelling out.
[AI] 陪审团大喊大叫。

47
00:02:37.410 --> 00:02:40.097
"Bored! Sociopath!"
[AI] “无聊！反社会者！”

48
00:02:40.121 --> 00:02:41.262
(Laughter)
[AI] （众笑）

49
00:02:41.286 --> 00:02:44.305
You know. when we watch courtroom dramas. we tend to identify
[AI] 你知道的。当我们看法庭剧的时候。我们倾向于认同

50
00:02:44.329 --> 00:02:47.300
with the kindhearted defense attorney.
[AI] 和善良的辩护律师。

51
00:02:47.324 --> 00:02:50.830
but give us the power. and we become like hanging judges.
[AI] 但是给我们力量。我们就像被绞死的法官。

52
00:02:51.666 --> 00:02:53.639
Power shifts fast.
[AI] 权力转移很快。

53
00:02:54.104 --> 00:02:58.600
We were getting Jonah because he was perceived to have misused his privilege.
[AI] 我们得到约拿是因为他被认为滥用了他的特权。

54
00:02:58.624 --> 00:03:01.907
but Jonah was on the floor then. and we were still kicking.
[AI] 但约拿当时在地板上。我们还在踢。

55
00:03:01.931 --> 00:03:04.713
and congratulating ourselves for punching up.
[AI] 祝贺我们自己打了一拳。

56
00:03:05.554 --> 00:03:09.753
And it began to feel weird and empty when there wasn't a powerful person
[AI] 当没有一个有权势的人时，它开始感到奇怪和空虚

57
00:03:09.777 --> 00:03:12.795
who had misused their privilege that we could get.
[AI] 他们滥用了我们可以得到的特权。

58
00:03:13.152 --> 00:03:16.454
A day without a shaming began to feel like a day
[AI] 没有羞耻感的一天开始感觉像是一天

59
00:03:16.478 --> 00:03:19.405
picking fingernails and treading water.
[AI] 修剪指甲和踩水。

60
00:03:21.207 --> 00:03:22.603
Let me tell you a story.
[AI] 让我给你讲个故事。

61
00:03:23.381 --> 00:03:25.802
It's about a woman called Justine Sacco.
[AI] 是关于一个叫贾斯汀·萨科的女人的。

62
00:03:26.620 --> 00:03:30.564
She was a PR woman from New York with 170 Twitter followers.
[AI] 她是一位来自纽约的公关女士，拥有170名推特粉丝。

63
00:03:30.588 --> 00:03:33.544
and she'd Tweet little acerbic jokes to them.
[AI] 她会在推特上给他们讲一些尖刻的笑话。

64
00:03:33.568 --> 00:03:37.191
like this one on a plane from New York to London:
[AI] 就像这张从纽约到伦敦的飞机上的照片：

65
00:03:37.215 --> 00:03:40.726
[Weird German Dude: You're in first class. It's 2014. Get some deodorant."
[AI] [奇怪的德国人：你坐的是头等舱。2014年了。去买点除臭剂。”

66
00:03:40.750 --> 00:03:43.852
-Inner monologue as inhale BO. Thank god for pharmaceuticals.]
[AI] -内心独白如同吸入波。感谢上帝给了我们药品。]

67
00:03:43.876 --> 00:03:47.139
So Justine chuckled to herself. and pressed send. and got no replies.
[AI] 于是贾斯汀暗自发笑。然后按send。没有得到答复。

68
00:03:47.163 --> 00:03:49.224
and felt that sad feeling that we all feel
[AI] 感受到我们所有人都感受到的那种悲伤的感觉

69
00:03:49.248 --> 00:03:52.882
when the Internet doesn't congratulate us for being funny.
[AI] 当互联网不祝贺我们的幽默时。

70
00:03:52.906 --> 00:03:54.077
(Laughter)
[AI] （众笑）

71
00:03:54.101 --> 00:03:57.224
Black silence when the Internet doesn't talk back.
[AI] 当互联网不回应时，黑色的沉默。

72
00:03:57.859 --> 00:04:01.002
And then she got to Heathrow. and she had a little time to spare
[AI] 然后她到了希思罗机场。她还有一点时间

73
00:04:01.026 --> 00:04:05.802
before her final leg. so she thought up another funny little acerbic joke:
[AI] 在她最后一条腿之前。于是她想出了另一个有趣的尖刻的小笑话：

74
00:04:05.826 --> 00:04:10.148
[Going to Africa. Hope I don't get AIDS. Just kidding. I'm white!]
[AI] [去非洲。希望我不会得艾滋病。开玩笑吧。我是白人！]

75
00:04:10.172 --> 00:04:16.298
And she chuckled to herself. pressed send. got on the plane. got no replies.
[AI] 她暗自窃笑。按发送。上了飞机。没有得到答复。

76
00:04:16.322 --> 00:04:18.905
turned off her phone. fell asleep.
[AI] 关掉了她的手机。我睡着了。

77
00:04:18.929 --> 00:04:20.918
woke up 11 hours later.
[AI] 11小时后醒来。

78
00:04:20.942 --> 00:04:24.536
turned on her phone while the plane was taxiing on the runway.
[AI] 当飞机在跑道上滑行时，她打开了手机。

79
00:04:24.560 --> 00:04:26.917
and straightaway there was a message from somebody
[AI] 马上就有人传来了消息

80
00:04:26.941 --> 00:04:29.037
that she hadn't spoken to since high school.
[AI] 她从高中起就没跟她说过话。

81
00:04:29.061 --> 00:04:33.808
that said. "I am so sorry to see what's happening to you."
[AI] 也就是说。“我很抱歉看到你发生了什么事。”

82
00:04:34.832 --> 00:04:37.613
And then another message from a best friend.
[AI] 然后是最好的朋友发来的另一条信息。

83
00:04:37.637 --> 00:04:39.651
"You need to call me right now.
[AI] “你需要马上给我打电话。

84
00:04:39.675 --> 00:04:43.688
You are the worldwide number one trending topic on Twitter."
[AI] 你是推特上全球头号热门话题。"

85
00:04:43.712 --> 00:04:45.422
(Laughter)
[AI] （众笑）

86
00:04:46.074 --> 00:04:49.524
What had happened is that one of her 170 followers had sent the Tweet
[AI] 发生的事情是，她的170名追随者中有一人发了这条推特

87
00:04:49.548 --> 00:04:54.448
to a Gawker journalist. and he retweeted it to his 15.000 followers:
[AI] 对一个目瞪口呆的记者说。他把它转发给他的15000名追随者：

88
00:04:55.326 --> 00:04:57.692
[And now. a funny holiday joke from IAC's PR boss]
[AI] [现在，IAC公关部老板开的一个有趣的节日玩笑]

89
00:04:57.716 --> 00:04:59.679
And then it was like a bolt of lightning.
[AI] 然后就像一道闪电。

90
00:04:59.703 --> 00:05:02.205
A few weeks later. I talked to the Gawker journalist.
[AI] 几周后。我和Gawker记者谈过。

91
00:05:02.229 --> 00:05:05.917
I emailed him and asked him how it felt. and he said. "It felt delicious."
[AI] 我给他发了电子邮件，问他感觉如何。他说。“感觉很好吃。”

92
00:05:05.941 --> 00:05:08.823
And then he said. "But I'm sure she's fine."
[AI] 然后他说。“但我相信她很好。”

93
00:05:09.470 --> 00:05:12.581
But she wasn't fine. because while she slept.
[AI] 但她并不好。因为当她睡觉的时候。

94
00:05:12.605 --> 00:05:18.089
Twitter took control of her life and dismantled it piece by piece.
[AI] 推特控制了她的生活，并一块一块地摧毁了它。

95
00:05:18.967 --> 00:05:21.362
First there were the philanthropists:
[AI] 首先是慈善家：

96
00:05:21.386 --> 00:05:23.868
[If @JustineSacco's unfortunate words ... bother you.
[AI] [如果@JustineSacco的不幸话……会让你烦恼。

97
00:05:23.892 --> 00:05:26.039
join me in supporting @CARE's work in Africa.]
[AI] 与我一起支持@CARE在非洲的工作。]

98
00:05:26.063 --> 00:05:29.852
[In light of ... disgusting. racist tweet. I'm donating to @care today]
[AI] [鉴于……恶心。种族主义推特。我今天向@care捐款]

99
00:05:29.876 --> 00:05:31.367
Then came the beyond horrified:
[AI] 然后，惊骇的声音传来：

100
00:05:31.391 --> 00:05:36.582
[... no words for that horribly disgusting racist as fuck tweet from Justine Sacco. I am beyond horrified.]
[AI] […贾斯汀·萨科（Justine Sacco）那条令人厌恶的种族主义推特，我简直吓坏了。]

101
00:05:36.606 --> 00:05:38.859
Was anybody on Twitter that night? A few of you.
[AI] 那天晚上有人在推特上吗？你们中的一些人。

102
00:05:38.883 --> 00:05:42.353
Did Justine's joke overwhelm your Twitter feed the way it did mine?
[AI] 贾斯汀的笑话是否像我的一样压倒了你的推特？

103
00:05:42.377 --> 00:05:45.269
It did mine. and I thought what everybody thought that night.
[AI] 这是我的。我想的和那天晚上大家想的一样。

104
00:05:45.293 --> 00:05:48.381
which was. "Wow. somebody's screwed!
[AI] 是的。“哇，有人搞砸了！

105
00:05:48.405 --> 00:05:50.745
Somebody's life is about to get terrible!"
[AI] 有人的生活即将变得糟糕！"

106
00:05:50.769 --> 00:05:52.077
And I sat up in my bed.
[AI] 我在床上坐了起来。

107
00:05:52.101 --> 00:05:55.025
and I put the pillow behind my head.
[AI] 我把枕头放在脑后。

108
00:05:55.049 --> 00:06:00.296
and then I thought. I'm not entirely sure that joke was intended to be racist.
[AI] 然后我想。我不能完全肯定那个笑话是种族主义者开的。

109
00:06:00.320 --> 00:06:03.082
Maybe instead of gleefully flaunting her privilege.
[AI] 也许不是兴高采烈地炫耀她的特权。

110
00:06:03.106 --> 00:06:05.706
she was mocking the gleeful flaunting of privilege.
[AI] 她在嘲弄这种炫耀特权的行为。

111
00:06:05.730 --> 00:06:07.543
There's a comedy tradition of this.
[AI] 这是一个喜剧传统。

112
00:06:07.567 --> 00:06:11.255
like South Park or Colbert or Randy Newman.
[AI] 像南方公园、科尔伯特或兰迪·纽曼。

113
00:06:11.279 --> 00:06:15.724
Maybe Justine Sacco's crime was not being as good at it as Randy Newman.
[AI] 也许贾斯汀·萨科的罪行没有兰迪·纽曼那么擅长。

114
00:06:16.264 --> 00:06:19.184
In fact. when I met Justine a couple of weeks later in a bar.
[AI] 事实上几周后，我在酒吧遇到了贾斯汀。

115
00:06:19.208 --> 00:06:21.297
she was just crushed.
[AI] 她只是被压垮了。

116
00:06:21.321 --> 00:06:23.270
and I asked her to explain the joke.
[AI] 我请她解释这个笑话。

117
00:06:23.294 --> 00:06:26.929
and she said. "Living in America puts us in a bit of a bubble
[AI] 她说。“生活在美国让我们陷入了一点泡沫之中

118
00:06:26.953 --> 00:06:29.447
when it comes to what is going on in the Third World.
[AI] 当涉及到第三世界正在发生的事情时。

119
00:06:29.471 --> 00:06:31.668
I was making of fun of that bubble."
[AI] 我在取笑那个泡泡。"

120
00:06:32.668 --> 00:06:36.554
You know. another woman on Twitter that night. a New Statesman writer Helen Lewis.
[AI] 你知道的。那天晚上另一个女人在推特上。新政治家作家海伦·刘易斯。

121
00:06:36.578 --> 00:06:40.226
she reviewed my book on public shaming and wrote that she Tweeted that night.
[AI] 她回顾了我关于公众羞辱的书，并写道她那天晚上发了推特。

122
00:06:40.250 --> 00:06:43.540
"I'm not sure that her joke was intended to be racist."
[AI] “我不确定她的笑话是否有种族歧视的意图。”

123
00:06:43.564 --> 00:06:46.303
and she said straightaway she got a fury of Tweets saying.
[AI] 她马上说，她收到了一个愤怒的推特说。

124
00:06:46.327 --> 00:06:48.780
"Well. you're just a privileged bitch. too."
[AI] “嗯，你也是一个有特权的婊子。”

125
00:06:48.804 --> 00:06:51.040
And so to her shame. she wrote.
[AI] 让她感到羞耻的是。她写道。

126
00:06:51.064 --> 00:06:55.596
she shut up and watched as Justine's life got torn apart.
[AI] 她闭嘴，看着贾斯汀的生活支离破碎。

127
00:06:57.517 --> 00:06:59.326
It started to get darker:
[AI] 天开始变黑了：

128
00:06:59.350 --> 00:07:02.260
[Everyone go report this cunt @JustineSacco]
[AI] [每个人都去举报这个贱人@JustineSacco]

129
00:07:02.284 --> 00:07:04.870
Then came the calls for her to be fired.
[AI] 然后是要求解雇她的呼声。

130
00:07:04.894 --> 00:07:07.766
[Good luck with the job hunt in the new year. #GettingFired]
[AI] [祝你新年找工作好运。#被解雇了]

131
00:07:07.790 --> 00:07:13.076
Thousands of people around the world decided it was their duty to get her fired.
[AI] 全世界成千上万的人认为解雇她是他们的责任。

132
00:07:13.100 --> 00:07:16.270
[@JustineSacco last tweet of your career. #SorryNotSorry
[AI] [@JustineSacco你职业生涯的最后一条tweet.#对不起

133
00:07:16.982 --> 00:07:20.157
Corporations got involved. hoping to sell their products
[AI] 公司参与其中。希望销售他们的产品

134
00:07:20.181 --> 00:07:22.538
on the back of Justine's annihilation:
[AI] 在贾斯汀被歼灭的背后：

135
00:07:22.562 --> 00:07:25.779
[Next time you plan to tweet something stupid before you take off.
[AI] [下次你打算在起飞前发些愚蠢的推特时。

136
00:07:25.803 --> 00:07:27.954
make sure you are getting on a @Gogo flight!]
[AI] 确保您乘坐的是@Gogo航班！]

137
00:07:27.978 --> 00:07:30.384
(Laughter)
[AI] （众笑）

138
00:07:30.408 --> 00:07:33.014
A lot of companies were making good money that night.
[AI] 那天晚上很多公司都赚了很多钱。

139
00:07:33.038 --> 00:07:36.955
You know. Justine's name was normally Googled 40 times a month.
[AI] 你知道的。贾斯汀的名字通常每月被谷歌搜索40次。

140
00:07:36.979 --> 00:07:40.307
That month. between December the 20th and the end of December.
[AI] 那个月。从12月20日到12月底。

141
00:07:40.331 --> 00:07:45.084
her name was Googled 1.220.000 times.
[AI] 她的名字被谷歌搜索了1220000次。

142
00:07:45.713 --> 00:07:49.238
And one Internet economist told me that that meant that Google made
[AI] 一位互联网经济学家告诉我，这意味着谷歌

143
00:07:49.262 --> 00:07:54.272
somewhere between 120.000 dollars and 468.000 dollars
[AI] 大约在12万到46.8万美元之间

144
00:07:54.296 --> 00:07:58.362
from Justine's annihilation. whereas those of us doing the actual shaming --
[AI] 从贾斯汀的毁灭中。而我们中那些真正感到羞耻的人--

145
00:07:58.386 --> 00:07:59.540
we got nothing.
[AI] 我们什么都没有。

146
00:07:59.564 --> 00:08:00.564
(Laughter)
[AI] （众笑）

147
00:08:00.588 --> 00:08:04.038
We were like unpaid shaming interns for Google.
[AI] 我们就像谷歌的无薪实习生。

148
00:08:04.062 --> 00:08:07.349
(Laughter)
[AI] （众笑）

149
00:08:07.373 --> 00:08:09.769
And then came the trolls:
[AI] 然后来了巨魔：

150
00:08:09.793 --> 00:08:12.524
[I'm actually kind of hoping Justine Sacco gets aids? lol]
[AI] [我真的有点希望贾斯汀·萨科得了艾滋病？哈哈]

151
00:08:12.548 --> 00:08:13.954
Somebody else on that wrote.
[AI] 那上面有人写的。

152
00:08:13.978 --> 00:08:17.227
"Somebody HIV-positive should rape this bitch and then we'll find out
[AI] “HIV阳性的人应该强奸这个婊子，然后我们会发现的

153
00:08:17.251 --> 00:08:19.330
if her skin color protects her from AIDS."
[AI] 如果她的肤色能保护她免受艾滋病的侵害。"

154
00:08:19.354 --> 00:08:21.933
And that person got a free pass.
[AI] 那个人得到了一张免费通行证。

155
00:08:21.957 --> 00:08:24.044
Nobody went after that person.
[AI] 没有人去追那个人。

156
00:08:24.068 --> 00:08:26.703
We were all so excited about destroying Justine.
[AI] 我们都很兴奋能毁掉贾斯汀。

157
00:08:26.727 --> 00:08:29.354
and our shaming brains are so simple-minded.
[AI] 我们羞耻的大脑是如此简单。

158
00:08:29.378 --> 00:08:31.763
that we couldn't also handle destroying somebody
[AI] 我们也无法处理毁灭某人的问题

159
00:08:31.787 --> 00:08:34.724
who was inappropriately destroying Justine.
[AI] 他不恰当地摧毁了贾斯汀。

160
00:08:35.515 --> 00:08:39.043
Justine was really uniting a lot of disparate groups that night.
[AI] 那天晚上，贾斯汀真的团结了很多不同的团体。

161
00:08:39.067 --> 00:08:42.003
from philanthropists to "rape the bitch."
[AI] 从慈善家到“强奸婊子”

162
00:08:42.487 --> 00:08:46.326
[@JustineSacco I hope you get fired! You demented bitch...
[AI] [@JustineSacco我希望你被炒鱿鱼！你这个疯婊子。。。

163
00:08:46.350 --> 00:08:49.938
Just let the world know you're planning to ride bare back while in Africa.]
[AI] 只要让全世界都知道你打算在非洲裸奔。]

164
00:08:49.962 --> 00:08:51.987
Women always have it worse than men.
[AI] 女人总是比男人更糟糕。

165
00:08:52.011 --> 00:08:55.112
When a man gets shamed. it's. "I'm going to get you fired."
[AI] 当一个人感到羞耻时。“我会让你被炒鱿鱼。”

166
00:08:55.136 --> 00:08:56.834
When a woman gets shamed. it's.
[AI] 当一个女人感到羞耻时。是的。

167
00:08:56.858 --> 00:09:01.739
"I'm going to get you fired and raped and cut out your uterus."
[AI] “我要让你被炒鱿鱼，被强奸，然后切除你的子宫。”

168
00:09:01.763 --> 00:09:04.172
And then Justine's employers got involved:
[AI] 然后贾斯汀的雇主也参与了进来：

169
00:09:04.196 --> 00:09:07.502
[IAC on @JustineSacco tweet: This is an outrageous. offensive comment.
[AI] [IAC on@JustineSacco推特：这是一个令人愤怒的、冒犯性的评论。

170
00:09:07.526 --> 00:09:10.500
Employee in question currently unreachable on an intl flight.]
[AI] 在国际航班上无法联系到相关员工。]

171
00:09:10.524 --> 00:09:12.722
And that's when the anger turned to excitement:
[AI] 这时愤怒变成了激动：

172
00:09:12.746 --> 00:09:16.368
[All I want for Christmas is to see @JustineSacco's face when her plane lands
[AI] [圣诞节我只想看到@JustineSacco的飞机降落时的脸]

173
00:09:16.392 --> 00:09:18.393
and she checks her inbox/voicemail. #fired]
[AI] 她检查她的收件箱/语音信箱#解雇]

174
00:09:18.417 --> 00:09:21.108
[Oh man. @justinesacco is going to have the most painful
[AI] [哦，天哪。@justinesacco将会是最痛苦的

175
00:09:21.132 --> 00:09:23.531
phone-turning-on moment ever when her plane lands.]
[AI] 当她的飞机着陆时，手机一直开机。]

176
00:09:23.555 --> 00:09:26.971
[We are about to watch this @JustineSacco bitch get fired. In REAL time.
[AI] [我们马上就要看到这个@JustineSacco婊子被炒鱿鱼了。实时。

177
00:09:26.995 --> 00:09:29.019
Before she even KNOWS she's getting fired.]
[AI] 在她知道自己被解雇之前。]

178
00:09:29.043 --> 00:09:31.056
What we had was a delightful narrative arc.
[AI] 我们拥有的是一个令人愉快的叙述弧。

179
00:09:31.080 --> 00:09:32.905
We knew something that Justine didn't.
[AI] 我们知道一些贾斯汀不知道的事情。

180
00:09:32.929 --> 00:09:35.270
Can you think of anything less judicial than this?
[AI] 你能想出比这更不公正的办法吗？

181
00:09:35.294 --> 00:09:38.171
Justine was asleep on a plane and unable to explain herself.
[AI] 贾斯汀在飞机上睡着了，无法解释自己。

182
00:09:38.195 --> 00:09:41.758
and her inability was a huge part of the hilarity.
[AI] 她的无能是欢笑的一大部分。

183
00:09:42.349 --> 00:09:46.737
On Twitter that night. we were like toddlers crawling towards a gun.
[AI] 那天晚上在推特上。我们就像蹒跚学步的孩子，朝着枪爬去。

184
00:09:47.480 --> 00:09:52.737
Somebody worked out exactly which plane she was on. so they linked to a flight tracker website.
[AI] 有人查出了她到底在哪架飞机上。所以他们链接到了一个飞行追踪网站。

185
00:09:52.761 --> 00:09:55.873
[British Airways Flight 43 On-time - arrives in 1 hour 34 minutes]
[AI] [英国航空公司43次航班准点-1小时34分钟后抵达]

186
00:09:55.897 --> 00:09:58.352
A hashtag began trending worldwide:
[AI] 一个标签开始在全球流行：

187
00:09:58.376 --> 00:10:00.978
# hasJustineLandedYet?
[AI] #你结婚了吗？

188
00:10:01.002 --> 00:10:03.168
[It is kinda wild to see someone self-destruct
[AI] 看到有人自毁有点疯狂

189
00:10:03.192 --> 00:10:05.915
without them even being aware of it. #hasJustineLandedYet]
[AI] 他们甚至都不知道#还没有]

190
00:10:05.939 --> 00:10:09.333
[Seriously. I just want to go home to go to bed. but everyone at the bar
[AI] 说真的，我只是想回家睡觉，但酒吧里的每个人

191
00:10:09.357 --> 00:10:12.317
is SO into #HasJustineLandedYet. Can't look away. Can't leave.]
[AI] 他现在还很投入。不能把目光移开。我不能离开

192
00:10:12.341 --> 00:10:15.827
[#HasJustineLandedYet may be the best thing to happen to my Friday night.]
[AI] [#hasjustineladed可能是发生在我周五晚上最好的事情。]

193
00:10:15.851 --> 00:10:18.954
[Is no one in Cape Town going to the airport to tweet her arrival?
[AI] [开普敦没有人去机场推特她的到来吗？

194
00:10:18.978 --> 00:10:20.697
Come on. twitter! I'd like pictures]
[AI] 来吧啁啾我想要照片]

195
00:10:20.721 --> 00:10:22.237
And guess what? Yes there was.
[AI] 你猜怎么着？是的，有。

196
00:10:22.261 --> 00:10:25.127
[@JustineSacco HAS in fact landed at Cape Town international.
[AI] [@JustineSacco实际上已经登陆开普敦国际机场。

197
00:10:25.151 --> 00:10:27.683
And if you want to know what it looks like to discover
[AI] 如果你想知道它是什么样子的发现

198
00:10:27.707 --> 00:10:31.282
that you've just been torn to shreds because of a misconstrued liberal joke.
[AI] 你刚刚因为一个被误解的自由主义笑话而被撕成碎片。

199
00:10:31.306 --> 00:10:33.314
not by trolls. but by nice people like us.
[AI] 不是巨魔干的。但是像我们这样的好人。

200
00:10:33.338 --> 00:10:34.884
this is what it looks like:
[AI] 这就是它看起来的样子：

201
00:10:34.908 --> 00:10:37.562
[... She's decided to wear sunnies as a disguise.]
[AI] […她决定戴太阳眼镜作为伪装。]

202
00:10:37.586 --> 00:10:39.039
So why did we do it?
[AI] 那我们为什么要这么做？

203
00:10:39.753 --> 00:10:42.654
I think some people were genuinely upset.
[AI] 我想有些人真的很难过。

204
00:10:42.678 --> 00:10:44.106
but I think for other people.
[AI] 但我认为对其他人来说。

205
00:10:44.130 --> 00:10:47.153
it's because Twitter is basically a mutual approval machine.
[AI] 这是因为Twitter基本上是一个相互认可的机器。

206
00:10:47.177 --> 00:10:50.096
We surround ourselves with people who feel the same way we do.
[AI] 我们周围的人和我们的感觉一样。

207
00:10:50.120 --> 00:10:51.383
and we approve each other.
[AI] 我们互相认可。

208
00:10:51.407 --> 00:10:53.058
and that's a really good feeling.
[AI] 这是一种非常好的感觉。

209
00:10:53.082 --> 00:10:55.730
And if somebody gets in the way. we screen them out.
[AI] 如果有人挡了路。我们把他们筛选出来。

210
00:10:55.754 --> 00:10:57.841
And do you know what that's the opposite of?
[AI] 你知道那是什么的对立面吗？

211
00:10:57.865 --> 00:10:59.606
It's the opposite of democracy.
[AI] 这是民主的反面。

212
00:11:00.156 --> 00:11:04.153
We wanted to show that we cared about people dying of AIDS in Africa.
[AI] 我们想表明我们关心非洲死于艾滋病的人。

213
00:11:04.177 --> 00:11:08.184
Our desire to be seen to be compassionate is what led us to commit
[AI] 我们渴望被视为富有同情心的人，这正是我们做出承诺的原因

214
00:11:08.208 --> 00:11:11.253
this profoundly un-compassionate act.
[AI] 这是一种极不富有同情心的行为。

215
00:11:11.707 --> 00:11:14.237
As Meghan O'Gieblyn wrote in the Boston Review.
[AI] 正如Meghan O'Gieblyn在《波士顿评论》中写道的那样。

216
00:11:14.261 --> 00:11:18.672
"This isn't social justice. It's a cathartic alternative."
[AI] “这不是社会正义，而是一种宣泄方式。”

217
00:11:19.506 --> 00:11:20.705
For the past three years.
[AI] 过去三年。

218
00:11:20.729 --> 00:11:24.007
I've been going around the world meeting people like Justine Sacco --
[AI] 我一直在世界各地会见像贾斯汀·萨科这样的人--

219
00:11:24.031 --> 00:11:26.815
and believe me. there's a lot of people like Justine Sacco.
[AI] 相信我。有很多人喜欢贾斯汀·萨科。

220
00:11:26.839 --> 00:11:28.545
There's more every day.
[AI] 每天都有更多。

221
00:11:28.569 --> 00:11:31.861
And we want to think they're fine. but they're not fine.
[AI] 我们认为他们很好。但是他们不好。

222
00:11:31.885 --> 00:11:34.020
The people I met were mangled.
[AI] 我遇到的人都被弄坏了。

223
00:11:34.044 --> 00:11:35.885
They talked to me about depression.
[AI] 他们跟我谈过抑郁症。

224
00:11:35.909 --> 00:11:39.825
and anxiety and insomnia and suicidal thoughts.
[AI] 焦虑、失眠和自杀念头。

225
00:11:39.849 --> 00:11:44.588
One woman I talked to. who also told a joke that landed badly.
[AI] 我和一个女人谈过。他还讲了一个笑话，结果很糟糕。

226
00:11:44.612 --> 00:11:46.826
she stayed home for a year and a half.
[AI] 她在家呆了一年半。

227
00:11:47.247 --> 00:11:51.689
Before that. she worked with adults with learning difficulties.
[AI] 在那之前。她与有学习困难的成年人一起工作。

228
00:11:51.713 --> 00:11:54.151
and was apparently really good at her job.
[AI] 很明显她很擅长她的工作。

229
00:11:55.126 --> 00:11:58.995
Justine was fired. of course. because social media demanded it.
[AI] 贾斯汀被解雇了。当然因为社交媒体需要它。

230
00:11:59.427 --> 00:12:01.171
But it was worse than that.
[AI] 但比这更糟糕。

231
00:12:01.195 --> 00:12:03.154
She was losing herself.
[AI] 她迷失了自我。

232
00:12:03.178 --> 00:12:07.238
She was waking up in the middle of the night. forgetting who she was.
[AI] 她半夜醒来。忘了她是谁。

233
00:12:07.899 --> 00:12:11.855
She was got because she was perceived to have misused her privilege.
[AI] 她被逮捕是因为人们认为她滥用了自己的特权。

234
00:12:11.879 --> 00:12:15.440
And of course. that's a much better thing to get people for than the things
[AI] 当然了。这是一个更好的事情，让人们比的东西

235
00:12:15.464 --> 00:12:18.624
we used to get people for. like having children out of wedlock.
[AI] 我们过去常让人来帮忙。比如私生子。

236
00:12:18.648 --> 00:12:21.479
But the phrase "misuse of privilege" is becoming a free pass
[AI] 但“滥用特权”一词正在成为一种免费通行证

237
00:12:21.503 --> 00:12:24.931
to tear apart pretty much anybody we choose to.
[AI] 把我们选择的任何人都撕碎。

238
00:12:24.955 --> 00:12:27.261
It's becoming a devalued term.
[AI] 它正在成为一个贬值的术语。

239
00:12:27.285 --> 00:12:30.270
and it's making us lose our capacity for empathy
[AI] 这让我们失去了移情的能力

240
00:12:30.294 --> 00:12:35.214
and for distinguishing between serious and unserious transgressions.
[AI] 以及区分严重和不严重的违法行为。

241
00:12:36.154 --> 00:12:39.683
Justine had 170 Twitter followers. and so to make it work.
[AI] 贾斯汀有170名推特粉丝。为了让它发挥作用。

242
00:12:39.707 --> 00:12:41.676
she had to be fictionalized.
[AI] 她必须被虚构出来。

243
00:12:41.700 --> 00:12:46.515
Word got around that she was the daughter the mining billionaire Desmond Sacco.
[AI] 有消息说她是矿业亿万富翁德斯蒙德·萨科的女儿。

244
00:12:46.539 --> 00:12:50.163
[Let us not be fooled by #JustineSacco her father is a SA mining billionaire.
[AI] [让我们不要被贾斯汀萨克愚弄，她父亲是南非矿业的亿万富翁。

245
00:12:50.187 --> 00:12:52.242
She's not sorry. And neither is her father.]
[AI] 她并不后悔。她的父亲也不是

246
00:12:52.266 --> 00:12:54.089
I thought that was true about Justine.
[AI] 我认为贾斯汀是这样的。

247
00:12:54.113 --> 00:12:57.451
until I met her at a bar. and I asked her about her billionaire father.
[AI] 直到我在酒吧遇到她。我问她关于她亿万富翁父亲的事。

248
00:12:57.475 --> 00:12:59.388
and she said. "My father sells carpets."
[AI] 她说。“我父亲卖地毯。”

249
00:12:59.412 --> 00:13:01.569
And I think back on the early days of Twitter.
[AI] 我回想起Twitter的早期。

250
00:13:01.593 --> 00:13:04.323
when people would admit shameful secrets about themselves.
[AI] 当人们承认自己的可耻秘密时。

251
00:13:04.347 --> 00:13:07.273
and other people would say. "Oh my God. I'm exactly the same."
[AI] 其他人会说。“哦，我的天啊，我完全一样。”

252
00:13:07.297 --> 00:13:11.470
These days. the hunt is on for people's shameful secrets.
[AI] 这些天。人们正在寻找可耻的秘密。

253
00:13:11.494 --> 00:13:13.536
You can lead a good. ethical life.
[AI] 你可以领导一个好的团队。道德生活。

254
00:13:13.560 --> 00:13:17.994
but some bad phraseology in a Tweet can overwhelm it all.
[AI] 但Tweet中的一些糟糕措辞可能会压倒一切。

255
00:13:18.018 --> 00:13:21.002
become a clue to your secret inner evil.
[AI] 成为你内心秘密邪恶的线索。

256
00:13:21.617 --> 00:13:24.056
Maybe there's two types of people in the world:
[AI] 也许世界上有两种人：

257
00:13:24.080 --> 00:13:27.607
those people who favor humans over ideology.
[AI] 那些偏爱人类而不是意识形态的人。

258
00:13:27.631 --> 00:13:30.537
and those people who favor ideology over humans.
[AI] 还有那些偏爱意识形态甚于人类的人。

259
00:13:30.927 --> 00:13:33.575
I favor humans over ideology.
[AI] 我喜欢人类胜过意识形态。

260
00:13:33.599 --> 00:13:36.360
but right now. the ideologues are winning.
[AI] 但是现在。理论家们正在获胜。

261
00:13:36.384 --> 00:13:41.054
and they're creating a stage for constant artificial high dramas
[AI] 他们正在创造一个舞台，为不断的人造高潮创造舞台

262
00:13:41.078 --> 00:13:43.506
where everybody's either a magnificent hero
[AI] 每个人都是伟大的英雄

263
00:13:43.530 --> 00:13:45.138
or a sickening villain.
[AI] 或者一个令人作呕的恶棍。

264
00:13:45.162 --> 00:13:48.179
even though we know that's not true about our fellow humans.
[AI] 尽管我们知道我们的同胞不是这样的。

265
00:13:48.203 --> 00:13:52.189
What's true is that we are clever and stupid;
[AI] 事实上，我们既聪明又愚蠢；

266
00:13:52.213 --> 00:13:55.399
what's true is that we're grey areas.
[AI] 事实上，我们是灰色地带。

267
00:13:55.423 --> 00:13:59.721
The great thing about social media was how it gave a voice to voiceless people.
[AI] 社交媒体的伟大之处在于它如何让无声的人有发言权。

268
00:13:59.745 --> 00:14:02.399
but we're now creating a surveillance society.
[AI] 但我们现在正在创建一个监视社会。

269
00:14:02.423 --> 00:14:06.773
where the smartest way to survive is to go back to being voiceless.
[AI] 最聪明的生存方式是回到无声状态。

270
00:14:07.243 --> 00:14:08.676
Let's not do that.
[AI] 我们不要那样做。

271
00:14:08.700 --> 00:14:09.852
Thank you.
[AI] 非常感谢。

272
00:14:09.876 --> 00:14:15.594
(Applause)
[AI] （掌声）

273
00:14:21.230 --> 00:14:22.715
Bruno Giussani: Thank you. Jon.
[AI] 布鲁诺·朱萨尼：谢谢。乔恩。

274
00:14:22.739 --> 00:14:23.985
Jon Ronson: Thanks. Bruno.
[AI] 乔恩·朗森：谢谢。布鲁诺。

275
00:14:24.009 --> 00:14:25.183
BG: Don't go away.
[AI] BG：别走开。

276
00:14:26.759 --> 00:14:28.554
What strikes me about Justine's story
[AI] 贾斯汀的故事给我留下了什么印象

277
00:14:28.578 --> 00:14:31.011
is also the fact that if you Google her name today.
[AI] 事实上，如果你今天用谷歌搜索她的名字。

278
00:14:31.035 --> 00:14:33.782
this story covers the first 100 pages of Google results --
[AI] 这个故事涵盖了谷歌搜索结果的前100页--

279
00:14:33.806 --> 00:14:36.018
there is nothing else about her.
[AI] 她身上没有别的东西。

280
00:14:36.042 --> 00:14:38.630
In your book. you mention another story
[AI] 在你的书里。你提到另一个故事

281
00:14:38.654 --> 00:14:43.185
of another victim who actually got taken on by a reputation management firm.
[AI] 另一个受害者被一家声誉管理公司雇佣。

282
00:14:43.209 --> 00:14:48.293
and by creating blogs and posting nice. innocuous stories about her love for cats
[AI] 通过创建博客和发布好消息。关于她爱猫的无伤大雅的故事

283
00:14:48.317 --> 00:14:51.033
and holidays and stuff. managed to get the story
[AI] 还有假期之类的。设法得到了这个故事

284
00:14:51.057 --> 00:14:54.980
off the first couple pages of Google results. but it didn't last long.
[AI] 在谷歌搜索结果的前几页。但没持续多久。

285
00:14:55.004 --> 00:14:59.957
A couple of weeks later. they started creeping back up to the top result.
[AI] 几周后。他们开始慢慢恢复到最高成绩。

286
00:14:59.981 --> 00:15:01.929
Is this a totally lost battle?
[AI] 这是一场彻底失败的战斗吗？

287
00:15:02.303 --> 00:15:05.137
Jon Ronson: You know. I think the very best thing we can do.
[AI] 乔恩·朗森：你知道。我认为我们能做的最好的事情。

288
00:15:05.161 --> 00:15:09.735
if you see a kind of unfair or an ambiguous shaming.
[AI] 如果你看到一种不公平或模棱两可的羞辱。

289
00:15:09.759 --> 00:15:13.159
is to speak up. because I think the worst thing that happened to Justine
[AI] 就是大声说出来。因为我认为发生在Justine身上最糟糕的事情

290
00:15:13.183 --> 00:15:16.199
was that nobody supported her -- like. everyone was against her.
[AI] 就是没有人支持她，比如说。大家都反对她。

291
00:15:16.223 --> 00:15:17.948
and that is profoundly traumatizing.
[AI] 这让人深受创伤。

292
00:15:17.972 --> 00:15:21.794
to be told by tens of thousands of people that you need to get out.
[AI] 成千上万的人告诉你，你需要离开。

293
00:15:21.818 --> 00:15:25.908
But if a shaming happens and there's a babble of voices. like in a democracy.
[AI] 但是如果一个羞辱发生了，会有一大堆的声音。就像在民主国家一样。

294
00:15:25.932 --> 00:15:29.028
where people are discussing it. I think that's much less damaging.
[AI] 人们正在讨论的地方。我认为这样的破坏性要小得多。

295
00:15:29.052 --> 00:15:30.679
So I think that's the way forward.
[AI] 所以我认为这是前进的方向。

296
00:15:30.703 --> 00:15:33.299
but it's hard. because if you do stand up for somebody.
[AI] 但这很难。因为如果你真的支持某人。

297
00:15:33.323 --> 00:15:35.019
it's incredibly unpleasant.
[AI] 这令人难以置信的不愉快。

298
00:15:35.043 --> 00:15:36.963
BG: So let's talk about your experience.
[AI] BG：那么让我们谈谈你的经历。

299
00:15:36.987 --> 00:15:38.995
because you stood up by writing this book.
[AI] 因为你写了这本书站了起来。

300
00:15:39.019 --> 00:15:41.608
By the way. it's mandatory reading for everybody. okay?
[AI] 顺便说一句这是每个人的必读课。可以

301
00:15:41.632 --> 00:15:45.942
You stood up because the book actually puts the spotlight on shamers.
[AI] 你站起来是因为这本书实际上把焦点放在了羞耻者身上。

302
00:15:45.966 --> 00:15:48.998
And I assume you didn't only have friendly reactions on Twitter.
[AI] 我猜你在推特上不仅有友好的反应。

303
00:15:49.022 --> 00:15:51.702
JR: It didn't go down that well with some people.
[AI] JR：有些人觉得不太好。

304
00:15:51.726 --> 00:15:52.727
(Laughter)
[AI] （众笑）

305
00:15:52.751 --> 00:15:54.855
I mean. you don't want to just concentrate --
[AI] 我是说。你不想只集中注意力--

306
00:15:54.879 --> 00:15:58.276
because lots of people understood. and were really nice about the book.
[AI] 因为很多人都明白。我们对这本书很满意。

307
00:15:58.300 --> 00:16:01.653
But yeah. for 30 years I've been writing stories about abuses of power.
[AI] 但是是的。30年来，我一直在写关于滥用权力的故事。

308
00:16:01.677 --> 00:16:04.957
and when I say the powerful people over there in the military.
[AI] 当我说军队里有权势的人时。

309
00:16:04.981 --> 00:16:07.749
or in the pharmaceutical industry. everybody applauds me.
[AI] 或者在制药行业。大家都为我鼓掌。

310
00:16:07.773 --> 00:16:12.148
As soon as I say. "We are the powerful people abusing our power now."
[AI] 只要我说。“我们现在是滥用权力的有权势的人。”

311
00:16:12.172 --> 00:16:14.896
I get people saying. "Well you must be a racist too."
[AI] 我让人们说。“你一定也是个种族主义者。”

312
00:16:14.920 --> 00:16:17.595
BG: So the other night -- yesterday -- we were at dinner.
[AI] BG：那么前几天晚上——昨天——我们在吃饭。

313
00:16:17.619 --> 00:16:19.534
and there were two discussions going on.
[AI] 有两次讨论正在进行。

314
00:16:19.558 --> 00:16:22.606
On one side you were talking with people around the table --
[AI] 一方面，你和桌子周围的人交谈--

315
00:16:22.630 --> 00:16:24.793
and that was a nice. constructive discussion.
[AI] 这是一个很好的机会。建设性讨论。

316
00:16:24.817 --> 00:16:27.164
On the other. every time you turned to your phone.
[AI] 另一方面。每次你打开手机。

317
00:16:27.188 --> 00:16:28.749
there is this deluge of insults.
[AI] 有这么多的侮辱。

318
00:16:28.773 --> 00:16:32.164
JR: Yeah. This happened last night. We had like a TED dinner last night.
[AI] JR：是的。这是昨晚发生的。昨晚我们吃了一顿TED晚餐。

319
00:16:32.188 --> 00:16:35.988
We were chatting and it was lovely and nice. and I decided to check Twitter.
[AI] 我们在聊天，感觉很好。我决定查看推特。

320
00:16:36.012 --> 00:16:38.132
Somebody said. "You are a white supremacist."
[AI] 有人说。“你是白人至上主义者。”

321
00:16:38.156 --> 00:16:41.130
And then I went back and had a nice conversation with somebody.
[AI] 然后我回去和某人进行了一次愉快的谈话。

322
00:16:41.154 --> 00:16:42.695
and then I went back to Twitter.
[AI] 然后我又回到推特上。

323
00:16:42.719 --> 00:16:45.807
somebody said my very existence made the world a worse place.
[AI] 有人说我的存在让世界变得更糟。

324
00:16:45.831 --> 00:16:48.578
My friend Adam Curtis says
[AI] 我的朋友亚当·柯蒂斯说

325
00:16:48.602 --> 00:16:52.410
that maybe the Internet is like a John Carpenter movie from the 1980s.
[AI] 也许互联网就像上世纪80年代约翰·卡彭特的电影。

326
00:16:52.434 --> 00:16:55.475
when eventually everyone will start screaming at each other
[AI] 最终每个人都会开始互相尖叫

327
00:16:55.499 --> 00:17:00.049
and shooting each other. and then eventually everybody would flee to somewhere safer.
[AI] 还有互相射击。然后最终每个人都会逃到更安全的地方。

328
00:17:00.073 --> 00:17:03.973
and I'm starting to think of that as a really nice option.
[AI] 我开始认为这是一个非常好的选择。

329
00:17:03.997 --> 00:17:05.950
BG: Jon. thank you. JR: Thank you. Bruno.
[AI] 背景：乔恩。非常感谢。JR：谢谢。布鲁诺。

330
00:17:05.974 --> 00:17:09.972
(Applause)
[AI] （掌声）