WEBVTT

1
00:00:12.540 --> 00:00:16.820
People have been using media to talk about sex for a long time.
人们借助各种媒体来谈性已经有着很长的历史了

2
00:00:17.420 --> 00:00:20.860
Love letters, phone sex, racy Polaroids.
比如说情书、电话性爱以及裸照

3
00:00:21.300 --> 00:00:27.356
There's even a story of a girl who eloped with a man that she met over the telegraph
甚至有这样一个女孩与一个通过电报认识的男子私奔的故事

4
00:00:27.380 --> 00:00:29.020
in 1886.
在1886年

5
00:00:30.380 --> 00:00:35.476
Today we have sexting, and I am a sexting expert.
直到今天，我们演变出了一种短信称之为[色情短信]我是这方面的专家

6
00:00:35.500 --> 00:00:37.380
Not an expert sexter.
我作为专家是研究它的可不擅长于发这个

7
00:00:38.620 --> 00:00:42.796
Though, I do know what this means -- I think you do too.
嗯，我想在座的各位和我一样十分清楚这代表着什么

8
00:00:42.820 --> 00:00:44.195
[it's a penis]
（这指代着男性的阴茎）

9
00:00:44.220 --> 00:00:46.580
(Laughter)
（观众笑声）

10
00:00:48.180 --> 00:00:54.516
I have been studying sexting since the media attention to it began in 2008.
自从2008年媒体开始关注以来我一直致力于研究色情短信

11
00:00:54.540 --> 00:00:57.516
I wrote a book on the moral panic about sexting.
我撰写了一本书专门讨论色情短信的出现所引起的道德恐慌

12
00:00:57.540 --> 00:00:59.156
And here's what I found:
这是我发现的：

13
00:00:59.180 --> 00:01:02.396
most people are worrying about the wrong thing.
大部分的人都在担心错误的事情

14
00:01:02.420 --> 00:01:06.596
They're trying to just prevent sexting from happening entirely.
他们试图从根源上防止色情短信的产生

15
00:01:06.620 --> 00:01:08.156
But let me ask you this:
但是我不禁要问：

16
00:01:08.180 --> 00:01:13.036
As long as it's completely consensual, what's the problem with sexting?
只要是完全自愿的色情短信的问题在哪儿？

17
00:01:13.060 --> 00:01:17.076
People are into all sorts of things that you may not be into,
人们试图去理清各种各样的事甚至是与自己毫不相干的事

18
00:01:17.100 --> 00:01:19.396
like blue cheese or cilantro.
比如蓝奶酪或香菜

19
00:01:19.420 --> 00:01:21.060
(Laughter)
（观众笑声）

20
00:01:22.420 --> 00:01:26.556
Sexting is certainly risky, like anything that's fun,
色情短信和其它好玩的事情一样是绝对有风险性的

21
00:01:26.580 --> 00:01:33.276
but as long as you're not sending an image to someone who doesn't want to receive it,
但是只要你给愿意接受的人们发

22
00:01:33.300 --> 00:01:35.076
there's no harm.
也未尝不可

23
00:01:35.100 --> 00:01:37.716
What I do think is a serious problem
我认为这其中一个严重的问题

24
00:01:37.740 --> 00:01:42.540
is when people share private images of others without their permission.
是人们未经他人同意分享他人的隐私照片

25
00:01:43.180 --> 00:01:45.516
And instead of worrying about sexting,
与其忧心于色情短信本身

26
00:01:45.540 --> 00:01:50.100
what I think we need to do is think a lot more about digital privacy.
我想我们该更关注的是数字时代的个人隐私

27
00:01:50.700 --> 00:01:52.900
The key is consent.
关键是同意

28
00:01:53.500 --> 00:01:56.796
Right now most people are thinking about sexting
现在很多人在想着色情短信本身

29
00:01:56.820 --> 00:01:59.780
without really thinking about consent at all.
而完全忽略了“他人的同意”

30
00:02:00.220 --> 00:02:03.900
Did you know that we currently criminalize teen sexting?
你们知道我们现在在将青少年发送色情短信违法化吗？

31
00:02:05.220 --> 00:02:08.676
It can be a crime because it counts as child pornography,
它可以是一个罪犯是由于它可以被当作儿童色情

32
00:02:08.700 --> 00:02:11.556
if there's an image of someone under 18,
如果有一个当事人18岁以下的照片

33
00:02:11.580 --> 00:02:17.140
and it doesn't even matter if they took that image of themselves and shared it willingly.
是否他们自愿拍照以及自愿分享照片是无关紧要的

34
00:02:17.620 --> 00:02:20.596
So we end up with this bizarre legal situation
结果我们就有了这种怪异的法律情况

35
00:02:20.620 --> 00:02:25.156
where two 17-year-olds can legally have sex in most US states
即在美国大多数州两个17岁的孩子可以合法性交

36
00:02:25.180 --> 00:02:27.060
but they can't photograph it.
但不能把它拍出来

37
00:02:28.380 --> 00:02:32.636
Some states have also tried passing sexting misdemeanor laws
一些州还试图对色情短信立法

38
00:02:32.660 --> 00:02:35.676
but these laws repeat the same problem
但是这些立法都重复了同样的问题

39
00:02:35.700 --> 00:02:39.460
because they still make consensual sexting illegal.
因为他们仍然使得两厢情愿的性短信违法

40
00:02:40.340 --> 00:02:46.356
It doesn't make sense to try to ban all sexting to try to address privacy violations.
通过禁止所有形式的色情短信来试图解决隐私侵权问题其实都是徒劳

41
00:02:46.380 --> 00:02:47.876
This is kind of like saying,
这种做法就像是

42
00:02:47.900 --> 00:02:53.340
let's solve the problem of date rape by just making dating completely illegal.
让我们通过宣布约会违法来解决约会强奸的问题

43
00:02:54.940 --> 00:03:00.316
Most teens don't get arrested for sexting, but can you guess who does?
大部分青少年不会因发送色情短信而被捕不过你们能猜到谁被捕了？

44
00:03:00.340 --> 00:03:05.316
It's often teens who are disliked by their partner's parents.
就是那些不被发送色情短信的对象的父母喜欢的人

45
00:03:05.340 --> 00:03:10.140
And this can be because of class bias, racism or homophobia.
这也许源于阶层差异种族歧视以及对同性恋的憎恶

46
00:03:10.780 --> 00:03:13.556
Most prosecutors are, of course, smart enough
大部分的检举人还很明智

47
00:03:13.580 --> 00:03:19.060
not to use child pornography charges against teenagers, but some do.
不对青少年以儿童色情罪起诉但是有一些人这么做

48
00:03:19.540 --> 00:03:23.196
According to researchers at the University of New Hampshire
根据新罕布什尔大学的调查研究

49
00:03:23.220 --> 00:03:28.876
seven percent of all child pornography possession arrests are teens,
因儿童色情被捕的人群中有百分之七都是青少年

50
00:03:28.900 --> 00:03:31.900
sexting consensually with other teens.
而他们都是两厢情愿的发送色情短信

51
00:03:33.300 --> 00:03:35.836
Child pornography is a serious crime,
儿童色情是重罪

52
00:03:35.860 --> 00:03:39.540
but it's just not the same thing as teen sexting.
但是与青少年的色情短信还是有所差异的

53
00:03:40.860 --> 00:03:44.276
Parents and educators are also responding to sexting
很多父母和教育工作者也都往往不假思索的

54
00:03:44.300 --> 00:03:47.436
without really thinking too much about consent.
对色情短信作出反应而不去认真思考同意的问题

55
00:03:47.460 --> 00:03:51.580
Their message to teens is often: just don't do it.
他们往往冷冰冰的告诉孩子们不要这么做

56
00:03:52.020 --> 00:03:55.516
And I totally get it -- there are serious legal risks
我也完全明白这其中包含很严重的法律风险

57
00:03:55.540 --> 00:03:59.196
and of course, that potential for privacy violations.
当然，也可能触犯私人隐私

58
00:03:59.220 --> 00:04:00.476
And when you were a teen,
你们还是青少年的时候

59
00:04:00.500 --> 00:04:03.900
I'm sure you did exactly as you were told, right?
肯定也按吩咐办事，对吧？

60
00:04:05.260 --> 00:04:08.716
You're probably thinking, my kid would never sext.
你可能认为我的孩子从不发色情短信

61
00:04:08.740 --> 00:04:12.196
And that's true, your little angel may not be sexting
的确，你的小宝贝可能不会发色情短信

62
00:04:12.220 --> 00:04:17.740
because only 33 percent of 16- and 17-year-olds are sexting.
因为16到17岁这个年龄段里只有百分之三十三的人会发送色情短信

63
00:04:19.020 --> 00:04:23.636
But, sorry, by the time they're older, odds are they will be sexting.
但是，当他们长大些概率是他们会发送色情短信

64
00:04:23.660 --> 00:04:29.860
Every study I've seen puts the rate above 50 percent for 18- to 24-year-olds.
每一个我所看过的研究显示18到24岁人群中发送色情短信的人数过半

65
00:04:30.540 --> 00:04:33.596
And most of the time, nothing goes wrong.
大多情况下，这也没有出现什么问题

66
00:04:33.620 --> 00:04:38.996
People ask me all the time things like, isn't sexting just so dangerous, though?
人们总问我发色情短信不是很危险吗？

67
00:04:39.020 --> 00:04:42.596
It's like you wouldn't leave your wallet on a park bench
就像你不会把你的钱包落在公园椅子上

68
00:04:42.620 --> 00:04:46.060
and you expect it's going to get stolen if you do that, right?
因为你觉得这样做钱包会被偷，对吧？

69
00:04:46.700 --> 00:04:48.156
Here's how I think about it:
我觉得是这样的：

70
00:04:48.180 --> 00:04:52.116
sexting is like leaving your wallet at your boyfriend's house.
发色情短信就如把钱包丢在了男友家里一样

71
00:04:52.140 --> 00:04:53.916
If you come back the next day
如果你第二天回来

72
00:04:53.940 --> 00:04:56.220
and all the money is just gone,
发现钱都没了的话

73
00:04:56.860 --> 00:04:58.980
you really need to dump that guy.
你真的可以把他甩了

74
00:04:59.510 --> 00:05:01.680
(Laughter)
（观众笑声）

75
00:05:03.180 --> 00:05:05.500
So instead of criminalizing sexting
所以，与其将发送色情短信违法化

76
00:05:05.540 --> 00:05:08.156
to try to prevent these privacy violations,
以此来试图防止隐私侵犯

77
00:05:08.180 --> 00:05:11.476
instead we need to make consent central
我们可以将同意当作

78
00:05:11.500 --> 00:05:15.580
to how we think about the circulation of our private information.
我们如何看待我们隐私信息的传播的中心

79
00:05:16.300 --> 00:05:20.556
Every new media technology raises privacy concerns.
每个新的媒体技术都会引起隐私问题

80
00:05:20.580 --> 00:05:25.196
In fact, in the US the very first major debates about privacy
实际上，在美国关于隐私的最初辩论

81
00:05:25.220 --> 00:05:29.716
were in response to technologies that were relatively new at the time.
是对当时崭新的科技的回应

82
00:05:29.740 --> 00:05:37.116
In the late 1800s, people were worried about cameras, which were just suddenly more portable than ever before,
19世纪末，人们担心那较过去突然轻便许多的照相机

83
00:05:37.140 --> 00:05:39.636
and newspaper gossip columns.
以及报纸上的八卦板块

84
00:05:39.660 --> 00:05:43.476
They were worried that the camera would capture information about them,
他们担心照相机会获取他们的信息

85
00:05:43.500 --> 00:05:46.700
take it out of context and widely disseminate it.
断章取义 大肆宣扬

86
00:05:47.060 --> 00:05:48.676
Does this sound familiar?
听起来是不是很熟悉？

87
00:05:48.700 --> 00:05:53.556
It's exactly what we're worrying about now with social media and drone cameras,
就像我们担忧社交媒体和无人机摄像头

88
00:05:53.580 --> 00:05:55.220
and, of course, sexting.
当然，还有色情短信

89
00:05:55.740 --> 00:05:57.956
And these fears about technology,
这些对于科技的恐惧

90
00:05:57.980 --> 00:05:59.196
they make sense
不无道理

91
00:05:59.220 --> 00:06:02.636
because technologies can amplify and bring out
因为科技能够展露出

92
00:06:02.660 --> 00:06:05.380
our worst qualities and behaviors.
并放大我们最为糟糕的品质与行为

93
00:06:05.980 --> 00:06:08.356
But there are solutions.
但这是有解决方法的

94
00:06:08.380 --> 00:06:11.940
And we've been here before with a dangerous new technology.
我们就曾经历过一个危险的新科技

95
00:06:12.540 --> 00:06:16.316
In 1908, Ford introduced the Model T car.
1908年，福特推出了T系车

96
00:06:16.340 --> 00:06:18.916
Traffic fatality rates were rising.
交通死亡率不断上升

97
00:06:18.940 --> 00:06:21.740
It was a serious problem -- it looks so safe, right?
这曾是一个严重的问题--它看起来很安全，对吧？

98
00:06:23.900 --> 00:06:27.876
Our first response was to try to change drivers' behavior,
我们第一反应是尝试改变司机的驾驶行为

99
00:06:27.900 --> 00:06:31.620
so we developed speed limits and enforced them through fines.
所以我们建立了速度限制并通过罚款来强制实行

100
00:06:32.060 --> 00:06:33.916
But over the following decades,
但在此后的几十年里

101
00:06:33.940 --> 00:06:39.436
we started to realize the technology of the car itself is not just neutral.
我们开始认识到汽车技术本身不是一成不变的

102
00:06:39.460 --> 00:06:42.676
We could design the car to make it safer.
我们可以设计出更安全的汽车

103
00:06:42.700 --> 00:06:46.156
So in the 1920s, we got shatter-resistant windshields.
于是上世纪20年代，我们有了 抗碎挡风玻璃

104
00:06:46.180 --> 00:06:48.676
In the 1950s, seat belts.
到了50年代有了安全带

105
00:06:48.700 --> 00:06:51.780
And in the 1990s, airbags.
到了90年代，安全气囊

106
00:06:52.260 --> 00:06:54.636
All three of these areas:
这三个领域：

107
00:06:54.660 --> 00:06:59.436
laws, individuals and industry came together over time
法律，个人及工业可以随着时间的推移集合在一起

108
00:06:59.460 --> 00:07:03.236
to help solve the problem that a new technology causes.
来帮助解决新科技所造成的问题

109
00:07:03.260 --> 00:07:06.500
And we can do the same thing with digital privacy.
我们在数字信息隐私上亦可以如法炮制

110
00:07:06.980 --> 00:07:09.740
Of course, it comes back to consent.
当然，这又回到同意的话题上来

111
00:07:10.180 --> 00:07:11.396
Here's the idea.
我有个想法

112
00:07:11.420 --> 00:07:15.236
Before anyone can distribute your private information,
在任何人可以传播你的个人信息之前

113
00:07:15.260 --> 00:07:17.500
they should have to get your permission.
他们应该得到你的同意

114
00:07:18.060 --> 00:07:22.876
This idea of affirmative consent comes from anti-rape activists
明确同意的观点源自于反性侵害人士

115
00:07:22.900 --> 00:07:26.676
who tell us that we need consent for every sexual act.
他们告诉我们对于每个性行为都需要得到双方同意

116
00:07:26.700 --> 00:07:31.276
And we have really high standards for consent in a lot of other areas.
我们在很多领域对待同意都有着极高的标准

117
00:07:31.300 --> 00:07:33.156
Think about having surgery.
比如做手术

118
00:07:33.180 --> 00:07:34.796
Your doctor has to make sure
医生需要确认

119
00:07:34.820 --> 00:07:38.860
that you are meaningfully and knowingly consenting to that medical procedure.
你了解并同意医疗程序

120
00:07:39.340 --> 00:07:43.036
This is not the type of consent like with an iTunes Terms of Service
这可不像你同意iTunes服务条款一样

121
00:07:43.060 --> 00:07:46.716
where you just scroll to the bottom and you're like, agree, agree, whatever.
直接滑到屏幕底部然后一个劲地点同意

122
00:07:46.740 --> 00:07:48.460
(Laughter)
（观众笑声）

123
00:07:48.980 --> 00:07:54.236
If we think more about consent, we can have better privacy laws.
如果我们多考虑他人是否同意我们会有更好隐私法

124
00:07:54.260 --> 00:07:57.676
Right now, we just don't have that many protections.
现在，我们没有那么多的保护

125
00:07:57.700 --> 00:08:01.276
If your ex-husband or your ex-wife is a terrible person,
如果你的前夫或前妻为人很不好

126
00:08:01.300 --> 00:08:05.516
they can take your nude photos and upload them to a porn site.
他们可以把你的裸照发到色情网站上去

127
00:08:05.540 --> 00:08:08.756
It can be really hard to get those images taken down.
想把那些照片删掉是很难的

128
00:08:08.780 --> 00:08:09.996
And in a lot of states,
在许多州里

129
00:08:10.020 --> 00:08:13.836
you're actually better off if you took the images of yourself
你自己拍照其实会更好点

130
00:08:13.860 --> 00:08:16.660
because then you can file a copyright claim.
因为这样你就可以申请版权了

131
00:08:17.140 --> 00:08:19.196
(Laughter)
（观众笑声）

132
00:08:19.220 --> 00:08:22.196
Right now, if someone violates your privacy,
现在，如果再有人侵犯了你的隐私

133
00:08:22.220 --> 00:08:26.420
whether that's an individual or a company or the NSA,
不管是个人还是企业还是美国国安局

134
00:08:27.100 --> 00:08:29.836
you can try filing a lawsuit,
你都可以提起诉讼

135
00:08:29.860 --> 00:08:31.996
though you may not be successful
尽管诉讼结果可能并不成功

136
00:08:32.020 --> 00:08:36.796
because many courts assume that digital privacy is just impossible.
因为很多法院觉得保护数字信息隐私是不可能的

137
00:08:36.820 --> 00:08:40.260
So they're not willing to punish anyone for violating it.
所以他们不愿意去惩罚那些触犯的人

138
00:08:41.020 --> 00:08:43.916
I still hear people asking me all the time,
我还是能听到人们不停的问我

139
00:08:43.940 --> 00:08:49.236
isn't a digital image somehow blurring the line between public and private
数字图像模糊了公共和私人的界限

140
00:08:49.260 --> 00:08:50.900
because it's digital, right?
因为它是数字的，对吗？

141
00:08:51.420 --> 00:08:52.756
No! No!
不！不！

142
00:08:52.780 --> 00:08:56.116
Everything digital is not just automatically public.
每一个数位化产品并不是自然而然就成为公众的

143
00:08:56.140 --> 00:08:58.036
That doesn't make any sense.
那太没道理了

144
00:08:58.060 --> 00:09:01.556
As NYU legal scholar Helen Nissenbaum tells us,
正如纽约大学法学者Helen Nissenbaum告诉我们

145
00:09:01.580 --> 00:09:04.196
we have laws and policies and norms
我们有着法律，政策以及准则

146
00:09:04.220 --> 00:09:07.356
that protect all kinds of information that's private,
来保护各类私人信息

147
00:09:07.380 --> 00:09:10.796
and it doesn't make a difference if it's digital or not.
不论它是不是数字信息

148
00:09:10.820 --> 00:09:13.476
All of your health records are digitized
你所有的医疗记录都是数字化的

149
00:09:13.500 --> 00:09:16.636
but your doctor can't just share them with anyone.
但你的医生却不能将它们分享给任何人

150
00:09:16.660 --> 00:09:21.116
All of your financial information is held in digital databases,
你所有的财务信息都储存在数字数据库里

151
00:09:21.140 --> 00:09:25.380
but your credit card company can't just post your purchase history online.
但你的信用卡公司不能将你的购买记录发布到网上

152
00:09:26.900 --> 00:09:32.356
Better laws could help address privacy violations after they happen,
更好的法律可以在侵犯隐私的问题发生之后帮助解决

153
00:09:32.380 --> 00:09:36.756
but one of the easiest things we can all do is make personal changes
但我们可以做的最为简便的事情之一

154
00:09:34.900 --> 00:09:39.460
to help protect each other's privacy.
就是从个人上做出改变来帮助保护他人的隐私

155
00:09:40.180 --> 00:09:42.076
We're always told that privacy
我们总是被告知隐私

156
00:09:41.990 --> 00:09:45.160
is our own, sole, individual responsibility.
是我们自己的，独有的个人的责任

157
00:09:45.180 --> 00:09:49.436
We're told, constantly monitor and update your privacy settings.
我们被告知要经常监控并更新隐私设置

158
00:09:49.460 --> 00:09:54.260
We're told, never share anything you wouldn't want the entire world to see.
我们被告知永远别把不想被全世界知道的东西分享出去

159
00:09:55.220 --> 00:09:56.436
This doesn't make sense.
这很没道理

160
00:09:56.460 --> 00:09:59.436
Digital media are social environments
数字媒体就是社会环境

161
00:09:59.460 --> 00:10:03.740
and we share things with people we trust all day, every day.
我们每天无时无刻地将事情分享给我们所信任的人

162
00:10:04.580 --> 00:10:07.556
As Princeton researcher Janet Vertesi argues,
就如普林斯顿研究员Janet Vertesi表示

163
00:10:07.580 --> 00:10:11.596
our data and our privacy, they're not just personal,
我们的数据和隐私不单单是私人的

164
00:10:11.620 --> 00:10:14.196
they're actually interpersonal.
它们实际上是一种人与人之间相互的

165
00:10:14.220 --> 00:10:17.476
And so one thing you can do that's really easy
所以，我们能做的很简单的一件事

166
00:10:17.500 --> 00:10:22.596
is just start asking for permission before you share anyone else's information.
就是在你分享别人信息之前取得别人的同意

167
00:10:22.620 --> 00:10:27.156
If you want to post a photo of someone online, ask for permission.
你想把某人的照片传到网上先经过那人的同意

168
00:10:27.180 --> 00:10:29.636
If you want to forward an email thread,
如果你想转寄一封电子邮件

169
00:10:29.660 --> 00:10:31.036
ask for permission.
先经过当事人同意

170
00:10:31.060 --> 00:10:33.836
And if you want to share someone's nude selfie,
如果你想分享某人的裸体自拍

171
00:10:33.860 --> 00:10:36.140
obviously, ask for permission.
显然，先经过当事人同意

172
00:10:37.380 --> 00:10:41.836
These individual changes can really help us protect each other's privacy,
这些个人行为的改变可以帮助我们保护彼此的隐私

173
00:10:41.860 --> 00:10:45.660
but we need technology companies on board as well.
但我们同样需要科技公司的帮忙

174
00:10:46.180 --> 00:10:50.676
These companies have very little incentive to help protect our privacy
科技公司几乎没有动机来保护我们的隐私

175
00:10:50.700 --> 00:10:56.260
because their business models depend on us sharing everything with as many people as possible.
因为他们的业务模式依靠于我们分享我们的每件事与尽可能多的人

176
00:10:56.900 --> 00:10:58.836
Right now, if I send you an image,
现在，如果我发给你一张照片

177
00:10:58.860 --> 00:11:01.956
you can forward that to anyone that you want.
你可以转发给任何人

178
00:11:01.980 --> 00:11:06.236
But what if I got to decide if that image was forwardable or not?
但如果我来决定这张照片可不可以被转发会怎样？

179
00:11:06.260 --> 00:11:10.316
This would tell you, you don't have my permission to send this image out.
这就会告诉你，你没有我的批准去发送这张照片

180
00:11:10.340 --> 00:11:14.476
We do this kind of thing all the time to protect copyright.
我们一直这样做来保护我们的版权

181
00:11:14.500 --> 00:11:19.276
If you buy an e-book, you can't just send it out to as many people as you want.
如果你买了本电子书你不能随意把它寄给别人

182
00:11:19.300 --> 00:11:21.860
So why not try this with mobile phones?
所以为什么不 如法炮制到手机上去呢？

183
00:11:22.780 --> 00:11:31.316
What you can do is we can demand that tech companies add these protections to our devices and our platforms as the default.
我们可以让科技公司给我们的设备和平台默认装上这些保护

184
00:11:31.340 --> 00:11:34.756
After all, you can choose the color of your car,
毕竟，你可以选择你自己车子的颜色

185
00:11:34.780 --> 00:11:37.620
but the airbags are always standard.
但安全气囊总是有固定标准的

186
00:11:39.900 --> 00:11:43.716
If we don't think more about digital privacy and consent,
如果我们不多思考数字隐私和同意的问题

187
00:11:43.740 --> 00:11:46.460
there can be serious consequences.
就可能会有严重后果

188
00:11:47.180 --> 00:11:49.436
There was a teenager from Ohio --
有一位来自俄亥俄的少女--

189
00:11:49.460 --> 00:11:52.300
let's call her Jennifer, for the sake of her privacy.
为了保护她的隐私我们就叫她Jennifer吧

190
00:11:52.940 --> 00:11:56.516
She shared nude photos of herself with her high school boyfriend,
她把她的裸照分享给了她高中的男朋友

191
00:11:56.540 --> 00:11:58.060
thinking she could trust him.
觉得他可以信任

192
00:11:59.540 --> 00:12:01.476
Unfortunately, he betrayed her
不幸的是，男友背叛了她

193
00:12:01.500 --> 00:12:04.476
and sent her photos around the entire school.
把她的照片传遍学校

194
00:12:04.500 --> 00:12:08.020
Jennifer was embarrassed and humiliated,
让Jennifer难堪，备受羞辱

195
00:12:08.620 --> 00:12:12.756
but instead of being compassionate, her classmates harassed her.
她的同学非但没有同情她反而对她进行骚扰

196
00:12:12.780 --> 00:12:14.636
They called her a slut and a whore
他们说她是个荡妇，妓女

197
00:12:14.660 --> 00:12:16.620
and they made her life miserable.
使她的生活痛苦不堪

198
00:12:17.180 --> 00:12:20.860
Jennifer started missing school and her grades dropped.
Jennifer开始缺课，成绩下滑

199
00:12:21.340 --> 00:12:25.140
Ultimately, Jennifer decided to end her own life.
最终，Jennifer决定结束了她的生命

200
00:12:26.540 --> 00:12:29.236
Jennifer did nothing wrong.
Jennifer没做错什么

201
00:12:29.260 --> 00:12:34.356
All she did was share a nude photo with someone she thought that she could trust.
她不过将她的裸照分享给了她认为可以信任的人

202
00:12:34.380 --> 00:12:36.996
And yet our laws tell her
可我们的法律告诉她

203
00:12:37.020 --> 00:12:41.180
that she committed a horrible crime equivalent to child pornography.
她犯了和儿童色情一样可怕的罪行

204
00:12:41.740 --> 00:12:43.236
Our gender norms tell her
我们的性别规范告诉她

205
00:12:43.260 --> 00:12:46.476
that by producing this nude image of herself,
给自己拍裸照

206
00:12:46.500 --> 00:12:49.700
she somehow did the most horrible, shameful thing.
是她做过的最为可怕羞耻的事

207
00:12:50.220 --> 00:12:54.436
And when we assume that privacy is impossible in digital media,
当我们觉得保护隐私在数字媒体环境下是不可能的时候

208
00:12:54.460 --> 00:12:59.980
we completely write off and excuse her boyfriend's bad, bad behavior.
我们完全无视男朋友的不道德行为

209
00:13:01.020 --> 00:13:06.756
People are still saying all the time to victims of privacy violations,
人们还是在不停地对那些隐私受侵犯的受害者们说

210
00:13:06.780 --> 00:13:08.036
"What were you thinking?
“你在想些什么啊？

211
00:13:08.060 --> 00:13:10.540
You should have never sent that image."
你就不该发那照片的”

212
00:13:11.460 --> 00:13:15.460
If you're trying to figure out what to say instead, try this.
如果你尝试换种说法试试这个

213
00:13:15.980 --> 00:13:19.500
Imagine you've run into your friend who broke their leg skiing.
想象下你碰到一个滑雪时摔断腿的朋友

214
00:13:20.060 --> 00:13:24.636
They took a risk to do something fun, and it didn't end well.
他们当时冒险做了些好玩的动作结果腿摔断了

215
00:13:24.660 --> 00:13:27.196
But you're probably not going to be the jerk who says,
但你不太可能蠢到说

216
00:13:27.220 --> 00:13:29.660
"Well, I guess you shouldn't have gone skiing then."
”唉，我觉得你就不该去滑雪的。”

217
00:13:31.900 --> 00:13:34.036
If we think more about consent,
如果我们多考虑他人是否同意

218
00:13:34.060 --> 00:13:37.316
we can see that victims of privacy violations
我们便能看见侵犯隐私的受害者们

219
00:13:37.340 --> 00:13:39.076
deserve our compassion,
得到了我们的同情

220
00:13:39.100 --> 00:13:43.700
not criminalization, shaming, harassment or punishment.
而不是遭到定罪，羞辱骚扰或是惩罚

221
00:13:44.260 --> 00:13:48.756
We can support victims, and we can prevent some privacy violations
我们可以支持这些受害者通过法律，个人和科技上的改变

222
00:13:48.780 --> 00:13:53.100
by making these legal, individual and technological changes.
来防止侵权隐私的发生

223
00:13:53.660 --> 00:13:59.476
Because the problem is not sexting, the issue is digital privacy.
因为问题不在于色情信息的发送而在于数字隐私

224
00:13:59.500 --> 00:14:01.860
And one solution is consent.
解决方法之一就是获得他人的同意

225
00:14:02.500 --> 00:14:07.076
So the next time a victim of a privacy violation comes up to you,
所以下次一个隐私受侵犯的人来找你的时候

226
00:14:07.100 --> 00:14:09.836
instead of blaming them, let's do this instead:
不要责备他们而是这么做

227
00:14:09.860 --> 00:14:13.276
let's shift our ideas about digital privacy,
让我们转变我们对数字隐私的看法

228
00:14:13.300 --> 00:14:15.940
and let's respond with compassion.
并以同情作为回应

229
00:14:16.500 --> 00:14:17.716
Thank you.
谢谢