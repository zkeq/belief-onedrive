WEBVTT

1
00:00:12.683 --> 00:00:16.888
Future tech always comes with two things: promise
有两样东西总是随未来科技而来

2
00:00:15.762 --> 00:00:19.010
and unintended consequences.
承诺 和意外成果

3
00:00:19.040 --> 00:00:22.446
And it's those consequences that I want to explore.
而这些成果正是我想要去探索的

4
00:00:22.921 --> 00:00:26.644
And before we get to how future tech may affect us,
在了解未来科技 会怎样影响我们之前

5
00:00:26.668 --> 00:00:30.417
I'd like to spend a little time exploring the unintended consequences
我会花一点时间去探索我们科技的

6
00:00:30.441 --> 00:00:32.008
of some of our recent tech,
一些意外成果

7
00:00:31.982 --> 00:00:34.054
namely, social media.
也就是社交媒体

8
00:00:34.705 --> 00:00:39.337
Social media, a few short years ago, was the tech of future you.
短短几年间 社交媒体从未来科技

9
00:00:39.361 --> 00:00:41.451
Now it just is you.
变成了现实

10
00:00:41.945 --> 00:00:44.772
Social media was supposed to bring us together
当时认为社交媒体 将会以我们从未想象过的方式

11
00:00:44.796 --> 00:00:47.239
in ways we could never imagine.
把我们聚集到一起

12
00:00:47.263 --> 00:00:49.032
And the predictors were correct.
这种预测是对的

13
00:00:50.232 --> 00:00:53.074
These three girls are talking to one another
这三个女孩正在自如地聊天

14
00:00:53.098 --> 00:00:56.132
without the awkward discomfort of eye contact.
还完美地避免了对视的尴尬

15
00:00:56.156 --> 00:00:57.485
(Laughter)
（笑声）

16
00:00:57.509 --> 00:00:59.589
I call that advancement.
我认为这是一种进步

17
00:01:01.353 --> 00:01:04.861
We were supposed to be caught up in a communication tsunami,
还有人预测我们将会被卷入一场

18
00:01:04.885 --> 00:01:07.725
the likes of which the world has never seen.
前所未有的世界性社交海啸

19
00:01:07.749 --> 00:01:09.494
And that did happen.
事实的确如此

20
00:01:09.518 --> 00:01:11.299
And so did this.
这也是

21
00:01:12.973 --> 00:01:16.017
(Sings) One of these things is not like the other.
（唱歌）有一个人 他落单了

22
00:01:15.991 --> 00:01:17.432
(Speaks) Now, look at this picture.
（说话）现在来看看这张照片

23
00:01:17.762 --> 00:01:20.226
If you picked the guy with the book, you’re wrong --
如果你在关注看书的那位 那就错了

24
00:01:20.250 --> 00:01:23.014
or, as a certain president would say, "Wrong!"
就像某位总统说的一样 “错了！”

25
00:01:22.988 --> 00:01:24.960
(Laughter)
（笑声）

26
00:01:27.316 --> 00:01:29.603
Clearly, three of these guys are reading,
显然 这三位仁兄都在阅读

27
00:01:29.627 --> 00:01:32.007
and one guy, on the end, is listening to music
而坐在边上的那位则在听音乐

28
00:01:31.971 --> 00:01:33.514
and playing "Candy Crush."
和玩消消乐

29
00:01:33.554 --> 00:01:35.105
(Laughter)
（笑声）

30
00:01:35.682 --> 00:01:37.265
So are we more connected,
那到底是人与人的关系变得更亲密

31
00:01:37.289 --> 00:01:40.934
or are we just more connected to our devices?
还是人与机的关系变得更亲密了

32
00:01:41.976 --> 00:01:45.381
Social media was supposed to place us in a veritable town square,
社交媒体理应要给我们 提供一个真正的言论广场

33
00:01:45.405 --> 00:01:50.144
where we could engage one another with challenging ideas and debates.
让我们的思想碰撞 相互辩论

34
00:01:50.168 --> 00:01:53.058
And instead what we got were trolls.
可事实上迎接我们的 是大量的“投饵”

35
00:01:53.082 --> 00:01:56.659
This is an actual tweet that I received.
这是我收到过的一条真实推特信息

36
00:01:58.040 --> 00:02:02.194
"Chuck, no one wants to hear your stupid, ill-informed political views!
“Chuck 没人想听你那些 愚蠢的 一知半解的政治见解

37
00:02:02.218 --> 00:02:04.539
I hope you get leprosy and die.
我希望你得庥风死掉

38
00:02:04.563 --> 00:02:05.971
Love, Dad"
爱你的 老爸

39
00:02:05.995 --> 00:02:07.662
(Laughter)
（笑声）

40
00:02:08.616 --> 00:02:11.269
Now, the great thing about that tweet if you look at it,
好消息是 如果你认真看这条推特

41
00:02:10.553 --> 00:02:13.164
just like most trolls, it's not that bad,
它跟大部分投饵一样没啥大碍

42
00:02:13.304 --> 00:02:16.974
because he wished "leporsy" on me instead of "leprosy,"
因为他希望我得“庥风” 而不是“麻风”

43
00:02:16.998 --> 00:02:19.839
and "leporsy" is not dangerous at all.
而“庥风”是完全无害的

44
00:02:19.863 --> 00:02:21.444
(Laughter)
（笑声）

45
00:02:21.468 --> 00:02:23.128
(Applause)
（掌声）

46
00:02:26.153 --> 00:02:30.670
Along with trolls, we got a brand new way of torturing teenagers --
伴随着投饵 一种折磨青少年的 新方式诞生了——

47
00:02:30.694 --> 00:02:32.059
cyberbullying.
网络欺凌

48
00:02:32.668 --> 00:02:37.601
A concept that my 75-year-old mother just can't seem to wrap her head around.
这概念会让我七十五岁的 老母亲摸不着头脑

49
00:02:38.261 --> 00:02:40.363
"So, uh, did they hit him?"
“那，他们打他了吗？”

50
00:02:40.387 --> 00:02:42.069
"No, Mom, they didn't hit him."
“不，妈妈，他们没有。”

51
00:02:42.439 --> 00:02:43.755
"Did they take his money?"
“那他们拿他钱了吗？”

52
00:02:43.779 --> 00:02:45.645
"No, Mom, they didn't take his money."
“不，妈妈，他们没拿他钱。”

53
00:02:45.669 --> 00:02:47.525
"Did they put his face in the toilet?"
“他们把他的脸按在厕所上了吗？”

54
00:02:47.549 --> 00:02:48.768
"No, Mom, they didn't --"
“不，妈妈，他们没这么干……”

55
00:02:48.792 --> 00:02:50.003
"Well, what did they do?"
“所以他们到底干啥了？”

56
00:02:49.897 --> 00:02:51.906
"They attacked him on the internet."
“他们在网上攻击他。”

57
00:02:52.620 --> 00:02:54.141
"Attacked him on the internet?"
“在网上攻击他？”

58
00:02:54.165 --> 00:02:55.166
(Laughter)
（笑声）

59
00:02:55.190 --> 00:02:57.532
"Well, why don't you just turn off the internet?"
“那你直接断网不就得了？”

60
00:02:57.556 --> 00:02:58.845
(Laughter)
（笑声）

61
00:02:58.869 --> 00:03:01.411
"Your whole generation is a bunch of wussies."
“你们这代人全是软蛋。”

62
00:03:01.435 --> 00:03:02.940
(Laughter)
（笑声）

63
00:03:03.480 --> 00:03:04.630
She's got a point.
她的话倒是没毛病

64
00:03:04.654 --> 00:03:05.993
(Laughter)
（笑声）

65
00:03:05.867 --> 00:03:07.090
She's got a point.
没毛病

66
00:03:07.200 --> 00:03:10.818
And I don't even want to talk about what social media has done to dating.
我甚至都不想谈 社交媒体是怎么毁掉约会的

67
00:03:11.311 --> 00:03:16.212
I was on Grindr until I found out it wasn't a sandwich app.
我上了 Grindr 才知道 原来它不是一款三明治手机叫餐应用

68
00:03:16.236 --> 00:03:18.319
(Laughter)
（笑声）

69
00:03:19.728 --> 00:03:22.950
And I can't even tell you about Tinder,
更别说 Tinder 了

70
00:03:22.974 --> 00:03:26.874
except for the fact that if you think there is a limit
如果你认为这世上只有

71
00:03:26.898 --> 00:03:30.784
to the amount of anonymous sex we can have on this planet,
极少人会匿名约炮

72
00:03:30.808 --> 00:03:32.625
you are sadly mistaken.
那就大错特错了

73
00:03:32.649 --> 00:03:33.650
(Laughter)
（笑声）

74
00:03:33.674 --> 00:03:35.553
So where do we go from here?
接下来要谈什么呢

75
00:03:35.577 --> 00:03:37.944
Well, let's just jump right in and play the hits.
一起来玩碰碰车吧

76
00:03:37.968 --> 00:03:39.119
Driverless cars.
无人驾驶汽车

77
00:03:39.143 --> 00:03:41.815
Something that has already been around for many years,
其实多年前我们已经做到了

78
00:03:41.839 --> 00:03:44.000
just without the assistance of computers.
只不过以前没有用电脑而已

79
00:03:43.964 --> 00:03:46.078
(Laughter)
（笑声）

80
00:03:47.172 --> 00:03:49.531
(Applause)
（掌声）

81
00:03:50.553 --> 00:03:54.533
Because for years, we have been driving while texting,
因为多年来我们都是 一边开车一边发信息

82
00:03:54.557 --> 00:03:56.135
putting on makeup,
一边化妆

83
00:03:56.159 --> 00:03:59.241
shaving, reading -- actually reading --
一边刮胡子 阅读 如果真有会人阅读

84
00:03:59.265 --> 00:04:00.427
that would be me.
那说的就是我

85
00:04:00.451 --> 00:04:01.464
(Laughter)
（笑声）

86
00:04:01.488 --> 00:04:04.487
The other thing is that since driverless cars will be shared,
同时 既然无人驾驶汽车将会共享

87
00:04:04.511 --> 00:04:05.827
most people won't own cars,
大部分人都不会买车了

88
00:04:05.851 --> 00:04:08.169
and that means the DMV will go away.
意味着车辆管理局要退出历史舞台了

89
00:04:08.820 --> 00:04:11.080
The DMV -- I know what you're saying right now.
车辆管理局——我知道你在想什么

90
00:04:10.614 --> 00:04:12.174
"There's no way this guy is going to stand up here
“这人不可能会支持

91
00:04:12.174 --> 00:04:14.154
and make a case for the DMV."
车辆管理局。”

92
00:04:14.944 --> 00:04:18.117
Well, I don't know about you, but I do not want to live in a world
好吧 我不了解你 但我真的不想在这么一个世界生活：

93
00:04:17.841 --> 00:04:20.363
where harsh fluorescent lights,
充斥着刺眼的灯光

94
00:04:20.443 --> 00:04:22.341
endless lines,
一眼望不到头的长队

95
00:04:22.365 --> 00:04:24.201
terrible forms to fill out
烦人的表格

96
00:04:24.225 --> 00:04:28.200
and disaffected, soulless bureaucrats remind me
还有心怀不满 行尸走肉般的官僚

97
00:04:27.024 --> 00:04:31.630
that I am pretty damn lucky not to work here.
提醒我幸亏自己没在那儿工作

98
00:04:31.690 --> 00:04:32.840
(Laughter)
（笑声）

99
00:04:33.310 --> 00:04:35.560
That is the real service they provide.
这就是他们真正提供的服务

100
00:04:36.278 --> 00:04:37.795
The DMV:
车辆管理局：

101
00:04:37.819 --> 00:04:39.880
come for the registration renewal,
为注册续签而生

102
00:04:39.904 --> 00:04:44.155
stay for the satisfaction of knowing you made some pretty good life choices.
致力于让你做出好的生活抉择

103
00:04:44.179 --> 00:04:46.026
(Laughter)
（笑声）

104
00:04:48.880 --> 00:04:50.878
Nobody will own their car in the future,
将来没人会开私家车了

105
00:04:50.902 --> 00:04:53.948
and that means teenagers will not have a place to make out.
青少年也少了一个卿卿我我的地方

106
00:04:55.366 --> 00:04:56.739
So you know what that means.
也就是说

107
00:04:56.763 --> 00:04:59.993
That means they will order driverless cars to do just that.
他们会叫一辆无人驾驶汽车来代替

108
00:05:00.422 --> 00:05:04.787
I do not want to step into a vehicle and ask the question:
我可不想在进车时有这样的疑惑

109
00:05:04.811 --> 00:05:09.604
"Why does this car smell like awkwardness, failure and shame?"
“为什么我嗅到了 笨拙、失败和羞耻的气息？”

110
00:05:09.628 --> 00:05:11.786
(Laughter)
（笑声）

111
00:05:12.736 --> 00:05:15.780
If I want to ask that question, I'll walk into my own bedroom.
如果我真想问这么一个问题 我会回我自己房间的

112
00:05:15.804 --> 00:05:17.185
(Laughter)
（笑声）

113
00:05:17.209 --> 00:05:19.219
So what else do we have to look forward to?
那还有什么要吐槽的呢

114
00:05:19.243 --> 00:05:21.067
That's right, artificial intelligence.
对 就是人工智能

115
00:05:21.091 --> 00:05:23.382
Artificial intelligence, yes.
没错 人工智能

116
00:05:23.406 --> 00:05:26.595
You know, there was a time when artificial intelligence was a joke.
曾几何时 人工智能还只是个笑话

117
00:05:26.619 --> 00:05:30.251
I mean, literally a quip that you would hear at a cocktail party
而且还是有些人会在

118
00:05:30.275 --> 00:05:32.636
when somebody would bring it up in conversation:
鸡尾酒派对上说的俏皮话

119
00:05:32.660 --> 00:05:34.592
"Artificial intelligence.
“人工智能

120
00:05:34.616 --> 00:05:38.172
The only real artificial intelligence is our American Congress.
唯一真正的人工智能就是美国国会

121
00:05:38.196 --> 00:05:40.224
Ha, ha, ha, ha, ha."
哈哈哈哈哈“

122
00:05:40.248 --> 00:05:41.665
Well, it's not funny anymore.
不过这已经不好笑了

123
00:05:41.689 --> 00:05:43.728
(Laughter)
（笑声）

124
00:05:47.928 --> 00:05:51.479
Stephen Hawking, Elon Musk and Bill Gates have all gone on record
斯蒂芬·霍金 埃隆·马斯克 比尔·盖茨

125
00:05:50.033 --> 00:05:55.423
expressing grave reservations about artificial intelligence.
都曾表达过对人工智能的悲观看法

126
00:05:55.483 --> 00:05:59.014
That's like Jesus, Moses and Muhammad coming together and saying,
就好像耶稣 摩西和 穆罕默迪聚在一起说：

127
00:05:58.978 --> 00:06:01.822
"Guy, guys -- here's something we can all believe in."
“嘿，嘿，你们真的要相信。”

128
00:06:01.852 --> 00:06:02.874
(Laughter)
（笑声）

129
00:06:02.898 --> 00:06:05.311
You might want to go with that, is all I'm saying.
你们可能会真的相信

130
00:06:07.130 --> 00:06:11.597
We are actually teaching machines how to think,
其实我们就是在教机器怎样思考

131
00:06:11.621 --> 00:06:13.845
how to understand our behavior,
怎样理解我们的行为

132
00:06:13.869 --> 00:06:17.470
how to defend themselves and even practice deception.
怎样自我防卫 甚至学会欺骗

133
00:06:18.724 --> 00:06:20.453
What could possibly go wrong?
这能有什么问题呢

134
00:06:20.477 --> 00:06:22.068
(Laughter)
（笑声）

135
00:06:23.388 --> 00:06:25.216
The one thing that's for sure:
有一点可以确定的是

136
00:06:25.240 --> 00:06:28.389
the creation always despises its creator.
造物者总是被自己的作品鄙视

137
00:06:28.863 --> 00:06:30.056
OK?
懂吗

138
00:06:29.950 --> 00:06:32.169
The Titans rose up against the gods;
泰坦总是会上帝作对

139
00:06:32.229 --> 00:06:33.961
Lucifer against Jehovah.
路西法与耶和华作对

140
00:06:34.367 --> 00:06:37.149
And anybody who has a teenager has heard these words:
各位青少年家长 肯定听过这样的话

141
00:06:37.173 --> 00:06:39.206
"I hate you and you're ruining my life!
“我恨你，你毁了我一生！”

142
00:06:39.230 --> 00:06:40.380
I hate you!"
“我恨你！”

143
00:06:42.145 --> 00:06:46.700
Now just imagine that sentiment with a machine that can outthink you
再想象一下一台比你聪明的机器 会对你怀有怎样的感情

144
00:06:46.724 --> 00:06:48.567
and is heavily armed.
还是全副武装那种

145
00:06:48.591 --> 00:06:50.102
(Laughter)
（笑声）

146
00:06:50.894 --> 00:06:52.095
The result?
结果呢

147
00:06:52.796 --> 00:06:53.998
Absolutely.
显而易见

148
00:06:53.952 --> 00:06:55.478
(Laughter)
（笑声）

149
00:06:58.793 --> 00:07:02.037
What we need to do before we perfect artificial intelligence
在完善人工智能之前

150
00:07:01.971 --> 00:07:04.248
is perfect artificial emotions.
我们应该完善人工情感

151
00:07:04.613 --> 00:07:08.523
That way, we can teach the robots or machines
我们可以教机器人或者机器

152
00:07:08.547 --> 00:07:11.028
how to love us unconditionally,
怎样无条件爱我们

153
00:07:11.052 --> 00:07:15.577
so that when they figure out that the only real problem on this planet
即便他们发现这个星球上的唯一问题

154
00:07:15.601 --> 00:07:16.791
is us,
就是我们

155
00:07:16.815 --> 00:07:18.531
instead of destroying us --
它们都不会灭了我们

156
00:07:18.555 --> 00:07:21.659
which, by the way, is totally logical --
而是 完全符合逻辑地

157
00:07:21.683 --> 00:07:24.129
they will find us adorable --
觉得我们可爱极了

158
00:07:24.153 --> 00:07:25.219
(Laughter)
（笑声）

159
00:07:24.753 --> 00:07:26.438
like baby poop.
就跟婴儿拉粑粑一样

160
00:07:26.488 --> 00:07:27.491
(Laughter)
（笑声）

161
00:07:27.515 --> 00:07:30.621
"Oh my god, I just love the way you just destroyed the planet.
“天哪，我爱死你摧毁地球的方式了，

162
00:07:30.645 --> 00:07:33.417
I can't stay mad at you, you're so cute!
我没办法对你发火，你太可爱了！

163
00:07:33.441 --> 00:07:34.663
You're so cute!"
你太可爱了！“

164
00:07:34.687 --> 00:07:35.847
(Laughter)
（笑声）

165
00:07:35.871 --> 00:07:42.796
Can't talk about this without talking about robotics. OK?
提到人工智能就必须要谈机器人了

166
00:07:42.820 --> 00:07:44.941
Remember when you thought robotics were cool?
还记得你曾经觉得机器人很酷吗

167
00:07:44.965 --> 00:07:47.087
I remember when I thought robotics were cool,
以前我也觉得机器人很酷

168
00:07:46.581 --> 00:07:49.235
until I figured out that they were going to take everybody's place,
直到我发现它们会取代任何人

169
00:07:49.235 --> 00:07:51.665
from the delivery guy down to the heart surgeon.
从快递员到心脏外科医生

170
00:07:51.665 --> 00:07:55.198
The one thing, though, that is very disappointing about robotics
关于机器人 只有一件事让我们失望

171
00:07:55.638 --> 00:07:57.070
is the holy grail of robotics,
那就是我们至今

172
00:07:56.198 --> 00:07:57.795
and it hasn't even happened.
也未能实现的终极梦想

173
00:07:57.795 --> 00:08:00.388
I'm talking about the robot girlfriend,
我说的是机器人女朋友

174
00:08:00.428 --> 00:08:04.036
the dream of one lonely geek in a windowless basement
住在无窗地下室的 孤独极客将她们视为梦想

175
00:08:04.060 --> 00:08:07.485
who vowed one day: "I am going to marry my creation."
并终会在将来的某天高呼： “我要跟我的作品结婚。”

176
00:08:08.558 --> 00:08:13.585
And there actually is a movement underway to stop this from happening,
事实上也有阻止 这种梦想成真的地下运动

177
00:08:13.609 --> 00:08:15.773
for fear of exploitation.
他们唯恐产生剥削

178
00:08:16.473 --> 00:08:19.099
And I, for one, am against that movement.
而我 是反对这种运动的

179
00:08:20.044 --> 00:08:22.871
I believe we should have robot girlfriends.
我觉得我们应该要有机器人女朋友

180
00:08:23.416 --> 00:08:27.661
I just believe that they should come with a feminist protocol
除了有人工智能之外

181
00:08:27.685 --> 00:08:29.564
and artificial intelligence,
她们还要懂得女权主义协议

182
00:08:29.588 --> 00:08:33.793
so she can take one look at that guy and go, "I am too good for you.
那样她们就可以对人说：“你配不上我，

183
00:08:33.817 --> 00:08:35.119
I'm leaving."
我要走了。”

184
00:08:34.823 --> 00:08:36.692
(Laughter)
（笑声）

185
00:08:36.732 --> 00:08:38.768
(Applause)
（掌声）

186
00:08:40.191 --> 00:08:41.822
And finally,
最后

187
00:08:41.846 --> 00:08:44.028
I have to talk about bioengineering,
我必须要谈一下生物工程

188
00:08:44.534 --> 00:08:50.587
an area of science that promises to end disease before it even begins,
这个科学领域承诺能够预防疾病

189
00:08:51.478 --> 00:08:55.898
to help us live longer, fuller, healthier lives.
让我们活得更长久 更精彩 更健康

190
00:08:57.038 --> 00:09:00.160
And when you couple that with implantable hardware,
只要联想一下植入式硬件

191
00:09:00.184 --> 00:09:04.611
you are looking at the next incarnation of human evolution.
你就能看到人类的下一轮进化

192
00:09:04.635 --> 00:09:06.951
And all of that sounds great,
在你搞清楚这是什么意思之前

193
00:09:06.975 --> 00:09:09.276
until you figure out where it's really going.
这一切听起来都很好

194
00:09:09.300 --> 00:09:10.479
One place:
比如说：

195
00:09:10.953 --> 00:09:12.272
designer babies,
“设计婴儿”

196
00:09:13.137 --> 00:09:15.164
where, no matter where you are on the globe
无论你在地球上的哪个地方

197
00:09:15.188 --> 00:09:16.973
or what your ethnicity,
是什么种族

198
00:09:16.997 --> 00:09:19.631
babies will end up looking like that.
生出来的宝宝都会长成这样

199
00:09:19.655 --> 00:09:21.251
(Laughter)
（笑声）

200
00:09:21.275 --> 00:09:23.857
That boy is surprised
这个小男孩很吃惊

201
00:09:23.881 --> 00:09:27.360
because he just found out both his parents are black.
因为他刚得知他的父母都是黑人

202
00:09:27.384 --> 00:09:30.092
(Laughter)
（笑声）

203
00:09:35.389 --> 00:09:38.557
Can you imagine him at a cocktail party in 20 years?
你能想象一下二十年后 他参加鸡尾酒派对的场景吗

204
00:09:39.249 --> 00:09:40.862
"Yeah, both my parents are black.
“对，我的父母都是黑人。

205
00:09:40.886 --> 00:09:43.085
I mean, it's a little awkward at times,
我是说，虽然有点奇怪，

206
00:09:43.109 --> 00:09:44.856
but you should see my credit rating.
不过你一定要去看看 我的信用等级

207
00:09:44.880 --> 00:09:46.603
Impressive, very impressive."
非常高，我真没有骗你。”

208
00:09:46.627 --> 00:09:48.066
(Laughter)
（笑声）

209
00:09:49.173 --> 00:09:51.513
Now, all of this seems scary,
这一切似乎都很吓人

210
00:09:51.537 --> 00:09:54.184
and everybody in this room knows that it isn't.
可这里的每个人都知道这不是事实

211
00:09:54.208 --> 00:09:55.670
Technology isn't scary.
科技并不可怕

212
00:09:56.388 --> 00:09:59.303
Never has been and it never will be.
以前不是 将来也不会

213
00:09:59.933 --> 00:10:02.604
What's scary is us
可怕的是我们自己

214
00:10:02.628 --> 00:10:04.620
and what we will do with technology.
以及我们会利用科技做的事

215
00:10:05.152 --> 00:10:08.241
Will we allow it to expose our humanity,
我们是用它展现我们的人性

216
00:10:09.154 --> 00:10:11.461
showing our true selves
展示我们的真我

217
00:10:11.485 --> 00:10:15.329
and reinforcing the fact that we are indeed our brother's keeper?
深化我们是自己兄弟的依靠这一事实

218
00:10:16.060 --> 00:10:21.794
Or will we allow it to reveal our deepest, darkest demons?
还是透过它显露自己 内心深处的阴暗面

219
00:10:22.543 --> 00:10:27.700
The true question is not whether or not technology is scary.
真正的问题不在于科技是否可怕

220
00:10:28.146 --> 00:10:29.431
The true question is:
真正的问题是

221
00:10:30.093 --> 00:10:31.245
How human
你到底是否

222
00:10:31.694 --> 00:10:32.864
are you?
枉而为人

223
00:10:33.476 --> 00:10:34.627
Thank you.
谢谢

224
00:10:34.651 --> 00:10:38.581
(Applause)
（掌声）