WEBVTT

1
00:00:12.732 --> 00:00:14.867
Kashmir Hill: So for my birthday last year.
[AI] 克什米尔山：去年我的生日也是这样。

2
00:00:14.891 --> 00:00:16.884
my husband got me an Amazon Echo.
[AI] 我丈夫给我买了一个亚马逊回声。

3
00:00:17.415 --> 00:00:18.955
I was kind of shocked. actually.
[AI] 我有点震惊。事实上

4
00:00:18.979 --> 00:00:22.213
because we both work in privacy and security.
[AI] 因为我们都在隐私和安全方面工作。

5
00:00:22.237 --> 00:00:23.573
(Laughter)
[AI] （众笑）

6
00:00:24.508 --> 00:00:27.897
And this was a device that would sit in the middle of our home
[AI] 这是一个可以坐在我们家中间的装置

7
00:00:27.921 --> 00:00:29.357
with a microphone on.
[AI] 带着麦克风。

8
00:00:29.381 --> 00:00:31.030
constantly listening.
[AI] 不断地倾听。

9
00:00:31.516 --> 00:00:32.770
We're not alone. though.
[AI] 我们并不孤单。虽然

10
00:00:32.794 --> 00:00:35.675
According to a survey by NPR and Edison Research.
[AI] 根据NPR和爱迪生研究公司的调查。

11
00:00:35.699 --> 00:00:39.778
one in six American adults now has a smart speaker.
[AI] 六分之一的美国成年人现在有一个智能扬声器。

12
00:00:39.802 --> 00:00:42.683
which means that they have a virtual assistant at home.
[AI] 这意味着他们家里有一个虚拟助手。

13
00:00:42.707 --> 00:00:43.905
Like. that's wild.
[AI] 喜欢那太疯狂了。

14
00:00:43.929 --> 00:00:48.045
The future. or the future dystopia. is getting here fast.
[AI] 未来。或者未来的反乌托邦。他很快就到了。

15
00:00:48.598 --> 00:00:53.105
Beyond that. companies are offering us all kinds of internet-connected devices.
[AI] 除此之外。公司为我们提供各种连接互联网的设备。

16
00:00:53.129 --> 00:00:58.097
There are smart lights. smart locks. smart toilets. smart toys.
[AI] 有智能灯。智能锁。智能厕所。智能玩具。

17
00:00:58.121 --> 00:00:59.432
smart sex toys.
[AI] 智能性玩具。

18
00:01:00.143 --> 00:01:02.834
Being smart means the device can connect to the internet.
[AI] 智能意味着设备可以连接到互联网。

19
00:01:02.858 --> 00:01:04.034
it can gather data.
[AI] 它可以收集数据。

20
00:01:04.058 --> 00:01:05.960
and it can talk to its owner.
[AI] 它可以和它的主人交谈。

21
00:01:06.786 --> 00:01:09.500
But once your appliances can talk to you.
[AI] 但一旦你的设备可以和你说话。

22
00:01:09.524 --> 00:01:11.669
who else are they going to be talking to?
[AI] 他们还会跟谁说话？

23
00:01:12.151 --> 00:01:13.516
I wanted to find out.
[AI] 我想知道。

24
00:01:13.540 --> 00:01:16.928
so I went all-in and turned my one-bedroom apartment in San Francisco
[AI] 于是我走了进去，打开了我在旧金山的一居室公寓。

25
00:01:16.952 --> 00:01:18.301
into a smart home.
[AI] 进入智能家居。

26
00:01:18.620 --> 00:01:21.711
I even connected our bed to the internet.
[AI] 我甚至把我们的床连上了互联网。

27
00:01:22.325 --> 00:01:25.627
As far as I know. it was just measuring our sleeping habits.
[AI] 据我所知。这只是测量我们的睡眠习惯。

28
00:01:26.310 --> 00:01:28.391
I can now tell you that the only thing worse
[AI] 我现在可以告诉你，唯一更糟糕的是

29
00:01:28.415 --> 00:01:30.202
than getting a terrible night's sleep
[AI] 比睡一个糟糕的晚上要好

30
00:01:30.226 --> 00:01:32.643
is to have your smart bed tell you the next day
[AI] 就是让你的智能床第二天告诉你

31
00:01:32.667 --> 00:01:35.723
that you "missed your goal and got a low sleep score."
[AI] 你“没有达到目标，睡眠分数很低。”

32
00:01:35.747 --> 00:01:37.127
(Laughter)
[AI] （众笑）

33
00:01:37.151 --> 00:01:38.588
It's like. "Thanks. smart bed.
[AI] 就像。“谢谢，漂亮的床。

34
00:01:38.612 --> 00:01:41.128
As if I didn't already feel like shit today."
[AI] 好像我今天还没觉得自己很糟糕。"

35
00:01:41.152 --> 00:01:42.305
(Laughter)
[AI] （众笑）

36
00:01:42.329 --> 00:01:46.865
All together. I installed 18 internet-connected devices in my home.
[AI] 全部加在一起。我在家里安装了18台连接互联网的设备。

37
00:01:46.889 --> 00:01:49.127
I also installed a Surya.
[AI] 我还安装了Surya。

38
00:01:49.151 --> 00:01:50.532
Surya Mattu: Hi. I'm Surya.
[AI] 苏丽亚·马图：嗨。我是苏里亚。

39
00:01:50.556 --> 00:01:51.754
(Laughter)
[AI] （众笑）

40
00:01:51.778 --> 00:01:54.722
I monitored everything the smart home did.
[AI] 我监控了智能家居所做的一切。

41
00:01:54.746 --> 00:01:58.675
I built a special router that let me look at all the network activity.
[AI] 我建立了一个特殊的路由器，让我可以查看所有的网络活动。

42
00:01:58.699 --> 00:02:01.629
You can think of my router sort of like a security guard.
[AI] 你可以把我的路由器想象成一个保安。

43
00:02:01.653 --> 00:02:03.786
compulsively logging all the network packets
[AI] 强制记录所有网络数据包

44
00:02:03.810 --> 00:02:05.857
as they entered and left the smart home.
[AI] 当他们进出智能家居时。

45
00:02:05.881 --> 00:02:08.635
KH: Surya and I are both journalists. he's not my husband.
[AI] 我和苏里亚都是记者。他不是我丈夫。

46
00:02:08.659 --> 00:02:10.335
we just work together at Gizmodo.
[AI] 我们只是在Gizmodo一起工作。

47
00:02:10.359 --> 00:02:11.748
SM: Thank you for clarifying.
[AI] 山猫：谢谢你的澄清。

48
00:02:11.772 --> 00:02:13.174
The devices Kashmir bought --
[AI] 克什米尔购买的设备--

49
00:02:13.198 --> 00:02:14.890
we were interested in understanding
[AI] 我们对理解感兴趣

50
00:02:14.914 --> 00:02:17.025
what they were saying to their manufacturers.
[AI] 他们对制造商说的话。

51
00:02:17.049 --> 00:02:19.111
But we were also interested in understanding
[AI] 但我们也对理解感兴趣

52
00:02:19.135 --> 00:02:21.505
what the home's digital emissions look like
[AI] 家庭的数字辐射是什么样子的

53
00:02:21.529 --> 00:02:23.794
to the internet service provider.
[AI] 给互联网服务提供商。

54
00:02:23.818 --> 00:02:26.660
We were seeing what the ISP could see. but more importantly.
[AI] 我们看到了ISP能看到的东西。但更重要的是。

55
00:02:26.684 --> 00:02:27.865
what they could sell.
[AI] 他们能卖的东西。

56
00:02:27.889 --> 00:02:30.032
KH: We ran the experiment for two months.
[AI] 我们做了两个月的实验。

57
00:02:30.056 --> 00:02:31.223
In that two months.
[AI] 在那两个月里。

58
00:02:31.247 --> 00:02:34.124
there wasn't a single hour of digital silence in the house --
[AI] 房子里没有一个小时的数码静默--

59
00:02:34.148 --> 00:02:36.080
not even when we went away for a week.
[AI] 即使我们离开一个星期也不行。

60
00:02:36.104 --> 00:02:37.278
SM: Yeah. it's so true.
[AI] 山猫：是的。这是真的。

61
00:02:37.302 --> 00:02:40.318
Based on the data. I knew when you guys woke up and went to bed.
[AI] 根据数据。我知道你们醒来睡觉的时候。

62
00:02:40.342 --> 00:02:42.381
I even knew when Kashmir brushed her teeth.
[AI] 我甚至知道克什米尔什么时候刷牙。

63
00:02:42.405 --> 00:02:44.429
I'm not going to out your brushing habits.
[AI] 我不会改变你刷牙的习惯。

64
00:02:44.453 --> 00:02:48.082
but let's just say it was very clear to me when you were working from home.
[AI] 但我要说的是，当你在家工作时，我很清楚。

65
00:02:48.106 --> 00:02:51.318
KH: Uh. I think you just outed them to. like. a lot of people here.
[AI] 赫：嗯。我想你刚刚把他们告诉了我。喜欢这里有很多人。

66
00:02:51.342 --> 00:02:53.688
SM: Don't be embarrassed. it's just metadata.
[AI] 山猫：别不好意思。这只是元数据。

67
00:02:54.292 --> 00:02:57.435
I knew when you turned on your TV and how long you watched it for.
[AI] 我知道你什么时候打开电视，看了多长时间。

68
00:02:57.459 --> 00:02:59.088
Fun fact about the Hill household:
[AI] 关于希尔家庭的有趣事实：

69
00:02:59.112 --> 00:03:00.906
they don't watch a lot of television.
[AI] 他们不常看电视。

70
00:03:00.930 --> 00:03:03.198
but when they do. it's usually in binge mode.
[AI] 但当他们这样做的时候。它通常处于狂欢模式。

71
00:03:03.222 --> 00:03:06.001
Favorite shows include "Difficult People" and "Party Down."
[AI] 最受欢迎的节目包括“难相处的人”和“聚会结束”

72
00:03:06.025 --> 00:03:08.064
KH: OK. you're right. I loved "Party Down."
[AI] 好的。你说得对。我喜欢“派对结束”

73
00:03:08.088 --> 00:03:10.635
It's a great show. and you should definitely watch it.
[AI] 这是一场精彩的演出。你一定要看。

74
00:03:10.659 --> 00:03:13.103
But "Difficult People" was all my husband. Trevor.
[AI] 但“难相处的人”都是我丈夫。特雷弗。

75
00:03:13.127 --> 00:03:16.730
And Trevor was actually a little upset that you knew about his binges.
[AI] 特雷弗其实有点不高兴，因为你知道他的狂欢。

76
00:03:16.754 --> 00:03:20.088
because even though he'd been the one to connect the TV to the router.
[AI] 因为即使他是那个把电视和路由器连接起来的人。

77
00:03:20.112 --> 00:03:22.559
he forgot that the TV was watching us.
[AI] 他忘了电视在看我们。

78
00:03:22.929 --> 00:03:26.222
It's actually not the first time that our TV has spied on us.
[AI] 事实上，这已经不是我们的电视台第一次监视我们了。

79
00:03:26.246 --> 00:03:27.945
The company that made it. VIZIO.
[AI] 制造它的公司。维齐奥。

80
00:03:27.969 --> 00:03:32.302
paid a 2.2 million-dollar settlement to the government just last year.
[AI] 去年刚刚向政府支付了220万美元的和解金。

81
00:03:32.326 --> 00:03:35.683
because it had been collecting second-by-second information
[AI] 因为它一直在一秒一秒地收集信息

82
00:03:35.707 --> 00:03:39.175
about what millions of people were watching on TV. including us.
[AI] 关于数百万人在电视上观看的内容。包括我们。

83
00:03:39.199 --> 00:03:42.904
and then it was selling that information to data brokers and advertisers.
[AI] 然后它将这些信息卖给数据代理和广告商。

84
00:03:42.928 --> 00:03:46.150
SM: Ah. classic surveillance economy move.
[AI] 山猫：啊。经典的监视经济动作。

85
00:03:46.595 --> 00:03:50.461
The devices Kashmir bought almost all pinged their servers daily.
[AI] 克什米尔购买的设备几乎每天都在ping服务器。

86
00:03:50.485 --> 00:03:52.881
But do you know which device was especially chatty?
[AI] 但是你知道哪个设备特别健谈吗？

87
00:03:52.905 --> 00:03:54.199
The Amazon Echo.
[AI] 亚马逊回声。

88
00:03:54.223 --> 00:03:56.651
It contacted its servers every three minutes.
[AI] 它每三分钟联系一次服务器。

89
00:03:56.675 --> 00:03:58.873
regardless of whether you were using it or not.
[AI] 不管你是否在使用它。

90
00:03:58.897 --> 00:04:01.080
KH: In general. it was disconcerting
[AI] 一般来说。这令人不安

91
00:04:01.104 --> 00:04:04.088
that all these devices were having ongoing conversations
[AI] 所有这些设备都在进行对话

92
00:04:04.112 --> 00:04:05.738
that were invisible to me.
[AI] 那是我看不见的。

93
00:04:05.762 --> 00:04:08.349
I mean. I would have had no idea. without your router.
[AI] 我是说。我不知道。没有你的路由器。

94
00:04:08.373 --> 00:04:11.841
If you buy a smart device. you should probably know --
[AI] 如果你买了智能设备。你应该知道--

95
00:04:11.865 --> 00:04:13.976
you're going to own the device.
[AI] 你将拥有这个设备。

96
00:04:14.000 --> 00:04:17.420
but in general. the company is going to own your data.
[AI] 但总的来说。公司将拥有你的数据。

97
00:04:17.444 --> 00:04:20.016
And you know. I mean. maybe that's to be expected --
[AI] 你知道的。我是说。也许这是意料之中的--

98
00:04:20.040 --> 00:04:23.547
you buy an internet-connected device. it's going to use the internet.
[AI] 你买了一台连接互联网的设备。它将使用互联网。

99
00:04:24.009 --> 00:04:28.533
But it's strange to have these devices moving into the intimate space that is the home
[AI] 但奇怪的是，这些设备进入了家庭的亲密空间

100
00:04:28.557 --> 00:04:32.000
and allowing companies to track our really basic behavior there.
[AI] 允许公司跟踪我们在那里的基本行为。

101
00:04:32.024 --> 00:04:33.183
SM: So true.
[AI] 山猫：真的。

102
00:04:33.207 --> 00:04:36.746
Even the most banal-seeming data can be mined by the surveillance economy.
[AI] 即使是最平庸的数据也可以通过监视经济进行挖掘。

103
00:04:36.770 --> 00:04:39.345
For example. who cares how often you brush your teeth?
[AI] 例如谁在乎你多久刷牙一次？

104
00:04:39.369 --> 00:04:42.895
Well. as it turns out. there's a dental insurance company called Beam.
[AI] 好事实证明。有一家名为Beam的牙科保险公司。

105
00:04:42.919 --> 00:04:46.754
They've been monitoring their customers' smart toothbrushes since 2015 --
[AI] 自2015年以来，他们一直在监控客户的智能牙刷--

106
00:04:46.778 --> 00:04:49.357
for discounts on their premiums. of course.
[AI] 保险费的折扣。当然

107
00:04:49.381 --> 00:04:51.640
KH: We know what some of you are thinking:
[AI] KH：我们知道你们中的一些人在想什么：

108
00:04:51.664 --> 00:04:54.318
this is the contract of the modern world.
[AI] 这是现代世界的契约。

109
00:04:54.342 --> 00:04:55.769
You give up a little privacy.
[AI] 你放弃了一点隐私。

110
00:04:55.793 --> 00:04:59.011
and you get some convenience or some price breaks in return.
[AI] 你会得到一些便利或者一些价格优惠作为回报。

111
00:04:59.334 --> 00:05:01.675
But that wasn't my experience in my smart home.
[AI] 但这不是我在智能家居的经历。

112
00:05:01.699 --> 00:05:05.373
It wasn't convenient. it was infuriating.
[AI] 这不方便。这是令人愤怒的。

113
00:05:05.397 --> 00:05:07.889
I'll admit. I love my smart vacuum.
[AI] 我承认。我喜欢我的智能吸尘器。

114
00:05:07.913 --> 00:05:10.318
but many other things in the house drove me insane:
[AI] 但房子里还有很多其他东西让我发疯：

115
00:05:10.342 --> 00:05:12.738
we ran out of electrical outlets.
[AI] 我们的电源插座用完了。

116
00:05:12.762 --> 00:05:16.141
and I had to download over a dozen apps to my phone
[AI] 我不得不把十几个应用程序下载到我的手机上

117
00:05:16.165 --> 00:05:17.492
to control everything.
[AI] 控制一切。

118
00:05:17.516 --> 00:05:19.605
And then every device had its own log-in.
[AI] 然后每个设备都有自己的登录。

119
00:05:19.629 --> 00:05:21.992
my toothbrush had a password ...
[AI] 我的牙刷有密码。。。

120
00:05:22.016 --> 00:05:23.753
(Laughter)
[AI] （众笑）

121
00:05:23.777 --> 00:05:27.905
And smart coffee. especially. was just a world of hell.
[AI] 还有浓咖啡。尤其地那只是一个地狱的世界。

122
00:05:27.929 --> 00:05:31.857
SM: Wait. really? Cloud-powered coffee wasn't really working for you?
[AI] 山猫：等等。真正地云端咖啡对你来说真的不管用吗？

123
00:05:31.881 --> 00:05:35.119
KH: I mean. maybe I'm naive. but I thought it was going to be great.
[AI] 我是说。也许我太天真了。但我觉得会很棒的。

124
00:05:35.143 --> 00:05:39.162
I thought we'd just wake up in the morning and we'd say. "Alexa. make us coffee."
[AI] 我想我们早上醒来后会说。“亚历山大，给我们煮咖啡。”

125
00:05:39.186 --> 00:05:41.059
But that's not how it went down.
[AI] 但事情并非如此。

126
00:05:41.083 --> 00:05:45.734
We had to use this really particular. brand-specific phrase to make it work.
[AI] 我们必须使用这个非常特别的。品牌特定的短语，使其发挥作用。

127
00:05:45.758 --> 00:05:50.366
It was. "Alexa. ask the Behmor to run quick start."
[AI] 是的。“Alexa.让Behmor运行快速启动。”

128
00:05:51.042 --> 00:05:54.384
And this was just. like. really hard to remember
[AI] 而这只是一个简单的例子。喜欢真的很难记住

129
00:05:54.408 --> 00:05:55.742
first thing in the morning.
[AI] 早上的第一件事。

130
00:05:55.766 --> 00:05:57.469
before you have had your caffeine.
[AI] 在你喝了咖啡因之前。

131
00:05:57.493 --> 00:05:58.596
(Laughter)
[AI] （众笑）

132
00:05:58.620 --> 00:06:00.310
And apparently. it was hard to say.
[AI] 而且很明显。很难说。

133
00:06:00.334 --> 00:06:03.397
because the Echo Dot that was right next to our bed
[AI] 因为就在我们床边的回声点

134
00:06:03.421 --> 00:06:05.032
just couldn't understand us.
[AI] 只是不理解我们。

135
00:06:05.524 --> 00:06:10.145
So we would basically start every day by screaming this phrase at the Echo Dot.
[AI] 所以我们基本上每天都会对着回声点尖叫这个短语。

136
00:06:10.169 --> 00:06:11.342
(Laughter)
[AI] （众笑）

137
00:06:11.366 --> 00:06:12.832
And Trevor hated this.
[AI] 特雷弗讨厌这样。

138
00:06:13.159 --> 00:06:14.907
He'd be like. "Please. Kashmir.
[AI] 他会像。“拜托，克什米尔。

139
00:06:14.931 --> 00:06:18.600
just let me go to the kitchen and push the button to make the coffee run."
[AI] 让我去厨房，按一下按钮，让咖啡开起来。"

140
00:06:19.199 --> 00:06:21.286
And I'd be like. "No. you can't!
[AI] 我会喜欢的。“不，你不能！

141
00:06:21.310 --> 00:06:23.719
We have to do it the smart way!"
[AI] 我们必须以明智的方式去做！"

142
00:06:23.743 --> 00:06:25.659
(Laughter)
[AI] （众笑）

143
00:06:25.683 --> 00:06:28.726
I'm happy to report that our marriage survived the experiment.
[AI] 我很高兴地报告，我们的婚姻在实验中幸存了下来。

144
00:06:28.750 --> 00:06:30.310
but just barely.
[AI] 但几乎没有。

145
00:06:30.334 --> 00:06:32.381
SM: If you decide to make your home smart.
[AI] SM：如果你决定让你的家变得更智能。

146
00:06:32.405 --> 00:06:35.254
hopefully. you’ll find it less infuriating than Kashmir did.
[AI] 有希望地你会发现它不像克什米尔那样令人愤怒。

147
00:06:35.278 --> 00:06:37.365
But regardless. the smart things you buy
[AI] 但无论如何。你买的聪明的东西

148
00:06:37.389 --> 00:06:40.484
can and probably are used to target and profile you.
[AI] 可以而且很可能被用来定位和分析你。

149
00:06:40.961 --> 00:06:44.001
Just the number of devices you have can be used to predict
[AI] 仅仅是你拥有的设备数量就可以用来预测

150
00:06:44.025 --> 00:06:45.447
how rich or poor you are.
[AI] 你是多么富有或贫穷。

151
00:06:45.471 --> 00:06:48.238
Facebook's made this tech. and they've also patented it.
[AI] Facebook制造了这项技术，他们还申请了专利。

152
00:06:48.262 --> 00:06:51.948
KH: All the anxiety you currently feel every time you go online.
[AI] KH：你现在每次上网都会感到焦虑。

153
00:06:51.972 --> 00:06:53.278
about being tracked.
[AI] 关于被跟踪。

154
00:06:53.302 --> 00:06:55.603
is about to move into your living room.
[AI] 就要搬进你的客厅了。

155
00:06:55.627 --> 00:06:57.206
Or into your bedroom.
[AI] 或者进你的卧室。

156
00:06:57.770 --> 00:06:59.992
There's this sex toy called the We-Vibe.
[AI] 有一种叫做“我们感觉”的性玩具。

157
00:07:00.397 --> 00:07:03.064
You might wonder why a sex toy connects to the internet.
[AI] 你可能想知道为什么性玩具会连接到互联网。

158
00:07:03.088 --> 00:07:06.524
but it's for two people who are in a long-distance relationship.
[AI] 但这是为两个处于远距离关系中的人准备的。

159
00:07:06.548 --> 00:07:09.468
so they can share their love from afar.
[AI] 所以他们可以在远方分享他们的爱。

160
00:07:10.079 --> 00:07:12.195
Some hackers took a close look at this toy
[AI] 一些黑客仔细观察了这个玩具

161
00:07:12.219 --> 00:07:14.294
and saw it was sending a lot of information
[AI] 看到它发送了很多信息

162
00:07:14.318 --> 00:07:16.780
back to the company that made it --
[AI] 回到制造它的公司--

163
00:07:16.804 --> 00:07:19.770
when it was used. how long it was used for.
[AI] 当它被使用的时候。它用了多长时间。

164
00:07:19.794 --> 00:07:23.500
what the vibration settings were. how hot the toy got.
[AI] 振动设置是什么。玩具多热啊。

165
00:07:23.524 --> 00:07:25.713
It was all going into a database.
[AI] 这一切都进入了数据库。

166
00:07:25.737 --> 00:07:28.486
So I reached out to the company.
[AI] 所以我向公司求助。

167
00:07:28.510 --> 00:07:31.812
and I said. "Why are you collecting this really sensitive data?"
[AI] 我说。“你为什么收集这些非常敏感的数据？”

168
00:07:32.189 --> 00:07:35.575
And they said. "Well. it's great for market research."
[AI] 他们说。“嗯，这对市场研究很有帮助。”

169
00:07:36.412 --> 00:07:39.341
But they were data-mining their customers' orgasms.
[AI] 但他们正在对顾客的性高潮进行数据挖掘。

170
00:07:39.365 --> 00:07:41.286
And they weren't telling them about it.
[AI] 他们没有告诉他们。

171
00:07:41.310 --> 00:07:43.532
I mean. even if you're cavalier about privacy.
[AI] 我是说。即使你对隐私很傲慢。

172
00:07:43.556 --> 00:07:46.151
I hope that you would admit that's a step too far.
[AI] 我希望你能承认这是一个过分的步骤。

173
00:07:46.500 --> 00:07:49.008
SM: This is why I want to keep my sex toys dumb.
[AI] 山猫：这就是为什么我想让我的性玩具保持沉默。

174
00:07:49.032 --> 00:07:50.198
KH: That's great.
[AI] 那太好了。

175
00:07:50.222 --> 00:07:51.888
We're all very glad to know that.
[AI] 我们都很高兴知道这一点。

176
00:07:51.912 --> 00:07:53.360
(Laughter)
[AI] （众笑）

177
00:07:53.384 --> 00:07:55.418
SM: A data point I'm willing to share.
[AI] SM：一个我愿意分享的数据点。

178
00:07:55.442 --> 00:07:57.165
(Laughter)
[AI] （众笑）

179
00:07:57.189 --> 00:08:00.159
The devices Kashmir bought range from useful to annoying.
[AI] 克什米尔购买的设备从有用到烦人。

180
00:08:00.183 --> 00:08:01.976
But the thing they all had in common
[AI] 但他们都有共同点

181
00:08:02.000 --> 00:08:04.699
was sharing data with the companies that made them.
[AI] 与制造它们的公司共享数据。

182
00:08:04.723 --> 00:08:07.031
With email service providers and social media.
[AI] 与电子邮件服务提供商和社交媒体合作。

183
00:08:07.055 --> 00:08:10.013
we've long been told that if it's free. you're the product.
[AI] 我们早就被告知如果免费的话。你就是产品。

184
00:08:10.037 --> 00:08:12.044
But with the internet of things. it seems.
[AI] 但是有了物联网。似乎是这样。

185
00:08:12.068 --> 00:08:14.076
even if you pay. you're still the product.
[AI] 即使你付钱。你仍然是产品。

186
00:08:14.100 --> 00:08:15.345
So you really have to ask:
[AI] 所以你真的要问：

187
00:08:15.369 --> 00:08:17.554
Who's the true beneficiary of your smart home.
[AI] 谁是你智能家居的真正受益者。

188
00:08:17.578 --> 00:08:19.207
you or the company mining you?
[AI] 你还是挖掘你的公司？

189
00:08:19.231 --> 00:08:21.183
KH: Look. we're a tech savvy crowd here.
[AI] 看。我们是一群精通技术的人。

190
00:08:21.207 --> 00:08:24.319
I think most of us know that these things connect to the internet
[AI] 我想我们大多数人都知道这些东西连接到互联网上

191
00:08:24.343 --> 00:08:25.506
and send data out.
[AI] 并发送数据。

192
00:08:25.530 --> 00:08:29.548
And fine. maybe you're OK with living in that commercial panopticon.
[AI] 很好。也许你可以住在商业全景电视里。

193
00:08:29.572 --> 00:08:30.969
but others aren't.
[AI] 但其他人并非如此。

194
00:08:30.993 --> 00:08:33.834
We need the companies to rethink the design of these devices
[AI] 我们需要这些公司重新考虑这些设备的设计

195
00:08:33.858 --> 00:08:35.373
with our privacy in mind.
[AI] 考虑到我们的隐私。

196
00:08:35.397 --> 00:08:38.508
because we're not all willing to participate in "market research."
[AI] 因为我们并不都愿意参与“市场调查”

197
00:08:38.532 --> 00:08:41.425
just because a device we bought has a Wi-Fi connection.
[AI] 就因为我们买的设备有Wi-Fi连接。

198
00:08:41.834 --> 00:08:43.032
And I have to tell you.
[AI] 我必须告诉你。

199
00:08:43.056 --> 00:08:45.638
even when you're aware. generally. this is happening.
[AI] 即使你意识到了。通常地这正在发生。

200
00:08:45.662 --> 00:08:50.056
it's really easy to forget that normal household items are spying on you.
[AI] 人们很容易忘记，普通的家庭用品正在监视你。

201
00:08:50.484 --> 00:08:52.834
It's easy to forget these things are watching you.
[AI] 很容易忘记这些东西在看着你。

202
00:08:52.858 --> 00:08:54.905
because they don't look like cameras.
[AI] 因为它们看起来不像照相机。

203
00:08:54.929 --> 00:08:56.358
They could look like ...
[AI] 他们可能看起来像。。。

204
00:08:56.382 --> 00:08:58.926
well. they could look like a dildo.
[AI] 好它们看起来像假阴茎。

205
00:08:59.600 --> 00:09:00.752
Thank you.
[AI] 非常感谢。

206
00:09:00.776 --> 00:09:04.462
(Applause)
[AI] （掌声）