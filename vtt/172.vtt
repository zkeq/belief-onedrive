WEBVTT

1
00:00:12.705 --> 00:00:14.250
In ancient Greece,
在古希腊，

2
00:00:15.256 --> 00:00:19.199
when anyone from slaves to soldiers, poets and politicians,
从奴隶到士兵，从诗人到政治家，

3
00:00:19.223 --> 00:00:23.227
needed to make a big decision on life's most important questions,
都需要对人生中最重要的问题做决定，

4
00:00:23.251 --> 00:00:24.642
like, "Should I get married?"
比如，我该结婚吗？

5
00:00:24.666 --> 00:00:26.523
or "Should we embark on this voyage?"
这次出海我该不该去？

6
00:00:26.547 --> 00:00:29.475
or "Should our army advance into this territory?"
我们该不该向那片区域进军？

7
00:00:29.499 --> 00:00:32.078
they all consulted the oracle.
他们纷纷去请教先知。

8
00:00:32.840 --> 00:00:34.280
So this is how it worked:
过程是这样的：

9
00:00:34.304 --> 00:00:37.416
you would bring her a question and you would get on your knees,
你问她一个问题，然后跪在她面前，

10
00:00:36.846 --> 00:00:38.541
and then she would go into this trance.
之后她会进入一种恍惚的状态。

11
00:00:38.541 --> 00:00:40.278
It would take a couple of days,
也许持续几天，

12
00:00:40.908 --> 00:00:43.071
and then eventually she would come out of it,
最终她会恢复清醒状态，

13
00:00:42.951 --> 00:00:45.631
giving you her predictions as your answer.
给出她的预测，回答你的问题。

14
00:00:46.730 --> 00:00:49.296
From the oracle bones of ancient China
从古代中国用骨头占卜，

15
00:00:49.320 --> 00:00:51.665
to ancient Greece to Mayan calendars,
到古希腊，再到玛雅历法，

16
00:00:51.689 --> 00:00:53.985
people have craved for prophecy
人们祈求能得到预言，

17
00:00:53.899 --> 00:00:57.146
in order to find out what's going to happen next.
从而知道未来会发生什么。

18
00:00:58.336 --> 00:01:01.575
And that's because we all want to make the right decision.
因为我们都想做出正确的决定。

19
00:01:01.599 --> 00:01:03.144
We don't want to miss something.
我们不想忽略什么。

20
00:01:03.712 --> 00:01:05.455
The future is scary,
未来是可怕的，

21
00:01:05.479 --> 00:01:08.196
so it's much nicer knowing that we can make a decision
因此若我们 在做决定时多多少少

22
00:01:07.896 --> 00:01:10.202
with some assurance of the outcome.
能预知结果，会更好。

23
00:01:10.899 --> 00:01:12.510
Well, we have a new oracle,
如今我们有了新的先知，

24
00:01:12.534 --> 00:01:14.679
and it's name is big data,
它的名字叫大数据，

25
00:01:14.703 --> 00:01:18.642
or we call it "Watson" or "deep learning" or "neural net."
或者叫它“沃森”或者 “深度学习”或者“神经网络”。

26
00:01:19.160 --> 00:01:23.172
And these are the kinds of questions we ask of our oracle now,
以下就是我们问这位先知的问题。

27
00:01:23.196 --> 00:01:27.118
like, "What's the most efficient way to ship these phones
“要把这些手机从中国运到瑞典，

28
00:01:27.142 --> 00:01:28.965
from China to Sweden?"
怎么做最高效？”

29
00:01:28.989 --> 00:01:30.789
Or, "What are the odds
或者“我的孩子出生时

30
00:01:30.813 --> 00:01:34.176
of my child being born with a genetic disorder?"
患遗传病的几率是多少？”

31
00:01:34.772 --> 00:01:38.016
Or, "What are the sales volume we can predict for this product?"
或者“这件产品的预计销量是多少？”

32
00:01:39.928 --> 00:01:43.975
I have a dog. Her name is Elle, and she hates the rain.
我养了一只狗，名叫艾尔， 她讨厌下雨。

33
00:01:43.999 --> 00:01:47.305
And I have tried everything to untrain her.
我想了很多办法来帮她。

34
00:01:47.329 --> 00:01:50.100
But because I have failed at this,
但是因为我失败了，

35
00:01:50.124 --> 00:01:53.410
I also have to consult an oracle, called Dark Sky,
因此每次准备遛狗时，

36
00:01:52.490 --> 00:01:55.069
every time before we go on a walk,
我都会求助一位先知，叫Dark Sky，

37
00:01:55.093 --> 00:01:58.670
for very accurate weather predictions in the next 10 minutes.
来获得未来10分钟精准的天气预报。

38
00:02:01.355 --> 00:02:02.658
She's so sweet.
小狗真可爱。

39
00:02:03.647 --> 00:02:09.354
So because of all of this, our oracle is a $122 billion industry.
因此，“先知”大数据是 一项价值1220亿美元的产业。

40
00:02:09.826 --> 00:02:13.202
Now, despite the size of this industry,
但尽管产业规模大，

41
00:02:13.226 --> 00:02:15.682
the returns are surprisingly low.
投资回报却出奇地低。

42
00:02:16.162 --> 00:02:18.656
Investing in big data is easy,
投资大数据很简单，

43
00:02:18.680 --> 00:02:20.613
but using it is hard.
但利用它却很难。

44
00:02:21.801 --> 00:02:25.841
Over 73 percent of big data projects aren't even profitable,
超过73%的大数据项目都不赚钱，

45
00:02:25.865 --> 00:02:28.296
and I have executives coming up to me saying,
有经理来找我说，

46
00:02:28.320 --> 00:02:30.109
"We're experiencing the same thing.
“我们的情况也是如此。

47
00:02:29.713 --> 00:02:31.776
We invested in some big data system,
我们投资了一些大数据系统，

48
00:02:31.910 --> 00:02:34.878
and our employees aren't making better decisions.
但雇员们并未因此做出更好的决策。

49
00:02:34.902 --> 00:02:38.064
And they're certainly not coming up with more breakthrough ideas."
更别说提出突破性的想法了。”

50
00:02:38.734 --> 00:02:41.918
So this is all really interesting to me,
我觉得这个现象很有意思，

51
00:02:41.942 --> 00:02:43.952
because I'm a technology ethnographer.
因为我是一名技术人类学家。

52
00:02:44.450 --> 00:02:47.014
I study and I advise companies
我研究人们使用技术的模式，

53
00:02:47.038 --> 00:02:49.521
on the patterns of how people use technology,
并据此为企业提供建议，

54
00:02:49.545 --> 00:02:52.223
and one of my interest areas is data.
数据是我感兴趣的领域之一。

55
00:02:52.247 --> 00:02:57.440
So why is having more data not helping us make better decisions,
为什么更多的数据不能 帮我们更好的决策呢？

56
00:02:57.464 --> 00:03:00.247
especially for companies who have all these resources
尤其是那些资源丰富，

57
00:03:00.271 --> 00:03:02.007
to invest in these big data systems?
能投资大数据系统的公司。

58
00:03:01.967 --> 00:03:04.429
Why isn't it getting any easier for them?
为什么对他们而言， 事情并未变得简单？

59
00:03:05.810 --> 00:03:08.444
So, I've witnessed the struggle firsthand.
我亲眼见过这种困境。

60
00:03:09.194 --> 00:03:12.678
In 2009, I started a research position with Nokia.
2009年，我跟诺基亚 开始进行一项研究。

61
00:03:13.052 --> 00:03:14.210
And at the time,
在当时，

62
00:03:13.980 --> 00:03:17.422
Nokia was one of the largest cell phone companies in the world,
诺基亚是全球最大的 手机生产商之一，

63
00:03:17.416 --> 00:03:20.618
dominating emerging markets like China, Mexico and India --
在中国、墨西哥和印度等 新兴市场占有巨大份额，

64
00:03:20.642 --> 00:03:23.144
all places where I had done a lot of research
我在上述国家进行了大量的研究，

65
00:03:22.924 --> 00:03:25.874
on how low-income people use technology.
看低收入人群是如何使用技术的。

66
00:03:25.868 --> 00:03:28.198
And I spent a lot of extra time in China
我在中国花了大量时间

67
00:03:28.222 --> 00:03:30.814
getting to know the informal economy.
去了解当地的街头经济。

68
00:03:30.838 --> 00:03:33.239
So I did things like working as a street vendor
我当过街边小贩，

69
00:03:33.263 --> 00:03:35.837
selling dumplings to construction workers.
卖饺子给建筑工人。

70
00:03:35.861 --> 00:03:37.219
Or I did fieldwork,
我还泡过网吧，

71
00:03:37.243 --> 00:03:40.201
spending nights and days in internet cafés,
在那里连续待上几天，

72
00:03:40.225 --> 00:03:42.771
hanging out with Chinese youth, so I could understand
跟中国年轻人 混在一起，来了解

73
00:03:42.795 --> 00:03:45.079
how they were using games and mobile phones
他们如何玩游戏和使用手机，

74
00:03:45.103 --> 00:03:48.473
and using it between moving from the rural areas to the cities.
如何在从农村来到城市时使用。

75
00:03:50.155 --> 00:03:54.082
Through all of this qualitative evidence that I was gathering,
通过搜集到的这些 高质量的例证，

76
00:03:54.106 --> 00:03:56.930
I was starting to see so clearly
我开始清晰地看到

77
00:03:56.954 --> 00:04:01.426
that a big change was about to happen among low-income Chinese people.
在中国低收入人群中 将发生巨大的变革。

78
00:04:02.840 --> 00:04:07.207
Even though they were surrounded by advertisements for luxury products
尽管奢华产品的广告随处可见，

79
00:04:06.747 --> 00:04:10.756
like fancy toilets -- who wouldn't want one? --
比如高级马桶——谁不想要？

80
00:04:10.750 --> 00:04:13.640
and apartments and cars,
还有房子和车子，

81
00:04:13.664 --> 00:04:15.484
through my conversations with them,
聊天过程中，

82
00:04:15.508 --> 00:04:19.349
I found out that the ads the actually enticed them the most
我发现最吸引他们的广告，

83
00:04:19.373 --> 00:04:21.369
were the ones for iPhones,
是iPhone的广告，

84
00:04:21.393 --> 00:04:24.445
promising them this entry into this high-tech life.
因为感觉可以将他们 带入高科技生活。

85
00:04:25.289 --> 00:04:28.452
And even when I was living with them in urban slums like this one,
跟他们一起住在 这样的城中村里，

86
00:04:28.476 --> 00:04:31.472
I saw people investing over half of their monthly income
我看到有人花掉超过 半个月的收入

87
00:04:31.496 --> 00:04:33.119
into buying a phone,
去买一部手机，

88
00:04:33.143 --> 00:04:35.445
and increasingly, they were "shanzhai,"
“山寨”越来越多，

89
00:04:35.469 --> 00:04:38.857
which are affordable knock-offs of iPhones and other brands.
就是苹果和其他品牌的 廉价仿冒品。

90
00:04:40.123 --> 00:04:41.748
They're very usable.
它们也能用。

91
00:04:42.710 --> 00:04:44.032
Does the job.
基本功能都有。

92
00:04:44.570 --> 00:04:50.359
And after years of living with migrants and working with them
多年来，我跟这些外地人 一起工作和生活，

93
00:04:50.383 --> 00:04:53.817
and just really doing everything that they were doing,
跟他们做着同样的事情，

94
00:04:53.841 --> 00:04:57.438
I started piecing all these data points together --
我开始把很多数据联系起来，

95
00:04:57.462 --> 00:05:00.585
from the things that seem random, like me selling dumplings,
从随机事件，比如卖饺子，

96
00:05:00.609 --> 00:05:02.413
to the things that were more obvious,
到比较直观的东西，

97
00:05:01.763 --> 00:05:04.859
like tracking how much they were spending on their cell phone bills.
比如看他们会花多少钱买手机。

98
00:05:04.859 --> 00:05:07.956
And I was able to create this much more holistic picture
我更全面地了解了

99
00:05:07.956 --> 00:05:09.312
of what was happening.
发生的事。

100
00:05:09.536 --> 00:05:11.258
And that's when I started to realize
此时我开始意识到，

101
00:05:11.282 --> 00:05:14.791
that even the poorest in China would want a smartphone,
即使是中国最穷的人， 也会想拥有一部智能手机，

102
00:05:14.815 --> 00:05:19.800
and that they would do almost anything to get their hands on one.
而为此他们几乎愿意付出一切。

103
00:05:20.893 --> 00:05:23.297
You have to keep in mind,
别忘了，

104
00:05:23.321 --> 00:05:26.405
iPhones had just come out, it was 2009,
那是2009年， iPhone才刚刚出现，

105
00:05:26.429 --> 00:05:28.314
so this was, like, eight years ago,
差不多是8年前，

106
00:05:28.338 --> 00:05:30.775
and Androids had just started looking like iPhones.
而安卓手机刚开始 长得像iPhone。

107
00:05:30.799 --> 00:05:33.306
And a lot of very smart and realistic people said,
很多聪明而务实的人断言，

108
00:05:33.330 --> 00:05:35.537
"Those smartphones -- that's just a fad.
“这些智能手机，只会昙花一现。

109
00:05:36.063 --> 00:05:39.059
Who wants to carry around these heavy things
谁会愿意拿着这么重的手机，

110
00:05:39.083 --> 00:05:42.570
where batteries drain quickly and they break every time you drop them?"
电量掉得那么快，一摔就坏。”

111
00:05:44.613 --> 00:05:45.814
But I had a lot of data,
但我有数据，

112
00:05:45.838 --> 00:05:48.098
and I was very confident about my insights,
我对自己的见解很自信，

113
00:05:48.122 --> 00:05:50.951
so I was very excited to share them with Nokia.
于是我非常兴奋地告诉诺基亚。

114
00:05:53.152 --> 00:05:55.669
But Nokia was not convinced,
但是诺基亚不为所动，

115
00:05:55.693 --> 00:05:58.028
because it wasn't big data.
因为我给的不是大数据。

116
00:05:58.842 --> 00:06:01.246
They said, "We have millions of data points,
他们说，“我们有几百万的数据，

117
00:06:01.270 --> 00:06:05.517
and we don't see any indicators of anyone wanting to buy a smartphone,
没有数据显示会 有人愿意买智能手机，

118
00:06:05.541 --> 00:06:09.929
and your data set of 100, as diverse as it is, is too weak
而你的数据量只有几百， 还如此分散，毫无说服力，

119
00:06:09.953 --> 00:06:11.667
for us to even take seriously."
根本不值一提。”

120
00:06:12.728 --> 00:06:14.333
And I said, "Nokia, you're right.
我说，“诺基亚，你是对的。

121
00:06:13.893 --> 00:06:15.531
Of course you wouldn't see this,
你当然看不到这些，

122
00:06:15.941 --> 00:06:19.312
because you're sending out surveys assuming that people don't know
因为你在调查时就假定

123
00:06:19.336 --> 00:06:20.495
what a smartphone is,
人们不了解智能手机，

124
00:06:20.519 --> 00:06:22.885
so of course you're not going to get any data back
因此当然得不到数据来了解

125
00:06:22.909 --> 00:06:25.481
about people wanting to buy a smartphone in two years.
2年之内想买智能手机的人。

126
00:06:24.925 --> 00:06:27.287
Your surveys, your methods have been designed
因为你们的调查和方法，

127
00:06:27.647 --> 00:06:29.669
to optimize an existing business model,
目的都是优化现有的商业模式，

128
00:06:29.693 --> 00:06:32.301
and I'm looking at these emergent human dynamics
而我看到的，是前所未有的

129
00:06:32.325 --> 00:06:33.679
that haven't happened yet.
人类新动向。

130
00:06:33.703 --> 00:06:36.141
We're looking outside of market dynamics
我们看的是市场动态之外的东西，

131
00:06:36.165 --> 00:06:37.796
so that we can get ahead of it."
因此可以领先一步。”

132
00:06:39.193 --> 00:06:41.437
Well, you know what happened to Nokia?
都知道诺基亚的结局吧？

133
00:06:41.461 --> 00:06:43.826
Their business fell off a cliff.
他们的生意一落千丈。

134
00:06:44.611 --> 00:06:48.338
This -- this is the cost of missing something.
这就是忽略某些事情的代价。

135
00:06:48.983 --> 00:06:50.982
It was unfathomable.
就是那么难以想象。

136
00:06:51.823 --> 00:06:53.474
But Nokia's not alone.
而诺基亚并非个案。

137
00:06:54.078 --> 00:06:56.659
I see organizations throwing out data all the time
我看到许多组织总是 对数据视而不见，

138
00:06:56.683 --> 00:06:59.244
because it didn't come from a quant model
因为这些数据并非 来自某种数据模型，

139
00:06:58.884 --> 00:07:01.036
or it doesn't fit in one.
或跟模型不符。

140
00:07:02.039 --> 00:07:04.087
But it's not big data's fault.
大数据本身并没有错。

141
00:07:04.762 --> 00:07:08.669
It's the way we use big data; it's our responsibility.
是我们使用不当，错在我们。

142
00:07:09.550 --> 00:07:11.461
Big data's reputation for success
大数据的声名鹊起

143
00:07:11.485 --> 00:07:15.244
comes from quantifying very specific environments,
是因为它能量化特定环境，

144
00:07:15.268 --> 00:07:20.181
like electricity power grids or delivery logistics or genetic code,
比如电网、物流或者基因编码，

145
00:07:20.205 --> 00:07:24.523
when we're quantifying in systems that are more or less contained.
帮我们量化一定程度上 可控的体系。

146
00:07:24.547 --> 00:07:27.516
But not all systems are as neatly contained.
然而并非所有的体系 都有很好的可控性。

147
00:07:27.540 --> 00:07:30.798
When you're quantifying and systems are more dynamic,
对一个动态的体系进行量化，

148
00:07:30.822 --> 00:07:34.621
especially systems that involve human beings,
尤其是牵涉到人时，

149
00:07:34.645 --> 00:07:37.071
forces are complex and unpredictable,
各种因素复杂多变，

150
00:07:37.095 --> 00:07:40.581
and these are things that we don't know how to model so well.
有些因素并没有很好的模型。

151
00:07:41.024 --> 00:07:43.837
Once you predict something about human behavior,
对人的行为进行预测时，

152
00:07:43.861 --> 00:07:45.716
new factors emerge,
会出现新的因素，

153
00:07:45.740 --> 00:07:48.105
because conditions are constantly changing.
因为条件是在不断变化的。

154
00:07:48.129 --> 00:07:49.932
That's why it's a never-ending cycle.
因此这是个永远的循环。

155
00:07:49.956 --> 00:07:51.420
You think you know something,
你以为已经懂了，

156
00:07:50.884 --> 00:07:53.736
and then something unknown enters the picture.
结果新的未知情况又出现了。

157
00:07:53.710 --> 00:07:57.032
And that's why just relying on big data alone
因此，仅仅依靠大数据，

158
00:07:56.922 --> 00:07:59.935
increases the chance that we'll miss something,
反而会使我们更容易 忽略一些事实，

159
00:07:59.929 --> 00:08:03.706
while giving us this illusion that we already know everything.
却给了我们已经掌握一切的错觉。

160
00:08:04.226 --> 00:08:08.082
And what makes it really hard to see this paradox
要看清这样一个矛盾，

161
00:08:08.106 --> 00:08:10.765
and even wrap our brains around it
哪怕仅仅去认真思考它，

162
00:08:10.789 --> 00:08:14.480
is that we have this thing that I call the quantification bias,
也是困难重重， 原因在于我们偏爱量化，

163
00:08:14.504 --> 00:08:18.426
which is the unconscious belief of valuing the measurable
比起不能量化的， 总是不自觉地相信

164
00:08:18.450 --> 00:08:20.044
over the immeasurable.
能够量化的。

165
00:08:21.042 --> 00:08:24.326
And we often experience this at our work.
这在工作中很常见。

166
00:08:24.350 --> 00:08:27.000
Maybe we work alongside colleagues who are like this,
也许我们的同事是这样，

167
00:08:26.934 --> 00:08:29.492
or even our whole entire company may be like this,
甚至整个公司都是这样，

168
00:08:29.476 --> 00:08:32.022
where people become so fixated on that number,
大家都盯着数字，

169
00:08:31.932 --> 00:08:33.907
that they can't see anything outside of it,
而忽略了其他东西，

170
00:08:33.907 --> 00:08:38.085
even when you present them evidence right in front of their face.
即便你将证据摆在他们面前。

171
00:08:38.943 --> 00:08:42.314
And this is a very appealing message,
这一点很有意思，

172
00:08:42.338 --> 00:08:44.681
because there's nothing wrong with quantifying;
因为量化本身并没有什么错，

173
00:08:44.705 --> 00:08:46.135
it's actually very satisfying.
甚至会让人愉悦。

174
00:08:46.159 --> 00:08:50.521
I get a great sense of comfort from looking at an Excel spreadsheet,
看Excel表格时我就感觉挺好的，

175
00:08:50.545 --> 00:08:51.946
even very simple ones.
哪怕表格很简单。

176
00:08:51.970 --> 00:08:52.984
(Laughter)
（笑声）

177
00:08:52.804 --> 00:08:53.460
It's just kind of like,
那感觉就是，

178
00:08:53.460 --> 00:08:57.688
"Yes! The formula worked. It's all OK. Everything is under control."
“好！这个公式能用。 都没问题，一切尽在掌握！”

179
00:08:58.612 --> 00:09:01.002
But the problem is
但问题在于，

180
00:09:01.026 --> 00:09:03.687
that quantifying is addictive.
量化会让人上瘾。

181
00:09:03.711 --> 00:09:05.093
And when we forget that
一旦忘记这点，

182
00:09:05.117 --> 00:09:08.155
and when we don't have something to kind of keep that in check,
又没有什么纠错的机制，

183
00:09:07.895 --> 00:09:10.327
it's very easy to just throw out data
就很容易舍弃

184
00:09:10.321 --> 00:09:13.039
because it can't be expressed as a numerical value.
无法变成数值的信息。

185
00:09:13.063 --> 00:09:15.984
It's very easy just to slip into silver-bullet thinking,
人们很容易执迷于一招鲜，

186
00:09:15.904 --> 00:09:18.587
as if some simple solution existed.
好像总有简单的解决方法。

187
00:09:19.420 --> 00:09:23.482
Because this is a great moment of danger for any organization,
对任何组织来说这都很要命，

188
00:09:23.506 --> 00:09:26.140
because oftentimes, the future we need to predict --
因为通常我们需要预测的未来，

189
00:09:26.164 --> 00:09:28.330
it isn't in that haystack,
不是这干草垛，

190
00:09:28.354 --> 00:09:30.892
but it's that tornado that's bearing down on us
而是谷仓外向我们袭来的

191
00:09:30.916 --> 00:09:32.404
outside of the barn.
龙卷风。

192
00:09:34.780 --> 00:09:37.106
There is no greater risk
最危险的莫过于

193
00:09:37.130 --> 00:09:38.796
than being blind to the unknown.
忽略未知事物。

194
00:09:38.820 --> 00:09:40.969
It can cause you to make the wrong decisions.
这会让你做出错误的决定，

195
00:09:40.993 --> 00:09:42.967
It can cause you to miss something big.
忽略重要的事情。

196
00:09:43.554 --> 00:09:46.655
But we don't have to go down this path.
但我们并非别无选择。

197
00:09:47.273 --> 00:09:50.468
It turns out that the oracle of ancient Greece
其实古希腊的先知们

198
00:09:50.492 --> 00:09:54.458
holds the secret key that shows us the path forward.
已经掌握了解决问题的关键。

199
00:09:55.474 --> 00:09:58.069
Now, recent geological research has shown
最近的地质研究表明，

200
00:09:58.093 --> 00:10:01.657
that the Temple of Apollo, where the most famous oracle sat,
最著名的先知 所在的阿波罗神庙

201
00:10:01.681 --> 00:10:04.765
was actually built over two earthquake faults.
正建在两个地震断层之间。

202
00:10:04.789 --> 00:10:07.675
And these faults would release these petrochemical fumes
断层不断从地下释放出

203
00:10:07.699 --> 00:10:09.384
from underneath the Earth's crust,
石油化学气体。

204
00:10:09.408 --> 00:10:13.274
and the oracle literally sat right above these faults,
先知们恰好坐在这些断层上，

205
00:10:13.298 --> 00:10:16.886
inhaling enormous amounts of ethylene gas, these fissures.
吸入了从断层中 逸出的大量乙烯，

206
00:10:16.910 --> 00:10:17.918
(Laughter)
（笑声）

207
00:10:17.942 --> 00:10:19.115
It's true.
是真的。

208
00:10:18.785 --> 00:10:20.066
(Laughter)
（笑声）

209
00:10:20.180 --> 00:10:23.689
It's all true, and that's what made her babble and hallucinate
没骗你们，因此她才会 产生幻觉，开始呢喃，

210
00:10:23.713 --> 00:10:25.437
and go into this trance-like state.
变得神情恍惚,

211
00:10:25.461 --> 00:10:27.231
She was high as a kite!
她正“飘”着呢！

212
00:10:27.255 --> 00:10:31.716
(Laughter)
（笑声）

213
00:10:31.740 --> 00:10:34.519
So how did anyone --
所以怎么可能——

214
00:10:34.543 --> 00:10:37.573
How did anyone get any useful advice out of her
这种情况下，怎么可能

215
00:10:36.407 --> 00:10:38.787
in this state?
从先知那里得到有用的建议？

216
00:10:39.317 --> 00:10:41.698
Well, you see those people surrounding the oracle?
看到先知身旁的人了吗？

217
00:10:41.722 --> 00:10:43.601
You see those people holding her up,
他们扶着她，

218
00:10:43.625 --> 00:10:45.342
because she's, like, a little woozy?
因为她已经有点晕了。

219
00:10:45.366 --> 00:10:47.674
And you see that guy on your left-hand side
你看左手边那位老兄，

220
00:10:47.698 --> 00:10:49.296
holding the orange notebook?
手里拿着橙色的本子。

221
00:10:49.925 --> 00:10:51.655
Well, those were the temple guides,
他们是神庙向导，

222
00:10:51.679 --> 00:10:54.695
and they worked hand in hand with the oracle.
跟先知一起合作的。

223
00:10:55.904 --> 00:10:58.420
When inquisitors would come and get on their knees,
当求问者跪在先知面前时，

224
00:10:58.444 --> 00:11:00.784
that's when the temple guides would get to work,
神庙向导就要开始介入了，

225
00:11:00.808 --> 00:11:02.672
because after they asked her questions,
求问者提问后，

226
00:11:02.696 --> 00:11:04.697
they would observe their emotional state,
向导开始观察他们的精神状态，

227
00:11:04.721 --> 00:11:07.045
and then they would ask them follow-up questions,
并且问进一步的问题，

228
00:11:05.979 --> 00:11:09.497
like, "Why do you want to know this prophecy? Who are you?
比如，“你为什么想问这个？你是谁？

229
00:11:09.927 --> 00:11:12.191
What are you going to do with this information?"
你要用这个答案来做什么？”

230
00:11:12.215 --> 00:11:15.397
And then the temple guides would take this more ethnographic,
神庙向导利用这些与人更相关的

231
00:11:15.421 --> 00:11:17.577
this more qualitative information,
更有实质意义的信息，

232
00:11:17.601 --> 00:11:19.676
and interpret the oracle's babblings.
来对先知的呢喃进行解释。

233
00:11:21.248 --> 00:11:23.540
So the oracle didn't stand alone,
所以先知并不是孤立的，

234
00:11:23.564 --> 00:11:25.712
and neither should our big data systems.
大数据也不应如此。

235
00:11:26.450 --> 00:11:27.611
Now to be clear,
别误会，

236
00:11:27.635 --> 00:11:31.094
I'm not saying that big data systems are huffing ethylene gas,
我不是说大数据吸了乙烯，

237
00:11:31.118 --> 00:11:33.471
or that they're even giving invalid predictions.
或者大数据的预测没有用。

238
00:11:33.495 --> 00:11:34.656
The total opposite.
完全不是。

239
00:11:34.680 --> 00:11:36.748
But what I am saying
我想说的是，

240
00:11:36.772 --> 00:11:40.604
is that in the same way that the oracle needed her temple guides,
正如先知需要神庙向导们一样，

241
00:11:40.628 --> 00:11:42.916
our big data systems need them, too.
大数据系统也需要协助。

242
00:11:42.940 --> 00:11:47.049
They need people like ethnographers and user researchers
需要人类学家和用户研究人员，

243
00:11:47.073 --> 00:11:49.579
who can gather what I call thick data.
搜集所谓的“厚数据”。

244
00:11:50.322 --> 00:11:53.313
This is precious data from humans,
这是来源于人类的宝贵信息，

245
00:11:53.337 --> 00:11:57.439
like stories, emotions and interactions that cannot be quantified.
比如故事、情感和交流 等不能被量化的东西。

246
00:11:57.463 --> 00:11:59.785
It's the kind of data that I collected for Nokia
像我曾为诺基亚搜集的，

247
00:11:59.809 --> 00:12:02.478
that comes in in the form of a very small sample size,
它们来自很小的样本量，

248
00:12:02.502 --> 00:12:05.457
but delivers incredible depth of meaning.
却能传达意义重大的信息。

249
00:12:05.481 --> 00:12:09.161
And what makes it so thick and meaty
而“厚数据”内涵丰富是因为

250
00:12:10.265 --> 00:12:14.294
is the experience of understanding the human narrative.
其中包含了理解人类生活的过程。

251
00:12:14.318 --> 00:12:17.957
And that's what helps to see what's missing in our models.
这能帮助我们看清 模型中缺失的东西。

252
00:12:18.671 --> 00:12:22.716
Thick data grounds our business questions in human questions,
“厚数据”将商业问题 落实到人类生活，

253
00:12:22.740 --> 00:12:26.302
and that's why integrating big and thick data
因此将大数据和厚数据相结合

254
00:12:26.326 --> 00:12:28.015
forms a more complete picture.
能得到更全面的认识。

255
00:12:28.592 --> 00:12:31.473
Big data is able to offer insights at scale
大数据能在数量级上提供视角，

256
00:12:31.497 --> 00:12:34.144
and leverage the best of machine intelligence,
最大限度利用机器智能，

257
00:12:34.168 --> 00:12:37.740
whereas thick data can help us rescue the context loss
而厚数据能补充 在利用大数据时

258
00:12:37.764 --> 00:12:39.862
that comes from making big data usable,
缺失的情境信息，

259
00:12:39.886 --> 00:12:42.067
and leverage the best of human intelligence.
充分利用人类智慧。

260
00:12:42.091 --> 00:12:45.643
And when you actually integrate the two, that's when things get really fun,
两者结合起来时就很有意思了，

261
00:12:44.927 --> 00:12:47.267
because then you're no longer just working with data
因为这样你不只是在使用

262
00:12:47.267 --> 00:12:48.597
you've already collected.
搜集到的数据。

263
00:12:48.597 --> 00:12:51.338
You get to also work with data that hasn't been collected.
你还能利用尚未搜集到的数据。

264
00:12:51.338 --> 00:12:53.801
You get to ask questions about why:
你可能会问：

265
00:12:53.851 --> 00:12:55.168
Why is this happening?
为什么会这样？

266
00:12:55.598 --> 00:12:56.977
Now, when Netflix did this,
Netflix这么做之后，

267
00:12:56.871 --> 00:13:00.036
they unlocked a whole new way to transform their business.
他们找到了全新的方式 来进行商业转型。

268
00:13:01.226 --> 00:13:05.182
Netflix is known for their really great recommendation algorithm,
Netflix以出色的 推荐算法而闻名，

269
00:13:05.206 --> 00:13:10.003
and they had this $1 million prize for anyone who could improve it.
他们设立了100万美元的奖金， 寻找可以改进它的人。

270
00:13:10.027 --> 00:13:11.341
And there were winners.
有人获奖了。

271
00:13:12.075 --> 00:13:16.398
But Netflix discovered the improvements were only incremental.
但Netflix发现改进太慢。

272
00:13:17.224 --> 00:13:19.188
So to really find out what was going on,
为了彻底弄清原因，

273
00:13:18.692 --> 00:13:22.983
they hired an ethnographer, Grant McCracken,
他们雇了一位人类学家： 格兰特·麦克拉肯，

274
00:13:22.977 --> 00:13:24.523
to gather thick data insights.
来搜集分析厚数据。

275
00:13:24.547 --> 00:13:28.471
And what he discovered was something that they hadn't seen initially
他发现了在一开始的数据分析中

276
00:13:28.495 --> 00:13:29.850
in the quantitative data.
没发现的东西。

277
00:13:30.892 --> 00:13:33.620
He discovered that people loved to binge-watch.
他发现人们喜欢连续看片。

278
00:13:33.644 --> 00:13:35.997
In fact, people didn't even feel guilty about it.
事实上人们才不会内疚。

279
00:13:35.511 --> 00:13:37.306
They enjoyed it.
大家乐在其中。

280
00:13:37.300 --> 00:13:38.326
(Laughter)
（笑声）

281
00:13:38.350 --> 00:13:40.706
So Netflix was like, "Oh. This is a new insight."
于是Netflix觉得， “噢，这是个新见解。”

282
00:13:40.730 --> 00:13:42.668
So they went to their data science team,
于是他们找来数据科学团队，

283
00:13:42.692 --> 00:13:45.010
and they were able to scale this big data insight
将基于厚数据的观点

284
00:13:45.034 --> 00:13:47.621
in with their quantitative data.
跟量化数据进行对比。

285
00:13:47.645 --> 00:13:50.815
And once they verified it and validated it,
这一观点得到验证后，

286
00:13:50.839 --> 00:13:55.600
Netflix decided to do something very simple but impactful.
Netflix决定采取 简单却有效的措施。

287
00:13:56.654 --> 00:14:03.146
They said, instead of offering the same show from different genres
他们不再把同一节目 做成不同体裁，

288
00:14:03.170 --> 00:14:07.058
or more of the different shows from similar users,
也不再给同一类用户 推荐不同节目，

289
00:14:07.082 --> 00:14:09.636
we'll just offer more of the same show.
而是提供同一节目，

290
00:14:09.660 --> 00:14:11.765
We'll make it easier for you to binge-watch.
便于连续观看。

291
00:14:11.789 --> 00:14:13.275
And they didn't stop there.
不仅如此，

292
00:14:12.949 --> 00:14:14.803
They did all these things
他们还想尽一切办法

293
00:14:14.797 --> 00:14:17.756
to redesign their entire viewer experience,
重新规划用户体验，

294
00:14:17.780 --> 00:14:19.538
to really encourage binge-watching.
引导用户连续观看。

295
00:14:20.050 --> 00:14:23.291
It's why people and friends disappear for whole weekends at a time,
于是大家在周末集体消失，

296
00:14:23.315 --> 00:14:25.658
catching up on shows like "Master of None."
都在追《无为大师》这样的剧。

297
00:14:25.682 --> 00:14:29.855
By integrating big data and thick data, they not only improved their business,
通过结合大数据和厚数据， 他们不仅发展了业务，

298
00:14:29.879 --> 00:14:32.691
but they transformed how we consume media.
还转变了人们消费媒体的方式。

299
00:14:32.715 --> 00:14:37.267
And now their stocks are projected to double in the next few years.
他们的股价预计会在 未来几年内翻番。

300
00:14:38.100 --> 00:14:41.930
But this isn't just about watching more videos
但这不只是关于看更多的视频，

301
00:14:41.954 --> 00:14:43.574
or selling more smartphones.
或者卖更多的智能手机。

302
00:14:43.963 --> 00:14:48.013
For some, integrating thick data insights into the algorithm
对某些人而言，将厚数据的观点 整合到算法中，

303
00:14:48.037 --> 00:14:50.300
could mean life or death,
关乎生死，

304
00:14:50.324 --> 00:14:52.470
especially for the marginalized.
尤其是被边缘化的人群。

305
00:14:53.558 --> 00:14:56.992
All around the country, police departments are using big data
全国各地的警察部门都在将大数据

306
00:14:56.782 --> 00:14:58.739
for predictive policing,
用于预防性警务，

307
00:14:58.739 --> 00:15:02.097
to set bond amounts and sentencing recommendations
规划牢房数量， 提供量刑建议，

308
00:15:02.111 --> 00:15:05.258
in ways that reinforce existing biases.
这种的方法更是强化了已有偏见。

309
00:15:06.116 --> 00:15:08.539
NSA's Skynet machine learning algorithm
国安局的天网机器学习算法

310
00:15:08.563 --> 00:15:14.007
has possibly aided in the deaths of thousands of civilians in Pakistan
可能间接导致了几千 巴基斯坦平民丧生，

311
00:15:13.867 --> 00:15:17.002
from misreading cellular device metadata.
因为误读了他们的 蜂窝移动设备的元数据。

312
00:15:18.951 --> 00:15:22.354
As all of our lives become more automated,
随着我们的生活变得更加自动化，

313
00:15:22.378 --> 00:15:25.458
from automobiles to health insurance or to employment,
从汽车到健康保险到就业，

314
00:15:25.482 --> 00:15:27.832
it is likely that all of us
所有人都可能

315
00:15:27.856 --> 00:15:30.845
will be impacted by the quantification bias.
会受量化偏见的负面影响。

316
00:15:32.792 --> 00:15:35.413
Now, the good news is that we've come a long way
不过好消息是，我们已经 有了很大进步，

317
00:15:35.437 --> 00:15:37.887
from huffing ethylene gas to make predictions.
不再吸入乙烯气体， 而是真正做出预测。

318
00:15:37.911 --> 00:15:40.981
We have better tools, so let's just use them better.
我们有了更好的工具， 那就让我们用好它。

319
00:15:41.005 --> 00:15:43.328
Let's integrate the big data with the thick data.
让我们将大数据和 厚数据结合起来，

320
00:15:43.352 --> 00:15:45.613
Let's bring our temple guides with the oracles,
为先知配上神庙向导，

321
00:15:45.637 --> 00:15:49.013
and whether this work happens in companies or nonprofits
无论是在公司、非营利性机构，

322
00:15:48.863 --> 00:15:51.436
or government or even in the software,
还是在政府或者软件公司，

323
00:15:51.530 --> 00:15:53.322
all of it matters,
都很重要，

324
00:15:53.346 --> 00:15:56.369
because that means we're collectively committed
因为这意味着我们共同承诺

325
00:15:56.393 --> 00:15:58.584
to making better data,
提供更好的数据，

326
00:15:58.608 --> 00:16:00.444
better algorithms, better outputs
更好的算法，更好的结果，

327
00:16:00.468 --> 00:16:02.111
and better decisions.
并做出更好的决定。

328
00:16:02.135 --> 00:16:05.693
This is how we'll avoid missing that something.
这样我们才不会忽略重要信息。

329
00:16:07.042 --> 00:16:10.990
(Applause)
（掌声）