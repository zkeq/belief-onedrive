WEBVTT

1
00:00:12.772 --> 00:00:14.534
I'm a meteorologist by degree,
我是一名气象学家，

2
00:00:14.558 --> 00:00:17.701
I have a bachelor's, master's and PhD in physical meteorology,
我有物理气象学的学士、 硕士和博士学位，

3
00:00:17.725 --> 00:00:19.861
so I'm a meteorologist, card carrying.
所以我是个气象学家，有证的。

4
00:00:20.264 --> 00:00:24.963
And so with that comes four questions, always.
然而总有4个问题等着我，

5
00:00:24.987 --> 00:00:27.543
This is one prediction I will always get right.
在这件事儿上我的预测总是对的。

6
00:00:27.567 --> 00:00:29.423
(Laughter)
（笑声）

7
00:00:29.447 --> 00:00:31.495
And those questions are,
这些问题是，

8
00:00:31.519 --> 00:00:34.003
"Marshall, what channel are you on?"
“马修，你在哪个频道呢？”

9
00:00:33.977 --> 00:00:35.828
(Laughter)
（笑声）

10
00:00:35.868 --> 00:00:38.709
"Dr. Shepherd, what's the weather going to be tomorrow?"
“谢博德博士，明天天气怎么样?”

11
00:00:38.733 --> 00:00:39.733
(Laughter)
（笑声）

12
00:00:39.757 --> 00:00:41.344
And oh, I love this one:
啊，我喜欢这个：

13
00:00:41.368 --> 00:00:44.813
"My daughter is getting married next September, it's an outdoor wedding.
“我女儿明年九月结婚， 是个户外婚礼。

14
00:00:44.837 --> 00:00:46.047
Is it going to rain?"
到时会下雨吗？”

15
00:00:45.991 --> 00:00:47.447
(Laughter)
（笑声）

16
00:00:47.477 --> 00:00:50.382
Not kidding, I get those, and I don't know the answer to that,
没开玩笑，我总被问这些问题， 然而我并不知道答案，

17
00:00:50.406 --> 00:00:52.006
the science isn't there.
科学在这儿不管用。

18
00:00:53.005 --> 00:00:55.908
But the one I get a lot these days is,
但我这些天经常被问的是，

19
00:00:55.932 --> 00:01:00.784
"Dr. Shepherd, do you believe in climate change?"
“谢博德博士，你相信气候变化吗？”

20
00:01:01.151 --> 00:01:03.857
"Do you believe in global warming?"
“你相信全球变暖吗？”

21
00:01:04.627 --> 00:01:08.326
Now, I have to gather myself every time I get that question.
如今每次被问到这些问题时， 我都得打起精神。

22
00:01:08.350 --> 00:01:10.112
Because it's an ill-posed question --
因为这是个不恰当的问题——

23
00:01:10.136 --> 00:01:12.136
science isn't a belief system.
科学可不是一个信仰体系。

24
00:01:12.731 --> 00:01:15.997
My son, he's 10 -- he believes in the tooth fairy.
我10岁的儿子相信牙仙的存在。

25
00:01:16.818 --> 00:01:20.207
And he needs to get over that, because I'm losing dollars, fast.
他得克服这一点，因为太费钱了。 （传说牙仙会用金币把小孩子掉的牙换走）

26
00:01:20.231 --> 00:01:22.548
(Laughter)
（笑声）

27
00:01:22.572 --> 00:01:24.397
But he believes in the tooth fairy.
他的确相信牙仙。

28
00:01:24.421 --> 00:01:26.392
But consider this.
但想一想这个。

29
00:01:27.181 --> 00:01:29.729
Bank of America building, there, in Atlanta.
这是亚特兰大的美国银行大楼。

30
00:01:29.753 --> 00:01:32.308
You never hear anyone say,
你从没听到人说，

31
00:01:32.332 --> 00:01:34.911
"Do you believe, if you go to the top of that building
“你相信吗，如果你到那个楼顶，

32
00:01:34.935 --> 00:01:37.189
and throw a ball off, it's going to fall?"
抛个球，它就会掉下去？”

33
00:01:37.627 --> 00:01:40.961
You never hear that, because gravity is a thing.
你从没听过，因为重力是实际存在的。

34
00:01:42.247 --> 00:01:44.532
So why don't we hear the question,
所以为什么我们不会听到这个问题，

35
00:01:44.556 --> 00:01:46.361
"Do you believe in gravity?"
“你相信重力吗？”

36
00:01:46.385 --> 00:01:48.243
But of course, we hear the question,
但我们肯定听过这个问题，

37
00:01:48.267 --> 00:01:50.600
"Do you believe in global warming?"
“你相信全球变暖吗？”

38
00:01:51.981 --> 00:01:54.393
Well, consider these facts.
考虑到这些事实：

39
00:01:55.619 --> 00:01:58.715
The American Association for the Advancement of Science, AAAS,
美国科学促进会，简称AAAS，

40
00:01:58.739 --> 00:02:01.588
one of the leading organizations in science,
这是一个在科学领域的主要组织，

41
00:02:01.612 --> 00:02:05.532
queried scientists and the public on different science topics.
曾就不同的科学课题 向科学家和公众提问。

42
00:02:05.556 --> 00:02:06.755
Here are some of them:
这是其中一些课题：

43
00:02:06.779 --> 00:02:10.706
genetically modified food, animal research, human evolution.
转基因产品，动物研究，人类进化。

44
00:02:11.529 --> 00:02:14.029
And look at what the scientists say about those,
看看科学家对这些怎么说，

45
00:02:14.053 --> 00:02:16.767
the people that actually study those topics, in red,
红色代表那些在研究这些课题的人，

46
00:02:16.791 --> 00:02:19.418
versus the gray, what the public thinks.
灰色，则代表公众的态度。

47
00:02:19.442 --> 00:02:21.028
How did we get there?
这是怎么造成的？

48
00:02:21.802 --> 00:02:23.294
How did we get there?
为什么会有这么大的差异？

49
00:02:24.563 --> 00:02:28.464
That scientists and the public are so far apart on these science issues.
科学家和公众在这些 科学问题上意见如此相左。

50
00:02:29.080 --> 00:02:31.476
Well, I'll come a little bit closer to home for me,
好了，我要说个我比较擅长的，

51
00:02:31.500 --> 00:02:32.650
climate change.
气候变化。

52
00:02:33.159 --> 00:02:36.051
Eighty-seven percent of scientists
87%的科学家

53
00:02:36.075 --> 00:02:40.283
believe that humans are contributing to climate change.
认为是人类的行为导致了气候变化，

54
00:02:41.270 --> 00:02:43.537
But only 50 percent of the public?
但只有50%的公众这样认为。

55
00:02:45.143 --> 00:02:46.524
How did we get there?
为什么会这样？

56
00:02:46.548 --> 00:02:47.851
So it begs the question,
这就引出了问题，

57
00:02:47.875 --> 00:02:52.612
what shapes perceptions about science?
是什么塑造了我们对科学的认知？

58
00:02:54.475 --> 00:02:55.865
It's an interesting question
这是个有趣的问题，

59
00:02:55.889 --> 00:02:58.467
and one that I've been thinking about quite a bit.
我也一直在思考这个问题。

60
00:03:00.254 --> 00:03:04.920
I think that one thing that shapes perceptions in the public, about science,
我想有一件事影响了 公众对科学的看法，

61
00:03:04.944 --> 00:03:07.134
is belief systems and biases.
就是信仰体系和偏见，

62
00:03:08.159 --> 00:03:09.595
Belief systems and biases.
信仰体系和偏见。

63
00:03:09.619 --> 00:03:11.219
Go with me for a moment.
我来解释一下。

64
00:03:11.825 --> 00:03:14.278
Because I want to talk about three elements of that:
我想要谈一谈这个问题的三个元素：

65
00:03:14.302 --> 00:03:17.975
confirmation bias, Dunning-Kruger effect
确认偏误，达克效应

66
00:03:17.999 --> 00:03:19.864
and cognitive dissonance.
和认知失调。

67
00:03:19.888 --> 00:03:23.911
Now, these sound like big, fancy, academic terms, and they are.
这些听起来都有点像不切实际的 学术术语，它们也确实是这样的。

68
00:03:24.405 --> 00:03:28.032
But when I describe them, you're going to be like, "Oh!
但当我进一步做出解释时， 你们就会恍然大悟，“哦！

69
00:03:28.056 --> 00:03:31.789
I recognize that; I even know somebody that does that."
我听说过这个； 我甚至知道有人就是这样的。”

70
00:03:33.175 --> 00:03:34.754
Confirmation bias.
确认偏误。

71
00:03:36.080 --> 00:03:40.552
Finding evidence that supports what we already believe.
寻找证据来支持我们已经相信的事。

72
00:03:40.576 --> 00:03:43.500
Now, we're probably all a little bit guilty of that at times.
我们对此可能多少都难辞其咎。

73
00:03:45.247 --> 00:03:46.786
Take a look at this.
看看这个。

74
00:03:46.810 --> 00:03:48.127
I'm on Twitter.
我有自己的Twitter账户。

75
00:03:48.151 --> 00:03:50.555
And often, when it snows,
通常，遇到下雪的时候，

76
00:03:50.579 --> 00:03:52.468
I'll get this tweet back to me.
我会收到这样的转发。

77
00:03:52.492 --> 00:03:54.968
(Laughter)
（笑声）

78
00:03:54.992 --> 00:03:58.721
"Hey, Dr. Shepherd, I have 20 inches of global warming in my yard,
“嘿，谢博德博士，我院子里 有20英寸的全球变暖（指雪），

79
00:03:58.745 --> 00:04:01.729
what are you guys talking about, climate change?"
你们这些家伙在说啥，气候变化？”

80
00:04:01.753 --> 00:04:03.491
I get that tweet a lot, actually.
我其实收到了很多那样的推特。

81
00:04:04.729 --> 00:04:07.666
It's a cute tweet, it makes me chuckle as well.
这条推特挺逗的，也让我忍俊不禁。

82
00:04:07.690 --> 00:04:11.635
But it's oh, so fundamentally scientifically flawed.
但它在科学上是站不住脚的。

83
00:04:12.112 --> 00:04:13.670
Because it illustrates
因为它说明了

84
00:04:13.694 --> 00:04:15.715
that the person tweeting doesn't understand
发推特的人并不理解

85
00:04:15.739 --> 00:04:17.841
the difference between weather and climate.
天气和气候的差异。

86
00:04:19.286 --> 00:04:22.834
I often say, weather is your mood
我常说，天气是你的情绪，

87
00:04:22.858 --> 00:04:25.317
and climate is your personality.
而气候是你的个性。

88
00:04:26.801 --> 00:04:27.952
Think about that.
想想看。

89
00:04:27.976 --> 00:04:30.420
Weather is your mood, climate is your personality.
天气是你的情绪，气候是你的个性。

90
00:04:30.444 --> 00:04:34.429
Your mood today doesn't necessarily tell me anything about your personality,
你今天的情绪不一定 能代表你的个性，

91
00:04:34.453 --> 00:04:37.223
nor does a cold day tell me anything about climate change,
所以即使有一天特别冷， 也不能说明气候变化了，

92
00:04:37.247 --> 00:04:39.247
or a hot day, for that matter.
有一天特别热，也一样不能代表什么。

93
00:04:41.794 --> 00:04:42.944
Dunning-Kruger.
达克效应。 (高估自己的能力）

94
00:04:43.436 --> 00:04:46.491
Two scholars from Cornell came up with the Dunning-Kruger effect.
康奈尔大学的两位学者 提出了达克效应。

95
00:04:46.515 --> 00:04:48.896
If you go look up the peer-reviewed paper for this,
如果你去查阅同行评议的论文，

96
00:04:48.920 --> 00:04:51.389
you will see all kinds of fancy terminology:
你会看到各种很炫的术语：

97
00:04:51.413 --> 00:04:55.056
it's an illusory superiority complex, thinking we know things.
这是一种虚幻的优越感， 以为我们什么都知道。

98
00:04:55.080 --> 00:04:57.897
In other words, people think they know more than they do.
换句话说，人们高估了 自己所掌握的知识。

99
00:04:59.373 --> 00:05:02.306
Or they underestimate what they don't know.
或者说，他们低估了他们的无知。

100
00:05:02.667 --> 00:05:05.134
And then, there's cognitive dissonance.
然后是认知失调。 （新信息冲击现有认知）

101
00:05:06.651 --> 00:05:08.984
Cognitive dissonance is interesting.
认知失调很有趣。

102
00:05:09.358 --> 00:05:12.008
We just recently had Groundhog Day, right?
我们刚刚过了土拨鼠节，是吧？ （北美传统节日，用土拨鼠预测时令）

103
00:05:12.952 --> 00:05:15.673
Now, there's no better definition of cognitive dissonance
对认知失调最好的解释就好比是，

104
00:05:15.697 --> 00:05:19.215
than intelligent people asking me if a rodent's forecast is accurate.
一个聪明人问我 啮齿动物的预测是否准确。

105
00:05:19.239 --> 00:05:21.970
(Laughter)
（笑声）

106
00:05:21.994 --> 00:05:24.541
But I get that, all of the time.
但我一直都能理解。

107
00:05:24.565 --> 00:05:25.819
(Laughter)
（笑声）

108
00:05:25.843 --> 00:05:29.446
But I also hear about the Farmer's Almanac.
我也听说过黄历。

109
00:05:29.470 --> 00:05:32.666
We grew up on the Farmer's Almanac, people are familiar with it.
我们靠着黄历长大，人们很熟悉它。

110
00:05:34.079 --> 00:05:37.491
The problem is, it's only about 37 percent accurate,
但问题在于，根据 宾夕法尼亚州立大学的研究，

111
00:05:37.515 --> 00:05:40.649
according to studies at Penn State University.
它的准确性只有37%。

112
00:05:43.278 --> 00:05:46.849
But we're in an era of science
但我们身在科学的时代，

113
00:05:46.873 --> 00:05:48.937
where we actually can forecast the weather.
我们确实可以预测天气。

114
00:05:48.961 --> 00:05:52.382
And believe it or not, and I know some of you are like, "Yeah, right,"
不管信不信，我知道你们有些人 会说：“好吧好吧，你说的都对”，

115
00:05:50.686 --> 00:05:55.063
we're about 90 percent accurate, or more, with weather forecast.
我们对天气预测的 准确率有90%或者更高。

116
00:05:55.453 --> 00:05:58.077
You just tend to remember the occasional miss, you do.
但你们只会记得偶尔几次的 失误，可别不承认。

117
00:05:58.101 --> 00:05:59.251
(Laughter)
（笑声）

118
00:06:02.083 --> 00:06:05.488
So confirmation bias, Dunning-Kruger and cognitive dissonance.
所以确认偏误，达克效应和认知失调。

119
00:06:05.512 --> 00:06:10.924
I think those shape biases and perceptions that people have about science.
我认为是这些形成了 人们对科学的偏见和看法。

120
00:06:11.445 --> 00:06:13.594
But then, there's literacy and misinformation
但是，文化素养和错误信息

121
00:06:13.618 --> 00:06:15.685
that keep us boxed in, as well.
也会让我们陷入困境。

122
00:06:17.731 --> 00:06:20.215
During the hurricane season of 2017,
在2017年的飓风季，

123
00:06:20.239 --> 00:06:24.452
media outlets had to actually assign reporters
媒体机构不得不指派记者，

124
00:06:24.476 --> 00:06:28.633
to dismiss fake information about the weather forecast.
驳斥有关天气预报的虚假信息。

125
00:06:30.024 --> 00:06:31.958
That's the era that we're in.
这就是我们所在的时代。

126
00:06:32.464 --> 00:06:34.901
I deal with this all the time in social media.
我一直在社交媒体上应对这些问题。

127
00:06:34.925 --> 00:06:36.512
Someone will tweet a forecast --
有人会在推特上发布预报——

128
00:06:36.536 --> 00:06:39.472
that's a forecast for Hurricane Irma, but here's the problem:
这是飓风厄玛的预报，但问题是：

129
00:06:39.496 --> 00:06:41.496
it didn't come from the Hurricane Center.
它不是官方飓风中心发布的。

130
00:06:42.428 --> 00:06:45.215
But people were tweeting and sharing this; it went viral.
但人们在推特上分享这个， 消息就扩散开了。

131
00:06:45.239 --> 00:06:48.104
It didn't come from the National Hurricane Center at all.
它根本就不是国家飓风中心发布的。

132
00:06:50.183 --> 00:06:52.667
So I spent 12 years of my career at NASA
在来到乔治亚大学之前，

133
00:06:52.691 --> 00:06:54.723
before coming to the University of Georgia,
我在NASA工作了12年，

134
00:06:54.747 --> 00:06:57.262
and I chair their Earth Science Advisory Committee,
我是地球科学咨询委员会的主席，

135
00:06:56.816 --> 00:06:58.717
I was just up there last week in DC.
我上周刚刚去过华盛顿。

136
00:06:58.717 --> 00:07:00.938
And I saw some really interesting things.
我看到了一些很有趣的事情。

137
00:07:00.938 --> 00:07:04.360
Here's a NASA model and science data from satellite
这是NASA的模型和 来自卫星的科学数据

138
00:07:04.400 --> 00:07:06.683
showing the 2017 hurricane season.
显示了2017年飓风季的情况。

139
00:07:06.707 --> 00:07:08.773
You see Hurricane Harvey there?
你们看到那边的哈维飓风没？

140
00:07:09.469 --> 00:07:11.978
Look at all the dust coming off of Africa.
看看这些从非洲飘来的尘土。

141
00:07:12.437 --> 00:07:17.424
Look at the wildfires up in northwest US and in western Canada.
看看美国西北部和加拿大西部的野火。

142
00:07:17.448 --> 00:07:19.248
There comes Hurricane Irma.
飓风厄玛来了。

143
00:07:20.743 --> 00:07:22.886
This is fascinating to me.
这对我很有吸引力。

144
00:07:23.508 --> 00:07:25.603
But admittedly, I'm a weather geek.
无可否认，我是个气象迷。

145
00:07:26.802 --> 00:07:30.278
But more importantly, it illustrates that we have the technology
但更重要的是，它展示了我们拥有的科技

146
00:07:30.302 --> 00:07:32.881
to not only observe the weather and climate system,
不仅可以观察天气和气候系统，

147
00:07:32.905 --> 00:07:34.055
but predict it.
而且可以预测它。

148
00:07:34.445 --> 00:07:36.207
There's scientific understanding,
这就是科学理念，

149
00:07:36.231 --> 00:07:39.318
so there's no need for some of those perceptions and biases
所以我们刚才说的那些观念和偏见

150
00:07:39.342 --> 00:07:40.912
that we've been talking about.
是真的毫无用处。

151
00:07:40.936 --> 00:07:42.135
We have knowledge.
我们拥有知识。

152
00:07:42.159 --> 00:07:43.397
But think about this ...
但是想想这个…

153
00:07:43.421 --> 00:07:46.603
This is Houston, Texas, after Hurricane Harvey.
这是飓风哈维过后的 德克萨斯州休斯顿。

154
00:07:47.556 --> 00:07:50.519
Now, I write a contribution for "Forbes" magazine periodically,
现在，我定期为《福布斯》杂志撰稿，

155
00:07:50.553 --> 00:07:55.084
and I wrote an article a week before Hurricane Harvey made landfall, saying,
在飓风哈维登陆前一周， 我写了一篇文章说，

156
00:07:55.108 --> 00:07:57.950
"There's probably going to be 40 to 50 inches of rainfall."
“可能会有40到50英寸的降雨量。”

157
00:07:58.596 --> 00:08:01.080
I wrote that a week before it happened.
我在它发生的前一周写了这个文章。

158
00:08:01.104 --> 00:08:03.230
But yet, when you talk to people in Houston,
但是，当你和休斯敦的人交谈时，

159
00:08:03.254 --> 00:08:06.327
people are saying, "We had no idea it was going to be this bad."
人们会说，“我没想到会这么糟糕。”

160
00:08:06.913 --> 00:08:08.088
I'm just...
我只能…

161
00:08:08.112 --> 00:08:09.293
(Sigh)
（叹息）

162
00:08:09.317 --> 00:08:10.453
(Laughter)
（笑声）

163
00:08:10.477 --> 00:08:11.651
A week before.
整整提前了一周。

164
00:08:11.675 --> 00:08:12.865
But --
但是——

165
00:08:12.889 --> 00:08:15.387
I know, it's amusing, but the reality is,
我知道这有点可笑，但现实是，

166
00:08:15.411 --> 00:08:21.555
we all struggle with perceiving something outside of our experience level.
让我们理解经验水平之外的 东西真的很困难。

167
00:08:21.579 --> 00:08:23.849
People in Houston get rain all of the time,
休斯顿的人总在经历下雨，

168
00:08:23.873 --> 00:08:25.673
they flood all of the time.
雨水泛滥很平常。

169
00:08:26.333 --> 00:08:28.667
But they've never experienced that.
但他们从没有遭受过那样的情况。

170
00:08:29.381 --> 00:08:33.770
Houston gets about 34 inches of rainfall for the entire year.
休斯顿全年降雨量约为34英寸。

171
00:08:33.794 --> 00:08:36.349
They got 50 inches in three days.
而那段时间，他们 在3天内遭受了50英寸。

172
00:08:37.120 --> 00:08:40.211
That's an anomaly event, that's outside of the normal.
这是异常事件，超出了正常范围。

173
00:08:42.008 --> 00:08:44.849
So belief systems and biases, literacy and misinformation.
所以信仰体系和偏见， 文化素养和错误信息。

174
00:08:44.873 --> 00:08:48.756
How do we step out of the boxes that are cornering our perceptions?
我们如何走出左右我们认知的框框？

175
00:08:50.453 --> 00:08:54.186
Well we don't even have to go to Houston, we can come very close to home.
我们甚至不需要去休斯顿， 在家附近就可以观察到。

176
00:08:54.210 --> 00:08:55.391
(Laughter)
（笑声）

177
00:08:55.415 --> 00:08:57.328
Remember "Snowpocalypse?"
还记得“末日暴雪”吗？

178
00:08:57.352 --> 00:08:59.153
(Laughter)
（笑声）

179
00:08:59.177 --> 00:09:00.677
Snowmageddon?
雪魔？

180
00:09:00.701 --> 00:09:01.852
Snowzilla?
雪巨人？

181
00:09:01.876 --> 00:09:03.905
Whatever you want to call it.
不管你怎么称呼她，

182
00:09:03.929 --> 00:09:06.246
All two inches of it.
都只有两英寸的雪。

183
00:09:06.270 --> 00:09:08.873
(Laughter)
（笑声）

184
00:09:08.897 --> 00:09:11.762
Two inches of snow shut the city of Atlanta down.
两英寸厚的雪就使亚特兰大市瘫痪了。

185
00:09:11.786 --> 00:09:13.357
(Laughter)
（笑声）

186
00:09:14.802 --> 00:09:19.056
But the reality is, we were in a winter storm watch,
但事实是，我们在严防冬季风暴，

187
00:09:19.080 --> 00:09:21.715
we went to a winter weather advisory,
我们去了冬季天气咨询机构，

188
00:09:21.739 --> 00:09:24.389
and a lot of people perceived that as being a downgrade,
很多人都认为雪灾会降级，

189
00:09:24.413 --> 00:09:26.080
"Oh, it's not going to be as bad."
“哦，不会那么糟的。”

190
00:09:25.504 --> 00:09:28.978
When in fact, the perception was that it was not going to be as bad,
事实上，人们的感觉是，不会这么糟糕，

191
00:09:28.978 --> 00:09:30.686
but it was actually an upgrade.
但其实雪灾升级了。

192
00:09:30.686 --> 00:09:33.567
Things were getting worse as the models were coming in.
随着模型的出现，情况在变得更糟。

193
00:09:33.627 --> 00:09:37.433
So that's an example of how we get boxed in by our perceptions.
这就是我们被自己的 认知束缚的一个例子。

194
00:09:37.985 --> 00:09:39.961
So, the question becomes,
所以问题就变成了，

195
00:09:39.985 --> 00:09:43.476
how do we expand our radius?
我们如何扩大我们的认知半径？

196
00:09:45.643 --> 00:09:47.553
The area of a circle is "pi r squared".
圆的面积是 π R的平方。

197
00:09:47.577 --> 00:09:49.820
We increase the radius, we increase the area.
我们增加半径，就能增加面积。

198
00:09:49.844 --> 00:09:53.825
How do we expand our radius of understanding about science?
我们如何扩大我们理解科学的半径？

199
00:09:54.413 --> 00:09:55.813
Here are my thoughts.
这是我的思考。

200
00:09:56.540 --> 00:09:59.611
You take inventory of your own biases.
你们列出自己的偏见。

201
00:09:59.635 --> 00:10:01.651
And I'm challenging you all to do that.
我想让你们所有人都这么做。

202
00:10:01.675 --> 00:10:04.699
Take an inventory of your own biases.
列出你们的偏见。

203
00:10:04.723 --> 00:10:06.008
Where do they come from?
它们来自哪里？

204
00:10:05.992 --> 00:10:09.380
Your upbringing, your political perspective, your faith --
你的教养，你的政治观点，你的信仰——

205
00:10:09.430 --> 00:10:11.849
what shapes your own biases?
你自己的偏见是如何形成的？

206
00:10:13.802 --> 00:10:15.239
Then, evaluate your sources --
然后，评估你的信息来源——

207
00:10:15.263 --> 00:10:17.714
where do you get your information on science?
你在哪里获取科学信息？

208
00:10:18.373 --> 00:10:20.349
What do you read, what do you listen to,
你读什么，你听什么，

209
00:10:20.373 --> 00:10:22.373
to consume your information on science?
什么是你获得科学信息的来源？

210
00:10:22.842 --> 00:10:25.588
And then, it's important to speak out.
然后，重要的是说出来。

211
00:10:25.612 --> 00:10:29.730
Talk about how you evaluated your biases and evaluated your sources.
谈谈你如何评估你的偏见和信息来源。

212
00:10:29.754 --> 00:10:32.524
I want you to listen to this little 40-second clip
我想让你们听听这个40秒的小片段，

213
00:10:32.548 --> 00:10:37.326
from one of the top TV meteorologists in the US, Greg Fishel,
来自美国顶尖的电视 气象学家之一，格雷格·费舍尔，

214
00:10:37.350 --> 00:10:38.873
in the Raleigh, Durham area.
他住在Durham的Raleigh地区。

215
00:10:38.897 --> 00:10:40.572
He's revered in that region.
他在那个地区很受尊敬。

216
00:10:40.596 --> 00:10:42.001
But he was a climate skeptic.
但他是个气候怀疑论者。

217
00:10:41.855 --> 00:10:44.216
But listen to what he says about speaking out.
但是听听他关于发声是怎么说的。

218
00:10:44.286 --> 00:10:46.022
Greg Fishel: The mistake I was making
格雷格·费舍尔： “我犯过的错误，

219
00:10:45.996 --> 00:10:47.984
and didn't realize until very recently,
并且直到最近我才意识到的是，

220
00:10:47.984 --> 00:10:50.611
was that I was only looking for information
我只看那些

221
00:10:50.641 --> 00:10:53.502
to support what I already thought,
能支撑我想法的信息，

222
00:10:53.526 --> 00:10:57.633
and was not interested in listening to anything contrary.
从来不对任何相反的信息感兴趣。

223
00:10:58.379 --> 00:11:00.450
And so I woke up one morning,
所以有一天早晨我醒来，

224
00:11:00.474 --> 00:11:04.172
and there was this question in my mind,
脑海中有个问题，

225
00:11:04.738 --> 00:11:07.342
"Greg, are you engaging in confirmation bias?
‘格雷格，你是不是陷入了确认偏误？

226
00:11:07.366 --> 00:11:11.291
Are you only looking for information to support what you already think?"
你是不是只看那些支持你想法的信息。’

227
00:11:11.889 --> 00:11:14.328
And if I was honest with myself, and I tried to be,
如果我对自己诚实，也试图对自己诚实，

228
00:11:14.342 --> 00:11:16.670
I admitted that was going on.
我得承认是这样的。

229
00:11:17.089 --> 00:11:19.603
And so the more I talked to scientists
所以我和科学家交谈的次数越多，

230
00:11:19.627 --> 00:11:21.685
and read peer-reviewed literature
阅读同行评议的文献越多，

231
00:11:21.709 --> 00:11:26.421
and tried to conduct myself the way I'd been taught to conduct myself
我也努力像我在 宾夕法尼亚州立大学上学时

232
00:11:26.445 --> 00:11:28.778
at Penn State when I was a student,
被教导的那样去要求自己，

233
00:11:29.485 --> 00:11:32.177
it became very difficult for me to make the argument
对我来说，就越难证明

234
00:11:32.201 --> 00:11:34.261
that we weren't at least having some effect.
我们一点也没有被影响。

235
00:11:34.285 --> 00:11:36.721
Maybe there was still a doubt as to how much,
也许，到底被影响了多少还是个疑问，

236
00:11:36.745 --> 00:11:41.460
but to say "nothing" was not a responsible thing for me to do
但作为一个科学家或一个人， 说‘一点也没被影响’

237
00:11:41.484 --> 00:11:43.284
as a scientist or a person.
是一件不负责任的事情。”

238
00:11:45.207 --> 00:11:49.068
JMS: Greg Fishel just talked about expanding his radius
JMS：格雷格·费舍尔刚刚在说

239
00:11:49.092 --> 00:11:50.715
of understanding of science.
扩大他认知科学的半径。

240
00:11:50.739 --> 00:11:52.794
And when we expand our radius,
当我们扩大我们的半径时，

241
00:11:52.818 --> 00:11:56.016
it's not about making a better future,
不是为了创造一个更好的未来，

242
00:11:55.980 --> 00:11:59.107
but it's about preserving life as we know it.
而是为了保留我们所知的生活。

243
00:12:00.000 --> 00:12:04.954
So as we think about expanding our own radius in understanding science,
所以当我们想要扩大 我们对科学的理解范围时，

244
00:12:06.112 --> 00:12:09.484
it's critical for Athens, Georgia, for Atlanta, Georgia,
这对乔治亚州的雅典和亚特兰大，

245
00:12:09.508 --> 00:12:12.366
for the state of Georgia, and for the world.
对乔治亚州和整个世界都很重要。

246
00:12:12.677 --> 00:12:14.748
So expand your radius.
所以，扩大你的半径吧。

247
00:12:14.772 --> 00:12:15.955
Thank you.
谢谢。

248
00:12:15.979 --> 00:12:19.994
(Applause)
（鼓掌）