WEBVTT

1
00:00:12.860 --> 00:00:15.367
I want to tell you guys something about neuroscience.
我想跟各位聊一聊神经科学。

2
00:00:15.860 --> 00:00:17.660
I'm a physicist by training.
我是物理学家，科班出身。

3
00:00:18.050 --> 00:00:20.256
About three years ago, I left physics
大约三年前，我离开了物理学领域，

4
00:00:20.280 --> 00:00:22.629
to come and try to understand how the brain works.
转行到神经科学，试图了解 大脑是如何工作的。

5
00:00:22.653 --> 00:00:24.127
And this is what I found.
我发现，

6
00:00:23.849 --> 00:00:26.203
Lots of people are working on depression.
很多人都在研究抑郁症。

7
00:00:26.239 --> 00:00:27.398
And that's really good,
这非常好，

8
00:00:27.422 --> 00:00:30.143
depression is something that we really want to understand.
我们的确特别想了解抑郁症。

9
00:00:29.733 --> 00:00:31.070
Here's how you do it:
但研究是这样进行的：

10
00:00:31.358 --> 00:00:35.519
you take a jar and you fill it up, about halfway, with water.
拿个罐子，装上大约半罐的水。

11
00:00:35.543 --> 00:00:39.725
And then you take a mouse, and you put the mouse in the jar, OK?
然后找一只老鼠，把它放进罐子里。

12
00:00:39.749 --> 00:00:42.099
And the mouse swims around for a little while
老鼠四处游了一会儿，

13
00:00:42.123 --> 00:00:44.511
and then at some point, the mouse gets tired
到某一时刻，老鼠累了，

14
00:00:44.535 --> 00:00:46.469
and decides to stop swimming.
决定不游了。

15
00:00:46.493 --> 00:00:49.626
And when it stops swimming, that's depression.
它一旦不游了，就是得了抑郁症。

16
00:00:50.516 --> 00:00:51.666
OK?
对吗？

17
00:00:52.111 --> 00:00:55.491
And I'm from theoretical physics,
我以前是学理论物理的，

18
00:00:55.515 --> 00:00:59.183
so I'm used to people making very sophisticated mathematical models
所以我习惯了 用非常复杂的数学模型

19
00:00:59.207 --> 00:01:02.088
to precisely describe physical phenomena,
来精确描述物理现象，

20
00:01:02.112 --> 00:01:04.564
so when I saw that this is the model for depression,
所以当我看到抑郁症的 模型是这个样子时，

21
00:01:04.588 --> 00:01:07.525
I though to myself, "Oh my God, we have a lot of work to do."
我心想，“天呐， 要做的工作还多着呢。”

22
00:01:07.549 --> 00:01:08.919
(Laughter)
（笑声）

23
00:01:08.943 --> 00:01:11.894
But this is a kind of general problem in neuroscience.
但这问题在神经科学中 几乎普遍存在。

24
00:01:11.894 --> 00:01:14.215
So for example, take emotion.
比如说，以情绪为例。

25
00:01:14.332 --> 00:01:16.791
Lots of people want to understand emotion.
很多人想理解情绪。

26
00:01:17.172 --> 00:01:20.485
But you can't study emotion in mice or monkeys
但是，在老鼠或猴子身上 没法研究情绪，

27
00:01:20.509 --> 00:01:21.763
because you can't ask them
因为你不能问它们

28
00:01:21.787 --> 00:01:24.104
how they're feeling or what they're experiencing.
感觉如何或正在经历什么。

29
00:01:23.656 --> 00:01:26.053
So instead, people who want to understand emotion,
所以，想要理解情绪的人

30
00:01:26.509 --> 00:01:29.286
typically end up studying what's called motivated behavior,
通常变成研究所谓的行为激励法，

31
00:01:29.310 --> 00:01:32.968
which is code for "what the mouse does when it really, really wants cheese."
这个术语的意思是“老鼠 特别特别想要奶酪时会做什么”。

32
00:01:33.659 --> 00:01:35.334
OK, I could go on and on.
我可以没完没了地说下去。

33
00:01:35.358 --> 00:01:41.674
I mean, the point is, the NIH spends about 5.5 billion dollars a year
我的意思是，关键在于， NIH每年花费大约55亿美元

34
00:01:41.698 --> 00:01:43.230
on neuroscience research.
用于神经科学研究。

35
00:01:43.254 --> 00:01:46.857
And yet there have been almost no significant improvements in outcomes
然而，在过去40年中， 对脑病患者的治疗效果

36
00:01:46.881 --> 00:01:50.372
for patients with brain diseases in the past 40 years.
几乎没有获得任何显著的进步。

37
00:01:50.835 --> 00:01:53.375
And I think a lot of that is basically due to the fact
我认为，这在很大程度上是由于

38
00:01:53.399 --> 00:01:57.550
that mice might be OK as a model for cancer or diabetes,
老鼠也许能做癌症 或糖尿病的模型，

39
00:01:57.574 --> 00:02:00.261
but the mouse brain is just not sophisticated enough
但是老鼠的大脑却不够复杂，

40
00:02:00.285 --> 00:02:03.460
to reproduce human psychology or human brain disease.
无法复制人类的心理 或人类的脑部疾病。

41
00:02:04.199 --> 00:02:05.424
OK?
对吧？

42
00:02:05.448 --> 00:02:09.082
So if the mouse models are so bad, why are we still using them?
那么，既然老鼠模型那么差， 为什么我们还在用它？

43
00:02:09.963 --> 00:02:12.066
Well, it basically boils down to this:
原因大致是这样的：

44
00:02:12.090 --> 00:02:14.646
the brain is made up of neurons
大脑是由神经元组成的，

45
00:02:14.670 --> 00:02:18.117
which are these little cells that send electrical signals to each other.
这些神经元是相互发送 电信号的小细胞。

46
00:02:18.500 --> 00:02:20.644
If you want to understand how the brain works,
如果你想了解大脑是如何工作的，

47
00:02:20.668 --> 00:02:24.476
you have to be able to measure the electrical activity of these neurons.
就必须能够测量 这些神经元的电活动。

48
00:02:25.159 --> 00:02:28.151
But to do that, you have to get really close to the neurons
但要做到这一点，你必须

49
00:02:28.175 --> 00:02:31.103
with some kind of electrical recording device or a microscope.
用某种电记录设备或显微镜 来真正接近神经元。

50
00:02:31.383 --> 00:02:34.193
And so you can do that in mice and you can do it in monkeys,
这个可以在老鼠身上做， 也可以在猴子身上做，

51
00:02:34.217 --> 00:02:36.765
because you can physically put things into their brain
因为你可以真正地把 设备放进它们的大脑，

52
00:02:36.789 --> 00:02:39.835
but for some reason we still can't do that in humans, OK?
但是由于某些原因，我们 还不能在人类身上这样做，对吧？

53
00:02:40.353 --> 00:02:43.723
So instead, we've invented all these proxies.
所以，我们发明了各种替代工具。

54
00:02:43.747 --> 00:02:46.262
So the most popular one is probably this,
最流行的应该是这个，

55
00:02:46.286 --> 00:02:48.683
functional MRI, fMRI,
功能性磁共振成像，fMRI，

56
00:02:48.707 --> 00:02:51.399
which allows you to make these pretty pictures like this,
它可以做出这样的美丽图片，

57
00:02:51.423 --> 00:02:53.479
that show which parts of your brain light up
显示当你从事不同的活动时，

58
00:02:53.503 --> 00:02:55.629
when you're engaged in different activities.
大脑的哪个部分会发光。

59
00:02:55.653 --> 00:02:57.573
But this is a proxy.
但这只是一个替代工具。

60
00:02:57.597 --> 00:03:00.889
You're not actually measuring neural activity here.
你实际上并不是在测量神经活动。

61
00:03:00.913 --> 00:03:03.755
What you're doing is you're measuring, essentially,
你是在测量大脑中的

62
00:03:03.779 --> 00:03:05.611
like, blood flow in the brain.
血液流动。

63
00:03:05.635 --> 00:03:06.873
Where there's more blood.
看哪里的含血量更高。

64
00:03:06.897 --> 00:03:10.000
It's actually where there's more oxygen, but you get the idea, OK?
其实是看哪里氧气多， 但你懂我意思了，对吧？

65
00:03:09.630 --> 00:03:12.519
The other thing that you can do is you can do this --
另一种方法是这个——

66
00:03:12.567 --> 00:03:16.158
electroencephalography -- you can put these electrodes on your head, OK?
脑电图——可以把 这些电极放在你的头上，

67
00:03:16.182 --> 00:03:18.325
And then you can measure your brain waves.
然后可以测量你的脑电波。

68
00:03:18.945 --> 00:03:22.024
And here, you're actually measuring electrical activity.
而这实际上是在测量电活动。

69
00:03:22.048 --> 00:03:24.413
But you're not measuring the activity of neurons.
而不是在测量神经元的活动。

70
00:03:24.731 --> 00:03:27.175
You're measuring these electrical currents,
你测量的是这些电流，

71
00:03:26.955 --> 00:03:29.474
sloshing back and forth in your brain.
在你的大脑中来回流动的电流。

72
00:03:29.977 --> 00:03:32.651
So the point is just that these technologies that we have
所以问题是，我们所拥有的这些技术

73
00:03:32.675 --> 00:03:35.111
are really measuring the wrong thing.
实际上是在测量错误的东西。

74
00:03:35.135 --> 00:03:38.088
Because, for most of the diseases that we want to understand --
因为，对于我们想了解的 大多数疾病——

75
00:03:37.880 --> 00:03:40.238
like, Parkinson's is the classic example.
比如帕金森症就是典型的例子。

76
00:03:40.334 --> 00:03:43.888
In Parkinson's, there's one particular kind of neuron deep in your brain
对于帕金森症，大脑深处 有一种特殊的神经元

77
00:03:43.912 --> 00:03:45.643
that is responsible for the disease,
对这种疾病负责，

78
00:03:45.667 --> 00:03:48.849
and these technologies just don't have the resolution that you need
而现有的这些技术还没有办法

79
00:03:48.873 --> 00:03:50.246
to get at that.
检测这些神经元。

80
00:03:50.270 --> 00:03:54.244
And so that's why we're still stuck with the animals.
所以这就是为什么 我们仍然在用动物。

81
00:03:54.268 --> 00:03:56.801
Not that anyone wants to be studying depression
谁也不是真的想

82
00:03:56.825 --> 00:03:59.087
by putting mice into jars, right?
用罐子里的老鼠 来研究抑郁症，对吧？

83
00:03:59.111 --> 00:04:02.864
It's just that there's this pervasive sense that it's not possible
只是有一种共识告诉我们，

84
00:04:02.888 --> 00:04:06.735
to look at the activity of neurons in healthy humans.
不可能观察到 健康人的神经元活动。

85
00:04:08.000 --> 00:04:09.492
So here's what I want to do.
那么，接下来，

86
00:04:09.794 --> 00:04:12.315
I want to take you into the future.
我想带你们进入未来。

87
00:04:12.339 --> 00:04:16.821
To have a look at one way in which I think it could potentially be possible.
看一看我认为有可能的一种方式。

88
00:04:17.346 --> 00:04:20.644
And I want to preface this by saying, I don't have all the details.
首先我想说，我没有完善的细节。

89
00:04:21.092 --> 00:04:24.059
So I'm just going to provide you with a kind of outline.
所以我只提供大概的介绍。

90
00:04:23.999 --> 00:04:26.459
But we're going to go the year 2100.
我们要去的是2100年。

91
00:04:27.552 --> 00:04:29.851
Now what does the year 2100 look like?
2100年是什么样子呢？

92
00:04:29.875 --> 00:04:33.393
Well, to start with, the climate is a bit warmer that what you're used to.
首先，气候比你习惯的暖和一点。

93
00:04:33.417 --> 00:04:37.000
(Laughter)
（笑声）

94
00:04:36.952 --> 00:04:41.820
And that robotic vacuum cleaner that you know and love
你了解并喜爱的机器人真空吸尘器

95
00:04:41.820 --> 00:04:43.564
went through a few generations,
进化了好几代，

96
00:04:43.538 --> 00:04:46.381
and the improvements were not always so good.
但进化的结果不怎么样。

97
00:04:46.405 --> 00:04:48.000
(Laughter)
（笑声）

98
00:04:48.350 --> 00:04:50.660
It was not always for the better.
并不总是越来越好。

99
00:04:52.041 --> 00:04:56.579
But actually, in the year 2100 most things are surprisingly recognizable.
但实际上，在2100年， 我们居然还能认出大部分的事物，

100
00:04:57.278 --> 00:05:00.012
It's just the brain is totally different.
只是大脑完全不同了。

101
00:05:00.560 --> 00:05:03.107
For example, in the year 2100,
例如，在2100年，

102
00:05:03.131 --> 00:05:05.988
we understand the root causes of Alzheimer's.
我们了解了阿尔茨海默症的病源。

103
00:05:05.964 --> 00:05:08.308
So we can deliver targeted genetic therapies or drugs
所以我们可以在 大脑功能退化开始之前，

104
00:05:08.308 --> 00:05:12.554
to stop the degenerative process before it begins.
提供有针对性的基因治疗 或药物来阻止退化。

105
00:05:13.449 --> 00:05:14.782
So how did we do it?
那是怎么做到的呢？

106
00:05:15.718 --> 00:05:17.956
Well, there were essentially three steps.
基本上有三个步骤。

107
00:05:18.409 --> 00:05:21.223
The first step was that we had to figure out
第一步，我们必须想办法

108
00:05:21.247 --> 00:05:24.540
some way to get electrical connections through the skull
让电信号的连接穿过头骨，

109
00:05:24.564 --> 00:05:27.579
so we could measure the electrical activity of neurons.
这样我们就可以测量 神经元的电活动。

110
00:05:28.159 --> 00:05:32.508
And not only that, it had to be easy and risk-free.
不仅如此，这一过程还必须 容易操作且无风险。

111
00:05:32.532 --> 00:05:34.910
Something that basically anyone would be OK with,
它必须是人人都能接受的，

112
00:05:34.934 --> 00:05:36.534
like getting a piercing.
就像穿个耳洞。

113
00:05:36.976 --> 00:05:39.723
Because back in 2017,
因为早在2017年，

114
00:05:39.747 --> 00:05:42.660
the only way that we knew of to get through the skull
人们知道的穿过头骨的唯一方法

115
00:05:42.684 --> 00:05:45.501
was to drill these holes the size of quarters.
就是钻出硬币大小的洞。

116
00:05:45.835 --> 00:05:47.874
You would never let someone do that to you.
谁都不会接受的。

117
00:05:48.787 --> 00:05:51.040
So in the 2020s,
所以在21世纪20年代，

118
00:05:51.064 --> 00:05:54.445
people began to experiment -- rather than drilling these gigantic holes,
人们开始实验—— 不是钻这些巨大的孔，

119
00:05:54.469 --> 00:05:57.584
drilling microscopic holes, no thicker than a piece of hair.
而是钻出不到一根头发丝 那么厚的微型孔。

120
00:05:58.555 --> 00:06:00.651
And the idea here was really for diagnosis --
这个方法实际是用于诊断——

121
00:06:00.675 --> 00:06:03.461
there are lots of times in the diagnosis of brain disorders
在脑部疾病的诊断中，有很多时候，

122
00:06:03.485 --> 00:06:08.357
when you would like to be able to look at the neural activity beneath the skull
你希望能够看到 颅骨底下的神经活动，

123
00:06:08.381 --> 00:06:11.572
and being able to drill these microscopic holes
而能够钻这些微小的孔，

124
00:06:11.596 --> 00:06:13.738
would make that much easier for the patient.
会让病人更容易 接受这种诊断方法。

125
00:06:13.762 --> 00:06:16.111
In the end, it would be like getting a shot.
最终，它就像打针。

126
00:06:15.991 --> 00:06:17.731
You just go in and you sit down
你只要到医院，坐下来，

127
00:06:17.739 --> 00:06:20.040
and there's a thing that comes down on your head,
有个设备降到你的头上，

128
00:06:19.602 --> 00:06:21.985
and a momentary sting and then it's done,
短暂的一下刺痛，就完事了，

129
00:06:21.985 --> 00:06:23.919
and you can go back about your day.
你可以回去继续忙你的了。

130
00:06:24.556 --> 00:06:29.349
So we're eventually able to do it
最终，我们能够用激光钻孔

131
00:06:29.373 --> 00:06:32.040
using lasers to drill the holes.
来实现这种方法。

132
00:06:32.064 --> 00:06:34.684
And with the lasers, it was fast and extremely reliable,
激光又快又非常可靠，

133
00:06:34.708 --> 00:06:36.921
you couldn't even tell the holes were there,
你甚至感觉不到有孔，

134
00:06:36.945 --> 00:06:39.945
any more than you could tell that one of your hairs was missing.
就像感觉不到掉了一根头发一样。

135
00:06:40.573 --> 00:06:45.311
And I know it might sound crazy, using lasers to drill holes in your skull,
我知道用激光在颅骨上钻孔 听起来可能很疯狂，

136
00:06:45.335 --> 00:06:46.701
but back in 2017,
但早在2017年，

137
00:06:46.725 --> 00:06:50.834
people were OK with surgeons shooting lasers into their eyes
人们就已经接受外科医生向 他们的眼睛里发射激光了，

138
00:06:50.858 --> 00:06:52.072
for corrective surgery
就为了做矫正手术，

139
00:06:52.096 --> 00:06:55.983
So when you're already here, it's not that big of a step.
所以，有了这个基础， 跨度也就不显得那么大了。

140
00:06:57.381 --> 00:06:58.532
OK?
对吧？

141
00:06:58.556 --> 00:07:02.127
So the next step, that happened in the 2030s,
下一步，发生在2030年代的，

142
00:07:02.151 --> 00:07:05.237
was that it's not just about getting through the skull.
就不仅仅是穿过头骨了。

143
00:07:05.261 --> 00:07:06.961
To measure the activity of neurons,
为了测量神经元的活动，

144
00:07:06.985 --> 00:07:10.810
you have to actually make it into the brain tissue itself.
你必须真正进入大脑组织本身。

145
00:07:10.994 --> 00:07:13.632
And the risk, whenever you put something into the brain tissue,
而风险是，只要往脑组织里放东西，

146
00:07:13.632 --> 00:07:15.571
is essentially that of stroke.
那基本上就等于在引发中风。

147
00:07:15.619 --> 00:07:17.815
That you would hit a blood vessel and burst it,
你会碰到血管并使其破裂，

148
00:07:17.839 --> 00:07:19.358
and that causes a stroke.
从而导致中风。

149
00:07:19.736 --> 00:07:23.461
So, by the mid 2030s, we had invented these flexible probes
所以，到2030年代中期， 我们发明了柔性探针，

150
00:07:23.485 --> 00:07:25.763
that were capable of going around blood vessels,
它能围绕血管安置，

151
00:07:25.787 --> 00:07:27.263
rather than through them.
而不用穿过血管。

152
00:07:27.287 --> 00:07:32.984
And thus, we could put huge batteries of these probes
因此，我们可以将 这些探针的巨大电池

153
00:07:32.912 --> 00:07:34.339
into the brains of patients
放入病人的大脑中，

154
00:07:34.389 --> 00:07:37.659
and record from thousands of their neurons without any risk to them.
对成千上万个神经元 进行记录，而不带来风险。

155
00:07:39.278 --> 00:07:43.339
And what we discovered, sort of to our surprise,
令人惊讶的是，我们发现，

156
00:07:43.363 --> 00:07:45.553
is that the neurons that we could identify
我们能识别的神经元

157
00:07:45.577 --> 00:07:49.101
were not responding to things like ideas or emotion,
对想法或情绪之类的东西 并没有做出反应，

158
00:07:49.125 --> 00:07:50.752
which was what we had expected.
这就与我们所期望的不一样。

159
00:07:50.776 --> 00:07:54.572
They were mostly responding to things like Jennifer Aniston
让它们有反应的是 珍妮弗 · 安妮斯顿、

160
00:07:54.596 --> 00:07:57.000
or Halle Berry
哈里 · 贝瑞、

161
00:07:56.880 --> 00:07:58.360
or Justin Trudeau.
或贾斯汀 · 特鲁多。

162
00:07:58.358 --> 00:07:59.611
I mean --
我的意思是——

163
00:07:59.635 --> 00:08:01.961
(Laughter)
（笑声）

164
00:08:01.985 --> 00:08:04.422
In hindsight, we shouldn't have been that surprised.
事后看来，也不用太惊讶。

165
00:08:04.446 --> 00:08:07.708
I mean, what do your neurons spend most of their time thinking about?
再说，你的神经元 大部分时间想的是什么呢？

166
00:08:07.732 --> 00:08:08.882
(Laughter)
（笑声）

167
00:08:09.200 --> 00:08:11.240
But really, the point is that
但说真的，关键是，

168
00:08:11.264 --> 00:08:15.694
this technology enabled us to begin studying neuroscience in individuals.
这项技术使我们能够开始 以个体为单位研究神经科学。

169
00:08:15.718 --> 00:08:19.948
So much like the transition to genetics, at the single cell level,
就像遗传学转化到 单细胞水平的研究，

170
00:08:19.972 --> 00:08:23.178
we started to study neuroscience, at the single human level.
我们开始在单个人类水平上 研究神经科学。

171
00:08:23.710 --> 00:08:25.328
But we weren't quite there yet.
但这一步也还不够。

172
00:08:25.715 --> 00:08:27.357
Because these technologies
因为这些技术

173
00:08:27.381 --> 00:08:30.437
were still restricted to medical applications,
仍然局限于医学应用，

174
00:08:30.461 --> 00:08:33.852
which meant that we were studying sick brains, not healthy brains.
意味着我们研究的是病态大脑， 而不是健康的大脑。

175
00:08:35.055 --> 00:08:38.809
Because no matter how safe your technology is,
因为不管技术有多安全，

176
00:08:38.833 --> 00:08:41.563
you can't stick something into someone's brain
你都不能为了研究目的把东西塞进

177
00:08:41.587 --> 00:08:43.007
for research purposes.
别人的大脑。

178
00:08:42.959 --> 00:08:44.608
They have to want it.
人们必须自己想要这么做。

179
00:08:44.604 --> 00:08:46.064
And why would they want it?
那人们为什么想这么做呢？

180
00:08:46.088 --> 00:08:49.659
Because as soon as you have an electrical connection to the brain,
因为一旦大脑通了电，

181
00:08:49.683 --> 00:08:52.127
you can use it to hook the brain up to a computer.
就可以把人脑连接到电脑上。

182
00:08:52.881 --> 00:08:56.310
Oh, well, you know, the general public was very skeptical at first.
你知道，公众一开始很怀疑。

183
00:08:56.334 --> 00:08:59.203
I mean, who wants to hook their brain up to their computers?
谁想把自己的大脑连到电脑上呢？

184
00:08:59.746 --> 00:09:03.982
Well just imagine being able to send an email with a thought.
那想象一下，你可以 用你的想法来发电邮。

185
00:09:03.962 --> 00:09:06.235
(Laughter)
（笑声）

186
00:09:06.283 --> 00:09:10.783
Imagine being able to take a picture with your eyes, OK?
想象一下能用眼睛拍照。

187
00:09:10.807 --> 00:09:12.037
(Laughter)
（笑声）

188
00:09:11.965 --> 00:09:14.978
Imagine never forgetting anything anymore,
想象永远不会忘记任何东西，

189
00:09:14.978 --> 00:09:17.197
because anything that you choose to remember
因为你选择记住的所有事

190
00:09:17.231 --> 00:09:19.708
will be stored permanently on a hard drive somewhere,
都将永久存储在某个硬盘上，

191
00:09:19.732 --> 00:09:21.761
able to be recalled at will.
可以随意回忆。

192
00:09:21.785 --> 00:09:25.151
(Laughter)
（笑声）

193
00:09:25.175 --> 00:09:28.556
The line here between crazy and visionary
疯狂与眼界之间的界限

194
00:09:28.580 --> 00:09:30.047
was never quite clear.
一直不太清晰。

195
00:09:30.540 --> 00:09:32.397
But the systems were safe.
但这些系统是安全的。

196
00:09:32.699 --> 00:09:37.715
So when the FDA decided to deregulate these laser-drilling systems, in 2043,
因此，当FDA在2043年决定 解除对激光钻孔系统的管制时，

197
00:09:37.739 --> 00:09:40.096
commercial demand just exploded.
商业需求爆发了。

198
00:09:40.120 --> 00:09:42.008
People started signing their emails,
人们的电邮签名变成，

199
00:09:41.960 --> 00:09:43.301
"Please excuse any typos.
“请原谅我的错别字。

200
00:09:43.397 --> 00:09:44.730
Sent from my brain."
本文来自我的大脑。”

201
00:09:44.754 --> 00:09:45.755
(Laughter)
（笑声）

202
00:09:45.779 --> 00:09:47.851
Commercial systems popped up left and right,
商业系统左右逢源，

203
00:09:47.875 --> 00:09:51.113
offering the latest and greatest in neural interfacing technology.
开始提供最新最大的 神经接口技术。

204
00:09:51.612 --> 00:09:53.365
There were 100 electrodes.
有百电极规格。

205
00:09:53.389 --> 00:09:55.300
A thousand electrodes.
千电极规格。

206
00:09:55.324 --> 00:09:57.800
High bandwidth for only 99.99 a month.
高速带宽，每月仅99.99。

207
00:09:57.824 --> 00:09:59.363
(Laughter)
（笑声）

208
00:09:59.387 --> 00:10:00.921
Soon, everyone had them.
很快，大家都有了。

209
00:10:01.514 --> 00:10:03.085
And that was the key.
那才是关键。

210
00:10:03.109 --> 00:10:06.032
Because, in the 2050s, if you were a neuroscientist,
因为，到2050年代， 如果你是神经科学家，

211
00:10:06.056 --> 00:10:09.995
you could have someone come into your lab essentially from off the street.
你可以到大街上 随便找个人来实验室。

212
00:10:10.612 --> 00:10:13.476
And you could have them engaged in some emotional task
让他们做一些情绪任务、

213
00:10:13.500 --> 00:10:15.937
or social behavior or abstract reasoning,
社交行为或抽象推理，

214
00:10:15.961 --> 00:10:18.492
things you could never study in mice.
这些不能用老鼠研究的东西。

215
00:10:18.516 --> 00:10:21.627
And you could record the activity of their neurons
你可以用他们已经有的接口

216
00:10:21.651 --> 00:10:24.842
using the interfaces that they already had.
记录他们神经元的活动。

217
00:10:24.866 --> 00:10:28.055
And then you could also ask them about what they were experiencing.
然后问他们的感受。

218
00:10:27.935 --> 00:10:31.314
So this link between psychology and neuroscience
所以在动物身上永远无法建立的 心理学和神经科学

219
00:10:31.452 --> 00:10:34.833
that you could never make in the animals, was suddenly there.
之间的这种联系，就这么出现了。

220
00:10:35.515 --> 00:10:37.699
So perhaps the classic example of this
这方面的典型例子可能是

221
00:10:37.723 --> 00:10:41.246
was the discovery of the neural basis for insight.
发现了洞察力的神经基础。

222
00:10:41.270 --> 00:10:44.870
That "Aha!" moment, the moment it all comes together, it clicks.
那种“原来如此！”的瞬间， 恍然大悟的时刻到来了。

223
00:10:45.413 --> 00:10:49.469
And this was discovered by two scientists in 2055,
这是两位科学家巴里和雷特

224
00:10:49.493 --> 00:10:50.865
Barry and Late,
在2055年发现的，

225
00:10:50.889 --> 00:10:54.552
who observed, in the dorsal prefrontal cortex,
他们在背侧前额叶皮层观察到

226
00:10:54.576 --> 00:10:59.798
how in the brain of someone trying to understand an idea,
人的大脑如何理解一个想法，

227
00:10:59.822 --> 00:11:03.191
how different populations of neurons would reorganize themselves --
不同的神经元群体 如何重新组织自己——

228
00:11:03.215 --> 00:11:05.651
you're looking at neural activity here in orange --
你现在看到的橙色是神经活动——

229
00:11:05.675 --> 00:11:09.413
until finally their activity aligns in a way that leads to positive feedback.
直到它们的活动最终以一种 导向正反馈的方式匹配。

230
00:11:10.159 --> 00:11:11.309
Right there.
就这一下。

231
00:11:12.543 --> 00:11:14.010
That is understanding.
这就是理解。

232
00:11:15.233 --> 00:11:19.670
So finally, we were able to get at the things that make us human.
终于，我们能够找到 让我们成为人类的东西。

233
00:11:21.691 --> 00:11:26.269
And that's what really opened the way to major insights from medicine.
它真正为医学的 深入研究开辟了道路。

234
00:11:27.285 --> 00:11:30.040
Because, starting in the 2060s,
因为从2060年代开始，

235
00:11:30.064 --> 00:11:32.548
with the ability to record the neural activity
我们将有能力记录 这些不同精神疾病的

236
00:11:32.572 --> 00:11:36.159
in the brains of patients with these different mental diseases,
患者大脑中的神经活动，

237
00:11:36.183 --> 00:11:40.873
rather than defining the diseases on the basis of their symptoms,
而不是像本世纪初那样，

238
00:11:40.897 --> 00:11:42.937
as we had at the beginning of the century,
根据症状来定义疾病，

239
00:11:42.961 --> 00:11:44.183
we started to define them
我们开始根据

240
00:11:43.943 --> 00:11:47.746
on the basis of the actual pathology that we observed at the neural level.
在神经层面观察到的 实际病理来定义疾病。

241
00:11:48.588 --> 00:11:52.413
So for example, in the case of ADHD,
例如，在多动症（ADHD）的例子中，

242
00:11:52.437 --> 00:11:55.611
we discovered that there are dozens of different diseases,
我们发现有数十种不同的疾病，

243
00:11:55.635 --> 00:11:58.644
all of which had been called ADHD at the start of the century,
所有这些疾病在本世纪初 都被称为ADHD，

244
00:11:58.668 --> 00:12:00.969
that actually had nothing to do with each other,
但它们除了症状相似之外，

245
00:12:00.993 --> 00:12:03.111
except that they had similar symptoms.
实际上彼此无关。

246
00:12:03.445 --> 00:12:05.817
And they needed to be treated in different ways.
并且需要以不同的方式治疗。

247
00:12:06.127 --> 00:12:08.374
So it was kind of incredible, in retrospect,
回想起来，令人难以置信的是，

248
00:12:08.398 --> 00:12:10.175
that at the beginning of the century,
在本世纪初，

249
00:12:09.881 --> 00:12:11.628
we had been treating all those different diseases
我们一直用同一种药物

250
00:12:11.628 --> 00:12:13.011
with the same drug,
治疗所有这些不同的疾病，

251
00:12:13.747 --> 00:12:16.961
just by giving people amphetamine, basically is what we were doing.
基本上我们所做的就是 给患者服用安非他明。

252
00:12:15.815 --> 00:12:19.473
And schizophrenia and depression are the same way.
治疗精神分裂症和抑郁症也一样。

253
00:12:19.497 --> 00:12:23.529
So rather than prescribing drugs to people essentially at random,
因此，我们不再像以前那样， 几乎是随机地

254
00:12:23.553 --> 00:12:24.703
as we had,
给人们开药，

255
00:12:24.727 --> 00:12:28.238
we learned how to predict which drugs would be most effective
而是学会了如何预测 哪些药物对哪些患者

256
00:12:28.262 --> 00:12:29.445
in which patients,
最有效，

257
00:12:29.469 --> 00:12:32.225
and that just led to this huge improvement in outcomes.
这将带来治疗结果的巨大改善。

258
00:12:33.318 --> 00:12:36.794
OK, I want to bring you back now to the year 2017.
好的，现在我们回到2017年。

259
00:12:37.937 --> 00:12:41.310
Some of this may sound satirical or even far fetched.
有些内容可能听起来很讽刺， 甚至有些牵强。

260
00:12:41.334 --> 00:12:42.627
And some of it is.
有些的确是。

261
00:12:43.111 --> 00:12:45.762
I mean, I can't actually see into the future.
我的意思是，我不能真的看到未来。

262
00:12:45.786 --> 00:12:47.152
I don't actually know
我也不知道

263
00:12:47.176 --> 00:12:50.843
if we're going to be drilling hundreds or thousands of microscopic holes
30年后我们是否 会在头上钻上成百上千个

264
00:12:50.867 --> 00:12:52.534
in our heads in 30 years.
微小的孔。

265
00:12:53.582 --> 00:12:55.288
But what I can tell you
但我可以告诉你的是，

266
00:12:55.312 --> 00:12:57.487
is that we're not going to make any progress
如果要在了解人脑或

267
00:12:57.511 --> 00:13:01.238
towards understanding the human brain or human diseases
人类疾病方面取得任何进步，

268
00:13:01.262 --> 00:13:05.778
until we figure out how to get at the electrical activity of neurons
就必须先知道如何获得

269
00:13:03.802 --> 00:13:07.002
in healthy humans.
健康人大脑神经元的电活动。

270
00:13:07.738 --> 00:13:10.977
And almost no one is working on figuring out how to do that today.
今天几乎没有人在研究 要如何做到这一点。

271
00:13:11.897 --> 00:13:14.231
That is the future of neuroscience.
而这才是神经科学的未来。

272
00:13:14.572 --> 00:13:18.965
And I think it's time for neuroscientists to put down the mouse brain
我认为是时候让 神经科学家放弃鼠脑，

273
00:13:18.989 --> 00:13:21.743
and to dedicate the thought and investment necessary
投入必要的人力和资金

274
00:13:21.767 --> 00:13:25.034
to understand the human brain and human disease.
去理解人脑和人类疾病了。

275
00:13:27.449 --> 00:13:28.600
Thank you.
谢谢。

276
00:13:28.624 --> 00:13:29.796
(Applause)
（掌声）