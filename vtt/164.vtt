WEBVTT

1
00:00:12.620 --> 00:00:16.180
So why do you think the rich should pay more in taxes?
为什么你认为富人就要多交税？

2
00:00:16.220 --> 00:00:18.596
Why did you buy the latest iPhone?
你为什么要买最新的 （苹果手机）iphone？

3
00:00:18.620 --> 00:00:21.076
Why did you pick your current partner?
你为什么选择了你现在的伴侣？

4
00:00:21.100 --> 00:00:24.516
And why did so many people vote for Donald Trump?
还有为什么有那么多人 投了唐纳德·特朗普的票？

5
00:00:24.540 --> 00:00:27.060
What were the reasons, why did they do it?
这背后的原因是什么， 他们为什么这样做？

6
00:00:27.810 --> 00:00:29.916
So we ask this kind of question all the time,
我们一直都问这些问题，

7
00:00:29.940 --> 00:00:31.676
and we expect to get an answer.
并且也希望得到答案。

8
00:00:31.700 --> 00:00:34.836
And when being asked, we expect ourselves to know the answer,
我们也会被问到这些问题， 也希望自己知道答案，

9
00:00:34.860 --> 00:00:37.340
to simply tell why we did as we did.
能够简单的回答 为什么我们要这么做。

10
00:00:38.260 --> 00:00:39.980
But do we really know why?
但是我们真的知道为什么吗？

11
00:00:40.820 --> 00:00:44.276
So when you say that you prefer George Clooney to Tom Hanks,
当你说你喜欢乔治·克鲁尼 多过汤姆·克鲁斯，

12
00:00:44.299 --> 00:00:46.356
due to his concern for the environment,
是因为你觉得 前者更关注环境问题，

13
00:00:46.380 --> 00:00:47.580
is that really true?
那是真的吗？

14
00:00:48.380 --> 00:00:50.876
So you can be perfectly sincere and genuinely believe
你能够诚心诚意的相信

15
00:00:50.900 --> 00:00:53.836
that this is the reason that drives your choice,
那就是驱使你做出选择的原因，

16
00:00:53.860 --> 00:00:56.460
but to me, it may still feel like something is missing.
但是对于我来说， 这其中还是遗漏了一些东西。

17
00:00:57.380 --> 00:01:00.556
As it stands, due to the nature of subjectivity,
事实表明，由于 主观臆断的自然属性，

18
00:01:00.580 --> 00:01:04.900
it is actually very hard to ever prove that people are wrong about themselves.
很难证明人们自己会 对自己有错误的认知。

19
00:01:06.420 --> 00:01:08.556
So I'm an experimental psychologist,
我是一个实验心理学家，

20
00:01:08.580 --> 00:01:12.116
and this is the problem we've been trying to solve in our lab.
这个问题是我们实验室 长久以致力解决的问题。

21
00:01:12.140 --> 00:01:14.316
So we wanted to create an experiment
我们计划设计一个实验，

22
00:01:14.340 --> 00:01:17.876
that would allow us to challenge what people say about themselves,
能够使我们挑战 人们对自己的认知，

23
00:01:17.900 --> 00:01:20.580
regardless of how certain they may seem.
不论看起来他们多么的认同自己。

24
00:01:21.780 --> 00:01:24.516
But tricking people about their own mind is hard.
但是欺骗人们的思想是困难的。

25
00:01:24.540 --> 00:01:26.916
So we turned to the professionals.
于是我们转向专业人员。

26
00:01:26.940 --> 00:01:28.140
The magicians.
魔术师。

27
00:01:28.940 --> 00:01:31.836
So they're experts at creating the illusion of a free choice.
他们很善于创造 一个自由选择的幻觉。

28
00:01:31.860 --> 00:01:34.156
So when they say, "Pick a card, any card,"
当他们说：“选张卡片，任意一张“，

29
00:01:34.180 --> 00:01:37.100
the only thing you know is that your choice is no longer free.
你能知道就是你的选择不再随意。

30
00:01:38.020 --> 00:01:40.396
So we had a few fantastic brainstorming sessions
因此我们和一组瑞典的魔术师，

31
00:01:40.420 --> 00:01:42.276
with a group of Swedish magicians,
来了几轮精彩的头脑风暴，

32
00:01:42.300 --> 00:01:43.942
and they helped us create a method
他们帮我们想出了一些方法，

33
00:01:43.967 --> 00:01:47.940
in which we would be able to manipulate the outcome of people's choices.
能够让我们操控人们选择的结果。

34
00:01:48.580 --> 00:01:51.516
This way we would know when people are wrong about themselves,
这样一来我们就能知道 人们何时对自己的认知是错误的，

35
00:01:51.540 --> 00:01:53.580
even if they don't know this themselves.
甚至他们自己都没意识到这一点。

36
00:01:54.300 --> 00:01:58.956
So I will now show you a short movie showing this manipulation.
我现在给你播放一段短片 来演示这种操控。

37
00:01:58.980 --> 00:02:00.396
So it's quite simple.
这相当简单。

38
00:02:00.420 --> 00:02:02.556
The participants make a choice,
参与者要做出选择，

39
00:02:02.580 --> 00:02:04.836
but I end up giving them the opposite.
但我最终会给出 与他们的选择相反的结果。

40
00:02:04.860 --> 00:02:08.380
And then we want to see: How did they react, and what did they say?
到时我们想看的是： 他们的反应如何，他们怎么说。

41
00:02:09.060 --> 00:02:12.220
So it's quite simple, but see if you can spot the magic going on.
这很简单，但是要看你 能不能看出到底发生了什么。

42
00:02:13.260 --> 00:02:16.780
And this was shot with real participants, they don't know what's going on.
这里拍摄的都是真实的参与者， 他们对幕后的一切毫不知情。

43
00:02:18.820 --> 00:02:21.036
(Video) Petter Johansson: Hi, my name's Petter.
（短片）培特·乔纳森： 嗨，我的名字是培特。

44
00:02:20.220 --> 00:02:21.185
Woman: Hi, I'm Becka.
女士：嗨，我是贝卡。

45
00:02:21.499 --> 00:02:23.470
PJ: I'm going to show you pictures like this.
培特：我要给你看像这样的图片。

46
00:02:23.470 --> 00:02:26.416
And you'll have to decide which one you find more attractive.
然后你要决定哪一张最吸引你。

47
00:02:26.820 --> 00:02:27.860
Becka: OK.
贝卡：好的。

48
00:02:27.860 --> 00:02:31.790
PJ: And then sometimes, I will ask you why you prefer that face.
培特：然后我还会问你 为什么你喜欢那张脸。

49
00:02:31.820 --> 00:02:33.036
Becka: OK.
贝卡：好的。

50
00:02:32.696 --> 00:02:34.260
PJ: Ready? Becka: Yeah.
培特：准备好了吗？ 贝卡：好了。

51
00:02:42.940 --> 00:02:44.756
PJ: Why did you prefer that one?
培特：为什么你喜欢那一张？

52
00:02:44.780 --> 00:02:46.276
Becka: The smile, I think.
贝卡：笑容，我认为。

53
00:02:46.300 --> 00:02:47.500
PJ: Smile.
彼得：笑容。

54
00:02:52.220 --> 00:02:53.460
Man: One on the left.
男士：左边的那张。

55
00:02:57.340 --> 00:02:58.980
Again, this one just struck me.
这张恰巧使我很着迷。

56
00:02:59.580 --> 00:03:01.196
Interesting shot.
很有趣的拍照。

57
00:03:01.220 --> 00:03:04.220
Since I'm a photographer, I like the way it's lit and looks.
我是摄影师，比较喜欢 它展现光线与容貌的方式。

58
00:03:06.100 --> 00:03:08.140
Petter Johansson: But now comes the trick.
（旁白）培特： 下面，见证奇迹的时刻到了。

59
00:03:09.940 --> 00:03:11.220
(Video) Woman 1: This one.
（短片）女士1: 这一张。

60
00:03:16.060 --> 00:03:18.340
PJ: So they get the opposite of their choice.
（旁白）培特：他们拿到的是 之前没有选的那张照片。

61
00:03:20.340 --> 00:03:21.940
And let's see what happens.
让我们来看看会发生什么事。

62
00:03:28.060 --> 00:03:29.260
Woman 2: Um ...
（短片）女士2: 嗯。。。

63
00:03:35.580 --> 00:03:38.380
I think he seems a little more innocent than the other guy.
我认为他看起来 比另一个人无辜些。

64
00:03:45.180 --> 00:03:46.420
Man: The one on the left.
男士：左边的这位。

65
00:03:49.100 --> 00:03:52.796
I like her smile and contour of the nose and face.
我喜欢它的笑容， 还有她鼻子和脸的轮廓。

66
00:03:52.820 --> 00:03:55.580
So it's a little more interesting to me, and her haircut.
有点儿意思， 还有她的头发。

67
00:03:59.860 --> 00:04:01.060
Woman 3: This one.
女士3：这一张。

68
00:04:03.340 --> 00:04:04.916
I like the smirky look better.
我喜欢这种得意的笑容。

69
00:04:04.940 --> 00:04:06.940
PJ: You like the smirky look better?
培特：你比较喜欢得意的表情？

70
00:04:09.500 --> 00:04:12.676
(Laughter)
（观众笑声）

71
00:04:12.700 --> 00:04:13.900
Woman 3: This one.
女士3：这一张。

72
00:04:15.100 --> 00:04:16.500
PJ: What made you choose him?
彼得：你为什么选这张？

73
00:04:17.340 --> 00:04:20.236
Woman 3: I don't know, he looks a little bit like the Hobbit.
女士3：我不知道，他看起来 有点儿像霍比特人。

74
00:04:20.260 --> 00:04:22.316
(Laughter)
（观众笑声）

75
00:04:22.340 --> 00:04:23.836
PJ: And what happens in the end
（旁白）培特：  当我告诉他们

76
00:04:23.860 --> 00:04:26.956
when I tell them the true nature of the experiment?
这个实验的真实目的后， 会发生什么事呢？

77
00:04:26.980 --> 00:04:29.436
Yeah, that's it. I just have to ask a few questions.
（短片）是的，就是这些。 我还要问一些问题。

78
00:04:29.460 --> 00:04:30.676
Man: Sure.
男士：当然。

79
00:04:30.700 --> 00:04:33.676
PJ: What did you think of this experiment, was it easy or hard?
培特：你觉得这实验怎么样， 感觉容易还是难？

80
00:04:33.700 --> 00:04:34.940
Man: It was easy.
男士：容易。

81
00:04:35.860 --> 00:04:37.196
PJ: During the experiments,
培特：在实验当中，

82
00:04:37.220 --> 00:04:40.556
I actually switched the pictures three times.
我其实将照片偷换了三次。

83
00:04:40.580 --> 00:04:42.156
Was this anything you noticed?
你有注意到什么了吗？

84
00:04:42.180 --> 00:04:43.996
Man: No. I didn't notice any of that.
男士：不，我没有注意到什么。

85
00:04:43.980 --> 00:04:45.510
PJ: Not at all? Man: No.
培特：一点都没有吗？ 男士：没有。

86
00:04:45.540 --> 00:04:47.636
Switching the pictures as far as ...
换照片是怎么回事。。。

87
00:04:47.660 --> 00:04:51.476
PJ: Yeah, you were pointing at one of them but I actually gave you the opposite.
培特：就是你选了其中的一张， 而我给你的是另外一张。

88
00:04:51.500 --> 00:04:53.316
Man: The opposite one. OK, when you --
男士：相反的那张， 好的，当你——

89
00:04:52.770 --> 00:04:55.580
No. Shows you how much my attention span was.
不，这是展示我的 注意力持续时间多长。

90
00:04:55.620 --> 00:04:57.140
(Laughter)
（观众笑声）

91
00:04:58.700 --> 00:05:01.716
PJ: Did you notice that sometimes during the experiment
培特：在实验进行当中， 你有注意到

92
00:05:01.740 --> 00:05:03.876
I switched the pictures?
我有几次偷换了照片了吗？

93
00:05:03.900 --> 00:05:05.916
Woman 2: No, I did not notice that.
女士2：不，我没有注意到。

94
00:05:05.940 --> 00:05:08.940
PJ: You were pointing at one, but then I gave you the other one.
培特：你指的一张，但是 我给你的却是另外一张。

95
00:05:09.740 --> 00:05:11.356
No inclination of that happening?
没有发现吗？

96
00:05:11.380 --> 00:05:12.956
Woman 2: No.
女士2：没有。

97
00:05:12.980 --> 00:05:14.236
Woman 2: I did not notice.
女士2：我没有注意到。

98
00:05:14.260 --> 00:05:16.196
(Laughs)
（笑声）

99
00:05:16.220 --> 00:05:17.436
PJ: Thank you.
培特：谢谢。

100
00:05:17.460 --> 00:05:18.836
Woman 2: Thank you.
女士2：谢谢。 （短片结束）

101
00:05:18.860 --> 00:05:20.916
PJ: OK, so as you probably figured out now,
培特：那么你现在大概能猜到了，

102
00:05:20.940 --> 00:05:23.196
the trick is that I have two cards in each hand,
骗术就是，我每只手里 都拿了两张牌，

103
00:05:23.220 --> 00:05:24.796
and when I hand one of them over,
当我把背面那张牌推过去的时候，

104
00:05:24.820 --> 00:05:29.180
the black one kind of disappears into the black surface on the table.
黑色那张原本被选的牌就在 黑色桌面的映衬下消失，被我藏起来了。

105
00:05:30.460 --> 00:05:32.196
So using pictures like this,
像这样使用照片，

106
00:05:32.220 --> 00:05:36.596
normally not more than 20 percent of the participants detect these tries.
通常有不到20%的 参与者会发现这些骗局。

107
00:05:36.620 --> 00:05:38.036
And as you saw in the movie,
正如你在影片中看到的，

108
00:05:38.060 --> 00:05:41.236
when in the end we explain what's going on,
最后我向他们解释 发生了什么的时候，

109
00:05:41.260 --> 00:05:45.636
they're very surprised and often refuse to believe the trick has been made.
他们都非常的惊讶并且通常 拒绝相信其中有诈。

110
00:05:45.660 --> 00:05:50.436
So this shows that this effect is quite robust and a genuine effect.
这就表明，这种效应 是十分强烈而又真实的。

111
00:05:50.460 --> 00:05:53.116
But if you're interested in self-knowledge, as I am,
但是，如果你和我一样对 “自知之明”感兴趣的话。

112
00:05:53.140 --> 00:05:54.476
the more interesting bit is,
最有趣的部分是：

113
00:05:54.500 --> 00:05:58.436
OK, so what did they say when they explained these choices?
他们会如何解释 自己所作出的选择？

114
00:05:58.460 --> 00:05:59.956
So we've done a lot of analysis
为此，我们做了很多关于

115
00:05:59.980 --> 00:06:02.060
of the verbal reports in these experiments.
这个实验当中口头报告的分析。

116
00:06:03.180 --> 00:06:05.636
And this graph simply shows
这张图表明，

117
00:06:05.660 --> 00:06:10.436
that if you compare what they say in a manipulated trial
如果你将有骗局的那组的说辞

118
00:06:10.460 --> 00:06:11.836
with a nonmanipulated trial,
和没有骗局的那组相比较，

119
00:06:11.860 --> 00:06:14.636
that is when they explain a normal choice they've made
你会发现，他们对自己 正常选择的解释

120
00:06:14.660 --> 00:06:17.156
and one where we manipulated the outcome,
和经过操控后的解释是

121
00:06:17.180 --> 00:06:19.636
we find that they are remarkably similar.
非常相似的。

122
00:06:19.660 --> 00:06:22.716
So they are just as emotional, just as specific,
他们都同样的情绪化，目标明确，

123
00:06:22.740 --> 00:06:25.940
and they are expressed with the same level of certainty.
并且他们表达的 肯定程度也处于同一水平。

124
00:06:26.940 --> 00:06:29.276
So the strong conclusion to draw from this
从这个实验中得到的 强有力的结论是，

125
00:06:29.300 --> 00:06:31.516
is that if there are no differences
如果在真正的选择和

126
00:06:31.540 --> 00:06:35.236
between a real choice and a manipulated choice,
被操控的选择之间没有差异的话，

127
00:06:35.260 --> 00:06:37.700
perhaps we make things up all the time.
或许我们一直都在编造理由。

128
00:06:38.500 --> 00:06:39.836
But we've also done studies
但是我们也做过研究，

129
00:06:39.860 --> 00:06:42.876
where we try to match what they say with the actual faces.
尝试将实际的面容 与和他们的描述相匹配。

130
00:06:42.900 --> 00:06:44.780
And then we find things like this.
然后我们发现了这样的事情。

131
00:06:45.580 --> 00:06:50.636
So here, this male participant, he preferred the girl to the left,
这个男性参与者，他偏好左面的女人，

132
00:06:50.660 --> 00:06:52.516
he ended up with the one to the right.
但结果他却是选的右边的那位。

133
00:06:52.540 --> 00:06:55.356
And then, he explained his choice like this.
然后，他给出的解释是：

134
00:06:55.380 --> 00:06:56.676
"She is radiant.
“她明艳动人，

135
00:06:56.700 --> 00:06:59.796
I would rather have approached her at the bar than the other one.
我宁可在酒吧碰到是她 而不是另外一位。

136
00:06:59.820 --> 00:07:01.436
And I like earrings."
并且我喜欢这耳环。“

137
00:07:01.460 --> 00:07:04.956
And whatever made him choose the girl on the left to begin with,
但开始不管是什么理由 让他选择了左边的女人，

138
00:07:04.980 --> 00:07:06.556
it can't have been the earrings,
耳环肯定不是其中一个，

139
00:07:06.580 --> 00:07:09.436
because they were actually sitting on the girl on the right.
因为，右边的女人才戴耳环。

140
00:07:09.460 --> 00:07:13.236
So this is a clear example of a post hoc construction.
这明显是一个“事后构建”的例子。

141
00:07:13.260 --> 00:07:16.060
So they just explained the choice afterwards.
因此，他们只是后来 才对作出的选择进行解释。

142
00:07:17.140 --> 00:07:19.436
So what this experiment shows is,
那么这个实验表明，

143
00:07:19.460 --> 00:07:23.116
OK, so if we fail to detect that our choices have been changed,
如果我们没有发现 自己的选择被调换了，

144
00:07:23.140 --> 00:07:26.340
we will immediately start to explain them in another way.
我们会立即开始用 另外一种方式来解释。

145
00:07:27.340 --> 00:07:28.596
And what we also found
我们还发现

146
00:07:28.620 --> 00:07:31.836
is that the participants often come to prefer the alternative,
参与者会渐渐喜欢上另外那个，

147
00:07:31.860 --> 00:07:34.116
that they were led to believe they liked.
他们被引导，从而相信 那就是他们喜欢的。

148
00:07:34.140 --> 00:07:36.156
So if we let them do the choice again,
如果我们再让他们做出一次选择，

149
00:07:36.180 --> 00:07:39.940
they will now choose the face they had previously rejected.
他们就会选择曾经 被他们拒绝掉的那个。

150
00:07:41.340 --> 00:07:43.636
So this is the effect we call "choice blindness."
这就是我们所说的 “选择盲目性”效应。

151
00:07:43.660 --> 00:07:45.876
And we've done a number of different studies --
并且我们做了很多不同的研究——

152
00:07:45.900 --> 00:07:48.436
we've tried consumer choices,
我们在消费者选择上做过实验，

153
00:07:48.460 --> 00:07:52.876
choices based on taste and smell and even reasoning problems.
建立在味觉和嗅觉上的实验， 甚至还有推理问题。

154
00:07:52.900 --> 00:07:54.956
But what you all want to know is of course
但你们都想知道的是，

155
00:07:54.980 --> 00:07:58.916
does this extend also to more complex, more meaningful choices?
这个现象能否适用于更复杂， 更有意义的选择上呢？

156
00:07:58.940 --> 00:08:02.020
Like those concerning moral and political issues.
比如那些关注于 道德和政治的问题。

157
00:08:04.220 --> 00:08:08.436
So the next experiment, it needs a little bit of a background.
下一个实验需要一些背景知识。

158
00:08:08.460 --> 00:08:12.716
So in Sweden, the political landscape
在瑞典，国家的政治事务是

159
00:08:12.740 --> 00:08:16.100
is dominated by a left-wing and a right-wing coalition.
由左翼和右翼的联合政府主导。

160
00:08:17.540 --> 00:08:21.956
And the voters may move a little bit between the parties within each coalition,
投票人可能会在每个联盟中的 两党之间有一点点犹疑，

161
00:08:21.980 --> 00:08:24.740
but there is very little movement between the coalitions.
但在不同的联盟之间 就没有那么多犹疑。

162
00:08:25.500 --> 00:08:27.476
And before each elections,
在每次选举之前，

163
00:08:27.500 --> 00:08:31.716
the newspapers and the polling institutes
报纸或投票机构，

164
00:08:31.740 --> 00:08:34.356
put together what they call "an election compass"
合起来拿出一个所谓的 “选举指南”，

165
00:08:34.380 --> 00:08:37.716
which consists of a number of dividing issues
这个包含了一系列的具有 分化性的问题，

166
00:08:37.740 --> 00:08:40.076
that sort of separates the two coalitions.
用来分离开两个联盟。

167
00:08:40.100 --> 00:08:43.835
Things like if tax on gasoline should be increased
那些议题包括， 比如燃油费是否要增加，

168
00:08:43.859 --> 00:08:47.955
or if the 13 months of paid parental leave
或者，父母是否应该平均

169
00:08:47.979 --> 00:08:50.475
should be split equally between the two parents
享用那个13个月的产假，

170
00:08:50.499 --> 00:08:53.220
in order to increase gender equality.
以便增加性别平等的机会。

171
00:08:54.660 --> 00:08:56.876
So, before the last Swedish election,
在瑞典最后一次选举之前，

172
00:08:56.900 --> 00:08:59.500
we created an election compass of our own.
我们自己做了一个选举指南。

173
00:09:00.300 --> 00:09:02.436
So we walked up to people in the street
我们走到街上去问路人，

174
00:09:02.460 --> 00:09:05.796
and asked if they wanted to do a quick political survey.
问他们是否愿意 做一个快速的政治调查问卷。

175
00:09:05.820 --> 00:09:08.276
So first we had them state their voting intention
首先，我们让他们在两个联盟

176
00:09:08.300 --> 00:09:09.660
between the two coalitions.
之间说出他们的选举倾向。

177
00:09:10.380 --> 00:09:14.156
Then we asked them to answer 12 of these questions.
然后让他们回答这12个问题。

178
00:09:14.180 --> 00:09:16.156
They would fill in their answers,
他们会写出他们的答案，

179
00:09:16.180 --> 00:09:17.796
and we would ask them to discuss,
然后我会让他们来讨论，

180
00:09:17.820 --> 00:09:23.316
so OK, why do you think tax on gas should be increased?
好，为什么你认为要增加燃油税？

181
00:09:23.340 --> 00:09:25.436
And we'd go through the questions.
我们接着把问题都问完。

182
00:09:25.460 --> 00:09:29.356
Then we had a color coded template
然后我们用涂有颜色的模版

183
00:09:29.380 --> 00:09:32.316
that would allow us to tally their overall score.
记录他们的总分数。

184
00:09:32.340 --> 00:09:35.796
So this person would have one, two, three, four
因此，这个人将会有1，2，3，4

185
00:09:35.820 --> 00:09:39.116
five, six, seven, eight, nine scores to the left,
5，6，7，8， 9分记在左边。

186
00:09:39.140 --> 00:09:41.820
so he would lean to the left, basically.
因此，基本上他会倾向于左翼。

187
00:09:42.620 --> 00:09:47.060
And in the end, we also had them fill in their voting intention once more.
最后，我们再让他们填写投票意向。

188
00:09:47.980 --> 00:09:50.260
But of course, there was also a trick involved.
当然，这里也有诈。

189
00:09:51.180 --> 00:09:53.356
So first, we walked up to people,
首先，我们找到一些路人，

190
00:09:53.380 --> 00:09:55.436
we asked them about their voting intention
询问他们的投票意向，

191
00:09:55.460 --> 00:09:57.716
and then when they started filling in,
然后当他们填写的时候，

192
00:09:57.740 --> 00:10:03.196
we would fill in a set of answers going in the opposite direction.
我们会填写一份相反的答案，

193
00:10:03.220 --> 00:10:05.796
We would put it under the notepad.
并放在写字板的下方。

194
00:10:05.820 --> 00:10:08.596
And when we get the questionnaire,
然后，当我们拿到填好的问卷时，

195
00:10:08.620 --> 00:10:11.940
we would simply glue it on top of the participant's own answer.
会直接把它粘到参与者 自己的答案上面。

196
00:10:15.820 --> 00:10:17.060
So there, it's gone.
于是乎，它不见了。

197
00:10:24.100 --> 00:10:26.476
And then we would ask about each of the questions:
然后，我们会再问他们这几个问题：

198
00:10:26.500 --> 00:10:28.036
How did you reason here?
这里你给出的理由是什么？

199
00:10:28.060 --> 00:10:29.796
And they'll state the reasons,
然后他们会陈述理由，

200
00:10:29.820 --> 00:10:32.300
together we will sum up their overall score.
同时，我们还会算他们的总分。

201
00:10:34.620 --> 00:10:38.300
And in the end, they will state their voting intention again.
最后，他们还会再次陈述 自己的投票意向。

202
00:10:41.780 --> 00:10:43.436
So what we find first of all here,
那么，我们首先了解到的是，

203
00:10:43.460 --> 00:10:47.676
is that very few of these manipulations are detected.
这些小把戏很少会被揭穿。

204
00:10:47.700 --> 00:10:50.356
And they're not detected in the sense that they realize,
即便被发现，他们也不会觉得，

205
00:10:50.380 --> 00:10:52.236
"OK, you must have changed my answer,"
"好吧，你肯定是换掉了我的答案，“

206
00:10:51.950 --> 00:10:53.400
it was more the case that,
更可能是这样，

207
00:10:53.540 --> 00:10:56.716
"OK, I must've misunderstood the question the first time I read it.
“好吧，我第一次读题目的时候 一定是误解它了。

208
00:10:56.740 --> 00:10:57.980
Can I please change it?"
我可以换回答案吗？“

209
00:10:58.900 --> 00:11:04.036
And even if a few of these manipulations were changed,
即便部分被篡改的答案 被改回来了，

210
00:11:04.060 --> 00:11:06.196
the overall majority was missed.
总的来说，大部分还是被忽略了。

211
00:11:06.220 --> 00:11:09.876
So we managed to switch 90 percent of the participants' answers
我们成功替换了90%参与者的答案，

212
00:11:09.900 --> 00:11:13.060
from left to right, right to left, their overall profile.
从左翼到右翼，从右翼到左翼， 他们整个的概述。

213
00:11:14.620 --> 00:11:19.020
And what happens then when they are asked to motivate their choices?
当他们被问及为什么会 选择这个答案时，会发生什么事呢？

214
00:11:19.980 --> 00:11:23.036
And here we find much more interesting verbal reports
在这里，我们发现了比起面部测试

215
00:11:23.060 --> 00:11:25.076
than compared to the faces.
更有趣的口头报告。

216
00:11:25.100 --> 00:11:28.460
People say things like this, and I'll read it to you.
人们这样说，我读给你们听。

217
00:11:29.540 --> 00:11:33.276
So, "Large-scale governmental surveillance of email and internet traffic
他们说：“ 政府大规模针对 电子邮件和网络系统的监管

218
00:11:33.300 --> 00:11:37.636
ought to be permissible as means to combat international crime and terrorism."
应当是被允许的，这意味着 可以打击国际犯罪和恐怖组织。“

219
00:11:37.660 --> 00:11:40.376
"So you agree to some extent with this statement." "Yes."
“那么在一定程度上 你是同意这一陈述的。” “是的”。

220
00:11:40.400 --> 00:11:41.900
"So how did you reason here?"
“那么，这里你给的理由是什么？”

221
00:11:43.420 --> 00:11:48.356
"Well, like, as it is so hard to get at international crime and terrorism,
“嗯，鉴于打击国际犯罪 和恐怖主义是非常困难的，

222
00:11:48.380 --> 00:11:51.156
I think there should be those kinds of tools."
我想那应该就是 可以采用的工具。”

223
00:11:51.180 --> 00:11:54.796
And then the person remembers an argument from the newspaper in the morning.
然后有个人记起早上的 报纸上有一段论述。

224
00:11:54.820 --> 00:11:56.436
"Like in the newspaper today,
“就像早上报纸讲的那样，

225
00:11:56.460 --> 00:11:59.836
it said they can like, listen to mobile phones from prison,
据说，他们能够监听到从狱中 打进打出的电话，

226
00:11:59.860 --> 00:12:03.396
if a gang leader tries to continue his crimes from inside.
比如是否有黑帮头目想在狱中 继续从事他的犯罪活动。

227
00:12:03.420 --> 00:12:06.236
And I think it's madness that we have so little power
我认为不可思议的是，

228
00:12:06.260 --> 00:12:07.916
that we can't stop those things
我们有希望 阻止此类事情发生，

229
00:12:07.940 --> 00:12:10.876
when we actually have the possibility to do so."
但是却没有足够的 能力做到这一点。“

230
00:12:10.900 --> 00:12:13.596
And then there's a little bit back and forth in the end:
最后还有一段犹豫不决的说辞：

231
00:12:13.620 --> 00:12:16.196
"I don't like that they have access to everything I do,
“我不喜欢他们介入到 我做的任何事情中，

232
00:12:15.660 --> 00:12:18.790
but I still think it's worth it in the long run."
但我还是认为这是长久之计。“

233
00:12:18.820 --> 00:12:21.356
So, if you didn't know that this person
如果你不知道这个人刚刚

234
00:12:21.380 --> 00:12:23.636
just took part in a choice blindness experiment,
参加了那个盲选实验，

235
00:12:23.660 --> 00:12:25.516
I don't think you would question
我想你不会质疑

236
00:12:25.540 --> 00:12:28.660
that this is the true attitude of that person.
这就是那个人的真实态度。

237
00:12:29.620 --> 00:12:32.476
And what happens in the end, with the voting intention?
那么最后的投票意向是怎样呢？

238
00:12:32.500 --> 00:12:37.196
What we find -- that one is also clearly affected by the questionnaire.
我们发现，人的思想也明显 受到了问卷的影响。

239
00:12:37.220 --> 00:12:38.956
So we have 10 participants
我们有10个参与者

240
00:12:38.980 --> 00:12:41.956
shifting from left to right or from right to left.
从左翼转到右翼， 右翼换到左翼。

241
00:12:41.980 --> 00:12:44.516
We have another 19 that go from clear voting intention
还有另外19个人的投票意向从

242
00:12:44.540 --> 00:12:45.996
to being uncertain.
明确变到不明确。

243
00:12:45.990 --> 00:12:49.110
Some go from being uncertain to clear voting intention.
有些人的投票意向由不明确 转向明确。

244
00:12:49.140 --> 00:12:53.876
And then there is a number of participants staying uncertain throughout.
还有很多参与者从头到尾都不确定。

245
00:12:53.900 --> 00:12:55.476
And that number is interesting
这个数字很有意思，

246
00:12:55.500 --> 00:13:00.116
because if you look at what the polling institutes say
因为，你若去看 民意调查机构的说法，

247
00:13:00.140 --> 00:13:01.796
the closer you get to an election,
越接近大选时，

248
00:13:01.820 --> 00:13:03.956
the only people that are sort of in play
还能够受到影响的人，

249
00:13:03.980 --> 00:13:06.636
are the ones that are considered uncertain.
就是那些犹豫不决的人。

250
00:13:06.660 --> 00:13:09.876
But we show there is a much larger number
但是，我们的试验表明 有相当一部分人

251
00:13:09.900 --> 00:13:12.700
that would actually consider shifting their attitudes.
实际上还会考虑转变他们的态度。

252
00:13:13.460 --> 00:13:16.956
And here I must point out, of course, that you are not allowed to use this
在这里我还想指出的是，当然 你会被禁止在大选之前

253
00:13:16.980 --> 00:13:19.596
as an actual method to change people's votes
使用这项手段来

254
00:13:19.620 --> 00:13:21.116
before an election,
改变人们的投票意向。

255
00:13:21.140 --> 00:13:24.756
and we clearly debriefed them afterwards
之后我们还很清楚地告诉了他们，

256
00:13:24.780 --> 00:13:27.076
and gave them every opportunity to change back
我们给他们改回原来

257
00:13:27.100 --> 00:13:29.580
to whatever they thought first.
他们所想的答案的机会。

258
00:13:30.420 --> 00:13:32.756
But what this shows is that if you can get people
但是这个试验表明， 如果你可以让这些人们

259
00:13:32.780 --> 00:13:38.316
to see the opposite view and engage in a conversation with themselves,
看到与他们相对的观点，并且 让他们仔细斟酌自己的想法，

260
00:13:38.340 --> 00:13:41.260
that could actually make them change their views.
那就可以使他们改变他们的观点。

261
00:13:42.220 --> 00:13:43.420
OK.
好的。

262
00:13:44.580 --> 00:13:46.236
So what does it all mean?
那么这一切都是什么意思？

263
00:13:46.260 --> 00:13:48.676
What do I think is going on here?
我认为这里到底发生了什么呢？

264
00:13:48.700 --> 00:13:49.916
So first of all,
首先，

265
00:13:49.940 --> 00:13:54.796
a lot of what we call self-knowledge is actually self-interpretation.
那些我们所谓的自知之明 其实是我们的自我诠释。

266
00:13:54.820 --> 00:13:57.316
So I see myself make a choice,
我明白我做了一个选择，

267
00:13:57.340 --> 00:14:00.116
and then when I'm asked why,
而当我被问起为什么时，

268
00:14:00.140 --> 00:14:02.676
I just try to make as much sense of it as possible
我仅仅是想让我的解释

269
00:14:02.700 --> 00:14:04.636
when I make an explanation.
听起来尽可能的合理。

270
00:14:04.660 --> 00:14:07.676
But we do this so quickly and with such ease
但是我们迅速并且很容易地 完成了这一过程，

271
00:14:07.700 --> 00:14:11.980
that we think we actually know the answer when we answer why.
就是我们会误以为 自己已经知道答案了。

272
00:14:12.860 --> 00:14:15.956
And as it is an interpretation,
因为这仅仅是一种诠释，

273
00:14:15.980 --> 00:14:18.276
of course we sometimes make mistakes.
当然我们时常会犯错误。

274
00:14:18.300 --> 00:14:21.820
The same way we make mistakes when we try to understand other people.
当我们尝试去理解他人时， 我们会以同样的方式犯错误。

275
00:14:22.980 --> 00:14:26.676
So beware when you ask people the question "why"
当你问别人“为什么”的 问题时要小心，

276
00:14:26.700 --> 00:14:31.596
because what may happen is that, if you asked them,
因为将会发生的事是， 如果你问他们，

277
00:14:31.620 --> 00:14:35.636
"So why do you support this issue?"
“为什么你会支持这个主张？”

278
00:14:35.660 --> 00:14:38.876
"Why do you stay in this job or this relationship?" --
“你为什么从事这份工作， 或持续这段感情？“

279
00:14:38.900 --> 00:14:42.316
what may happen when you ask why is that you actually create an attitude
其实你已经建立了一种态度，

280
00:14:42.340 --> 00:14:44.580
that wasn't there before you asked the question.
这种态度在你问 这个问题之前并不存在。

281
00:14:45.260 --> 00:14:48.436
And this is of course important in your professional life, as well,
当然这在你的职业生涯中也很重要，

282
00:14:48.460 --> 00:14:49.676
or it could be.
或可能很重要。

283
00:14:49.700 --> 00:14:52.236
If, say, you design something and then you ask people,
比如你设计了一样东西， 然后问人们，

284
00:14:52.260 --> 00:14:54.516
"Why do you think this is good or bad?"
“你为什么说它好，或者坏？”

285
00:14:54.540 --> 00:14:57.596
Or if you're a journalist asking a politician,
或者如果你是一个记者， 你问一个政治家，

286
00:14:57.620 --> 00:14:59.996
"So, why did you make this decision?"
“你为什么要做这个决定？”

287
00:15:00.020 --> 00:15:01.956
Or if indeed you are a politician
或者你就是一个政治家，

288
00:15:01.980 --> 00:15:04.620
and try to explain why a certain decision was made.
并且尝试解释做出 某一决定的原因。

289
00:15:05.900 --> 00:15:09.476
So this may all seem a bit disturbing.
这一切看起来会有些让人不安。

290
00:15:09.500 --> 00:15:12.996
But if you want to look at it from a positive direction,
但是如果你从一个 正面的角度来看，

291
00:15:12.980 --> 00:15:14.740
it could be seen as showing,
这可能就表明，

292
00:15:14.780 --> 00:15:18.156
OK, so we're actually a little bit more flexible than we think.
好吧，我们实际上比 自己想的要更灵活些。

293
00:15:18.180 --> 00:15:20.076
We can change our minds.
我们可以改变我们的想法。

294
00:15:20.100 --> 00:15:22.556
Our attitudes are not set in stone.
我们的态度也不是一成不变的。

295
00:15:22.580 --> 00:15:25.756
And we can also change the minds of others,
并且我们也可以 改变其他人的想法，

296
00:15:25.780 --> 00:15:28.156
if we can only get them to engage with the issue
只要让他们深入讨论问题，

297
00:15:28.180 --> 00:15:29.860
and see it from the opposite view.
并从对立的角度来看。

298
00:15:31.220 --> 00:15:35.156
And in my own personal life, since starting with this research --
在我个人的生活中， 自从我开始这个实验——

299
00:15:35.180 --> 00:15:37.756
So my partner and I, we've always had the rule
我和我的合作者， 我们一直遵守一项原则，

300
00:15:37.780 --> 00:15:40.076
that you're allowed to take things back.
就是你可以反悔。

301
00:15:40.100 --> 00:15:42.436
Just because I said I liked something a year ago,
就像我说的， 一年前我喜欢的东西，

302
00:15:42.460 --> 00:15:44.500
doesn't mean I have to like it still.
并不意味着我现在还要喜欢它。

303
00:15:45.300 --> 00:15:48.116
And getting rid of the need to stay consistent
摆脱对维持一致性的需要，

304
00:15:48.140 --> 00:15:52.500
is actually a huge relief and makes relational life so mush easier to live.
其实是一个巨大的解脱，并且 可以让我们更好的经营人际关系。

305
00:15:53.540 --> 00:15:55.900
Anyway, so the conclusion must be:
总之，结论就是：

306
00:15:56.714 --> 00:15:58.434
know that you don't know yourself.
要明白你不懂你自己。

307
00:15:59.660 --> 00:16:01.980
Or at least not as well as you think you do.
或者，至少不像 你想的那么了解自己。

308
00:16:02.410 --> 00:16:03.240
Thanks.
谢谢。

309
00:16:03.240 --> 00:16:06.016
(Applause)
（鼓掌）